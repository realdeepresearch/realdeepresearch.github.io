{
    "rank": 0,
    "keywords": "LLM evaluation, alignment methods, human feedback",
    "slope": 0.022398881124933073,
    "color": "#ffff00",
    "proportions": {
        "2021": 0.0017482517482517483,
        "2022": 0.0,
        "2023": 0.009868421052631578,
        "2024": 0.057803468208092484,
        "2025": 0.08484092326887087
    }
}