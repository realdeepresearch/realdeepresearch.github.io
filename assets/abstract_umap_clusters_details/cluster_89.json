{
  "cluster_id": 89,
  "papers": [
    {
      "id": "iclr22_7F9cOhdvfk_",
      "paper_id": "7F9cOhdvfk_",
      "title": "$\\mathrm{SO}(2)$-Equivariant Reinforcement Learning",
      "authors": "Dian Wang, Robin Walters, Robert Platt",
      "paper_url": "https://openreview.net/pdf/9f58959cef1dc2c685298e532713a5104f2df44b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_o5Bqa4o5Mi",
      "paper_id": "o5Bqa4o5Mi",
      "title": "$\\pi$2vec: Policy Representation with Successor Features",
      "authors": "Gianluca Scarpellini, Ksenia Konyushkova, Claudio Fantacci, Thomas Paine, Yutian Chen, Misha Denil",
      "paper_url": "https://openreview.net/pdf?id=o5Bqa4o5Mi",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_LWuYsSD94h",
      "paper_id": "LWuYsSD94h",
      "title": "A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning",
      "authors": "Haozhe Jiang, Qiwen Cui, Zhihan Xiong, Maryam Fazel, Simon Shaolei Du",
      "paper_url": "https://openreview.net/pdf?id=LWuYsSD94h",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_mbxz9Cjehr",
      "paper_id": "mbxz9Cjehr",
      "title": "A CMDP-within-online framework for Meta-Safe Reinforcement Learning",
      "authors": "Vanshaj Khattar, Yuhao Ding, Bilgehan Sel, Javad Lavaei, Ming Jin",
      "paper_url": "https://openreview.net/pdf/a0814d04508ed834d5ecec6097573946c1f8b619.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_JBAZe2yN6Ub",
      "paper_id": "JBAZe2yN6Ub",
      "title": "A First-Occupancy Representation for Reinforcement Learning",
      "authors": "Ted Moskovitz, Spencer R Wilson, Maneesh Sahani",
      "paper_url": "https://openreview.net/pdf/46abdff2d131f44012d855cdd93c0fa7034d601a.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_mUbYof5MKp",
      "paper_id": "mUbYof5MKp",
      "title": "A General Framework for Off-Policy Learning with Partially-Observed Reward",
      "authors": "Rikiya Takehi, Masahiro Asami, Kosuke Kawakami, Yuta Saito",
      "paper_url": "https://openreview.net/pdf?id=mUbYof5MKp",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_dqITIpZ5Z4b",
      "paper_id": "dqITIpZ5Z4b",
      "title": "A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning",
      "authors": "Zixiang Chen, Chris Junchi Li, Huizhuo Yuan, Quanquan Gu, Michael Jordan",
      "paper_url": "https://openreview.net/pdf/78f90f35e722c4fb344bd1556ce84379181cd92a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_8BAkNCqpGW",
      "paper_id": "8BAkNCqpGW",
      "title": "A Policy Gradient Method for Confounded POMDPs",
      "authors": "Mao Hong, Zhengling Qi, Yanxun Xu",
      "paper_url": "https://openreview.net/pdf?id=8BAkNCqpGW",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_YRq0ZUnzKoZ",
      "paper_id": "YRq0ZUnzKoZ",
      "title": "A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning",
      "authors": "Jiaxian Guo, Mingming Gong, Dacheng Tao",
      "paper_url": "https://openreview.net/pdf/a6c6a600f9e89fe92c0e2d8df1d09d0a78dd39ad.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_xCkgX4Xfu0",
      "paper_id": "xCkgX4Xfu0",
      "title": "A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals",
      "authors": "Grace Liu, Michael Tang, Benjamin Eysenbach",
      "paper_url": "https://openreview.net/pdf?id=xCkgX4Xfu0",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_ECuvULjFQia",
      "paper_id": "ECuvULjFQia",
      "title": "A teacher-student framework to distill future trajectories",
      "authors": "Alexander Neitz, Giambattista Parascandolo, Bernhard Schölkopf",
      "paper_url": "https://openreview.net/pdf/92e8f1e3d126b2094e7c7fd20bede53365fc6ea9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_ZSKRQMvttc",
      "paper_id": "ZSKRQMvttc",
      "title": "Accelerated Policy Learning with Parallel Differentiable Simulation",
      "authors": "Jie Xu, Viktor Makoviychuk, Yashraj Narang, Fabio Ramos, Wojciech Matusik, Animesh Garg, Miles Macklin",
      "paper_url": "https://openreview.net/pdf/114df250fe35e26582332a1e3f398f2f33148603.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_4gaySj8kvX",
      "paper_id": "4gaySj8kvX",
      "title": "Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research",
      "authors": "Michał Bortkiewicz, Władysław Pałucki, Vivek Myers, Tadeusz Dziarmaga, Tomasz Arczewski, Łukasz Kuciński, Benjamin Eysenbach",
      "paper_url": "https://openreview.net/pdf?id=4gaySj8kvX",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_yoVq2BGQdP",
      "paper_id": "yoVq2BGQdP",
      "title": "Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning",
      "authors": "Peizhong Ju, Arnob Ghosh, Ness Shroff",
      "paper_url": "https://openreview.net/pdf?id=yoVq2BGQdP",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_MOmqfJovQ6",
      "paper_id": "MOmqfJovQ6",
      "title": "Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping",
      "authors": "Yining Li, Peizhong Ju, Ness Shroff",
      "paper_url": "https://openreview.net/pdf?id=MOmqfJovQ6",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_zZhX4eYNeeh",
      "paper_id": "zZhX4eYNeeh",
      "title": "Achieving Sub-linear Regret in Infinite Horizon Average Reward Constrained MDP with Linear Function Approximation",
      "authors": "Arnob Ghosh, Xingyu Zhou, Ness Shroff",
      "paper_url": "https://openreview.net/pdf/1f7737b862cddaad3c73169398172437ec830f89.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_j1RMMKeP2gR",
      "paper_id": "j1RMMKeP2gR",
      "title": "Acting in Delayed Environments with Non-Stationary Markov Policies",
      "authors": "Esther Derman, Gal Dalal, Shie Mannor",
      "paper_url": "https://openreview.net/pdf/da00ad1a9fdf6ed49ff470887d9046490c8058b9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_Za3M6OZuCU",
      "paper_id": "Za3M6OZuCU",
      "title": "Actions Speak Louder Than Words: Rate-Reward Trade-off in Markov Decision Processes",
      "authors": "Haotian Wu, Gongpu Chen, Deniz Gunduz",
      "paper_url": "https://openreview.net/pdf?id=Za3M6OZuCU",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_sNuFKTMktcY",
      "paper_id": "sNuFKTMktcY",
      "title": "Active Hierarchical Exploration with Stable Subgoal Representation Learning",
      "authors": "Siyuan Li, Jin Zhang, Jianhao Wang, Yang Yu, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/ab3c3ef2320e8d9c7eb88f44d5945f5e22a93480.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_qiluFujVc8",
      "paper_id": "qiluFujVc8",
      "title": "ACTIVE: Offline Reinforcement Learning via Adaptive Imitation and In-sample $V$-Ensemble",
      "authors": "Tianyuan Chen, Ronglong Cai, Faguo Wu, Xiao Zhang",
      "paper_url": "https://openreview.net/pdf?id=qiluFujVc8",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_vEZyTBRPP6o",
      "paper_id": "vEZyTBRPP6o",
      "title": "Actor-critic is implicitly biased towards high entropy optimal policies",
      "authors": "Yuzheng Hu, Ziwei Ji, Matus Telgarsky",
      "paper_url": "https://openreview.net/pdf/e3148627ceb1e142df2619915a089a8c90153ef0.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_aKRADWBJ1I",
      "paper_id": "aKRADWBJ1I",
      "title": "ActSafe: Active Exploration with Safety Constraints for Reinforcement Learning",
      "authors": "Yarden As, Bhavya Sukhija, Lenart Treven, Carmelo Sferrazza, Stelian Coros, Andreas Krause",
      "paper_url": "https://openreview.net/pdf?id=aKRADWBJ1I",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_dyjPVUc2KB",
      "paper_id": "dyjPVUc2KB",
      "title": "Adapting to Reward Progressivity via Spectral Reinforcement Learning",
      "authors": "Michael Dann, John Thangarajah",
      "paper_url": "https://openreview.net/pdf/a3879d188d633661f6593af48f3c561aefbfb6ff.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_leACdxBEgv",
      "paper_id": "leACdxBEgv",
      "title": "Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning",
      "authors": "Théo Vincent, Fabian Wahren, Jan Peters, Boris Belousov, Carlo D'Eramo",
      "paper_url": "https://openreview.net/pdf?id=leACdxBEgv",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_8xLkv08d70T",
      "paper_id": "8xLkv08d70T",
      "title": "Adaptive Procedural Task Generation for Hard-Exploration Problems",
      "authors": "Kuan Fang, Yuke Zhu, Silvio Savarese, L. Fei-Fei",
      "paper_url": "https://openreview.net/pdf/24bbbe680bd44c907aab36d5e18bae82a7a5a48f.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_g90ysX1sVs",
      "paper_id": "g90ysX1sVs",
      "title": "Adaptive Rational Activations to Boost Deep Reinforcement Learning",
      "authors": "Quentin Delfosse, Patrick Schramowski, Martin Mundt, Alejandro Molina, Kristian Kersting",
      "paper_url": "https://openreview.net/pdf?id=g90ysX1sVs",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_apXtolxDaJ",
      "paper_id": "apXtolxDaJ",
      "title": "Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation",
      "authors": "Qiang He, Tianyi Zhou, Meng Fang, Setareh Maghsudi",
      "paper_url": "https://openreview.net/pdf?id=apXtolxDaJ",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_8H5bpVwvt5",
      "paper_id": "8H5bpVwvt5",
      "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
      "authors": "Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang",
      "paper_url": "https://openreview.net/pdf/d3061c36db2595696e3c5444edf46fe3a2f665e9.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_Z8UfDs4J46",
      "paper_id": "Z8UfDs4J46",
      "title": "Addressing Signal Delay in Deep Reinforcement Learning",
      "authors": "Wei Wang, Dongqi Han, Xufang Luo, Dongsheng Li",
      "paper_url": "https://openreview.net/pdf?id=Z8UfDs4J46",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_DuQkqSe9en",
      "paper_id": "DuQkqSe9en",
      "title": "Adversarial Imitation Learning via Boosting",
      "authors": "Jonathan Daniel Chang, Dhruv Sreenivas, Yingbing Huang, Kianté Brantley, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=DuQkqSe9en",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_bhfp5GlDtGe",
      "paper_id": "bhfp5GlDtGe",
      "title": "Adversarial Imitation Learning with Preferences",
      "authors": "Aleksandar Taranovic, Andras Gabor Kupcsik, Niklas Freymuth, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf/d28eb645545687a36d4398fab2466f674e553bb5.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_5Y9NT6lW21",
      "paper_id": "5Y9NT6lW21",
      "title": "Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning",
      "authors": "Hyungkyu Kang, Min-hwan Oh",
      "paper_url": "https://openreview.net/pdf?id=5Y9NT6lW21",
      "venue": "iclr25"
    },
    {
      "id": "iclr21__mQp5cr_iNy",
      "paper_id": "_mQp5cr_iNy",
      "title": "Adversarially Guided Actor-Critic",
      "authors": "Yannis Flet-Berliac, Johan Ferret, Olivier Pietquin, Philippe Preux, Matthieu Geist",
      "paper_url": "https://openreview.net/pdf/14e743d36a73f6572d0a514054121457cc066814.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_FDimWzmcWn",
      "paper_id": "FDimWzmcWn",
      "title": "AgentRefine: Enhancing Agent Generalization through Refinement Tuning",
      "authors": "Dayuan Fu, Keqing He, Yejie Wang, Wentao Hong, Zhuoma GongQue, Weihao Zeng, Wei Wang, Jingang Wang, Xunliang Cai, Weiran Xu",
      "paper_url": "https://openreview.net/pdf?id=FDimWzmcWn",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_M6XWoEdmwf",
      "paper_id": "M6XWoEdmwf",
      "title": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents",
      "authors": "Jake Grigsby, Linxi Fan, Yuke Zhu",
      "paper_url": "https://openreview.net/pdf?id=M6XWoEdmwf",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_0no8Motr-zO",
      "paper_id": "0no8Motr-zO",
      "title": "An Experimental Design Perspective on Model-Based Reinforcement Learning",
      "authors": "Viraj Mehta, Biswajit Paria, Jeff Schneider, Stefano Ermon, Willie Neiswanger",
      "paper_url": "https://openreview.net/pdf/63dd95d2070f3aa102826f2f0581987c13f5d0cf.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_9JtG4nN7ql",
      "paper_id": "9JtG4nN7ql",
      "title": "An Optimal Discriminator Weighted Imitation Perspective for Reinforcement Learning",
      "authors": "Haoran Xu, Shuozhe Li, Harshit Sikchi, Scott Niekum, Amy Zhang",
      "paper_url": "https://openreview.net/pdf?id=9JtG4nN7ql",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_JZCxlrwjZ8",
      "paper_id": "JZCxlrwjZ8",
      "title": "Any-step Dynamics Model Improves Future Predictions for Online and Offline Reinforcement Learning",
      "authors": "Haoxin Lin, Yu-Yan Xu, Yihao Sun, Zhilong Zhang, Yi-Chen Li, Chengxing Jia, Junyin Ye, Jiaji Zhang, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=JZCxlrwjZ8",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_Y87Ri-GNHYu",
      "paper_id": "Y87Ri-GNHYu",
      "title": "Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning",
      "authors": "Valerie Chen, Abhinav Gupta, Kenneth Marino",
      "paper_url": "https://openreview.net/pdf/be28b5c6ceded7efd434a4a312e5019c4cb5480f.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_LWmuPfEYhH",
      "paper_id": "LWmuPfEYhH",
      "title": "Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning",
      "authors": "Zican Hu, Zongzhang Zhang, Huaxiong Li, Chunlin Chen, Hongyu Ding, Zhi Wang",
      "paper_url": "https://openreview.net/pdf?id=LWmuPfEYhH",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_9ehJCZz4aM",
      "paper_id": "9ehJCZz4aM",
      "title": "AutoCGP: Closed-Loop Concept-Guided Policies from Unlabeled Demonstrations",
      "authors": "Pei Zhou, Ruizhe Liu, Qian Luo, Fan Wang, Yibing Song, Yanchao Yang",
      "paper_url": "https://openreview.net/pdf?id=9ehJCZz4aM",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_nkaba3ND7B5",
      "paper_id": "nkaba3ND7B5",
      "title": "Autonomous Reinforcement Learning: Formalism and Benchmarking",
      "authors": "Archit Sharma, Kelvin Xu, Nikhil Sardana, Abhishek Gupta, Karol Hausman, Sergey Levine, Chelsea Finn",
      "paper_url": "https://openreview.net/pdf/f572a28516f88b10b825a32cd24ba9922c1d015e.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_kmqjgSNXby",
      "paper_id": "kmqjgSNXby",
      "title": "Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization",
      "authors": "Michael R Zhang, Thomas Paine, Ofir Nachum, Cosmin Paduraru, George Tucker, ziyu wang, Mohammad Norouzi",
      "paper_url": "https://openreview.net/pdf/258fc8fbf3df2a9d9783d528b562f8f503fe1167.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_P6dwZJpJ4m",
      "paper_id": "P6dwZJpJ4m",
      "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
      "authors": "Weihao Zeng, Yuzhen Huang, Lulu Zhao, Yijun Wang, Zifei Shan, Junxian He",
      "paper_url": "https://openreview.net/pdf?id=P6dwZJpJ4m",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_YPChvOgRXRA",
      "paper_id": "YPChvOgRXRA",
      "title": "Backstepping Temporal Difference Learning",
      "authors": "Han-Dong Lim, Donghwan Lee",
      "paper_url": "https://openreview.net/pdf/2e9905b6b2da1535ad686cdfabe136dd962adb12.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_Bo62NeU6VF",
      "paper_id": "Bo62NeU6VF",
      "title": "Backtracking Improves Generation Safety",
      "authors": "Yiming Zhang, Jianfeng Chi, Hailey Nguyen, Kartikeya Upasani, Daniel M. Bikel, Jason E Weston, Eric Michael Smith",
      "paper_url": "https://openreview.net/pdf?id=Bo62NeU6VF",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_TQt98Ya7UMP",
      "paper_id": "TQt98Ya7UMP",
      "title": "Balancing Constraints and Rewards with Meta-Gradient D4PG",
      "authors": "Dan A. Calian, Daniel J Mankowitz, Tom Zahavy, Zhongwen Xu, Junhyuk Oh, Nir Levine, Timothy Mann",
      "paper_url": "https://openreview.net/pdf/c2bc1eac3b05c897508a2b6cf4f096a98dbcc8e2.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_tijmpS9Vy2",
      "paper_id": "tijmpS9Vy2",
      "title": "BAMDP Shaping: a Unified Framework for Intrinsic Motivation and Reward Shaping",
      "authors": "Aly Lidayan, Michael D Dennis, Stuart Russell",
      "paper_url": "https://openreview.net/pdf?id=tijmpS9Vy2",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_po-DLlBuAuz",
      "paper_id": "po-DLlBuAuz",
      "title": "Batch Reinforcement Learning Through Continuation Method",
      "authors": "Yijie Guo, Shengyu Feng, Nicolas Le Roux, Ed Chi, Honglak Lee, Minmin Chen",
      "paper_url": "https://openreview.net/pdf/84a7a35d996f84ab9fbbbcabccbdc21f44f2ba68.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_Ovnwe_sDQW",
      "paper_id": "Ovnwe_sDQW",
      "title": "BC-IRL: Learning Generalizable Reward Functions from Demonstrations",
      "authors": "Andrew Szot, Amy Zhang, Dhruv Batra, Zsolt Kira, Franziska Meier",
      "paper_url": "https://openreview.net/pdf/214dd3d4f346964ae17621ab8b33fe8cd5a4a444.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_hQ4K9Bf4G2B",
      "paper_id": "hQ4K9Bf4G2B",
      "title": "Behavior Prior Representation learning for Offline Reinforcement Learning",
      "authors": "Hongyu Zang, Xin Li, Jie Yu, Chen Liu, Riashat Islam, Remi Tachet des Combes, Romain Laroche",
      "paper_url": "https://openreview.net/pdf/96eb2ddb9c4aa37f98b044bc2a20d050badf1645.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_zrT3HcsWSAt",
      "paper_id": "zrT3HcsWSAt",
      "title": "Behavioral Cloning from Noisy Demonstrations",
      "authors": "Fumihiro Sasaki, Ryota Yamashina",
      "paper_url": "https://openreview.net/pdf/980d70256a0232aceda73c88d52522e48fff995d.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_LuT2CVrlpU",
      "paper_id": "LuT2CVrlpU",
      "title": "Behavioral Entropy-Guided Dataset Generation for Offline Reinforcement Learning",
      "authors": "Wesley A. Suttle, Aamodh Suresh, Carlos Nieto-Granda",
      "paper_url": "https://openreview.net/pdf?id=LuT2CVrlpU",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_7gDENzTzw1",
      "paper_id": "7gDENzTzw1",
      "title": "Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations",
      "authors": "Xiaolin Sun, Zizhan Zheng",
      "paper_url": "https://openreview.net/pdf?id=7gDENzTzw1",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_vINj_Hv9szL",
      "paper_id": "vINj_Hv9szL",
      "title": "Benchmarking Constraint Inference in Inverse Reinforcement Learning",
      "authors": "Guiliang Liu, Yudong Luo, Ashish Gaurav, Kasra Rezaee, Pascal Poupart",
      "paper_url": "https://openreview.net/pdf/293f3f980a964c27fc56091298401364387afced.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_3k5CUGDLNdd",
      "paper_id": "3k5CUGDLNdd",
      "title": "Benchmarking Offline Reinforcement Learning on Real-Robot Hardware",
      "authors": "Nico Gürtler, Sebastian Blaes, Pavel Kolev, Felix Widmaier, Manuel Wuthrich, Stefan Bauer, Bernhard Schölkopf, Georg Martius",
      "paper_url": "https://openreview.net/pdf/67dcc1b0cfc87e5d6aeaf0391094380da9c1897b.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_kWSeGEeHvF8",
      "paper_id": "kWSeGEeHvF8",
      "title": "Benchmarks for Deep Off-Policy Evaluation",
      "authors": "Justin Fu, Mohammad Norouzi, Ofir Nachum, George Tucker, ziyu wang, Alexander Novikov, Mengjiao Yang, Michael R Zhang, Yutian Chen, Aviral Kumar, Cosmin Paduraru, Sergey Levine, Thomas Paine",
      "paper_url": "https://openreview.net/pdf/3a90850ebecc25b81a9534180c75842a2b672812.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_DFTHW0MyiW",
      "paper_id": "DFTHW0MyiW",
      "title": "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies",
      "authors": "Xiangyu Liu, Chenghao Deng, Yanchao Sun, Yongyuan Liang, Furong Huang",
      "paper_url": "https://openreview.net/pdf?id=DFTHW0MyiW",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_FviefuxmeW",
      "paper_id": "FviefuxmeW",
      "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration",
      "authors": "Heyang Zhao, Xingrui Yu, David Mark Bossens, Ivor Tsang, Quanquan Gu",
      "paper_url": "https://openreview.net/pdf?id=FviefuxmeW",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_LedObtLmCjS",
      "paper_id": "LedObtLmCjS",
      "title": "Bi-linear Value Networks for Multi-goal Reinforcement Learning",
      "authors": "Zhang-Wei Hong, Ge Yang, Pulkit Agrawal",
      "paper_url": "https://openreview.net/pdf/278077713254a379481bd2b7e25393ca3e4758b6.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_qZmn2hkuzw",
      "paper_id": "qZmn2hkuzw",
      "title": "Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling",
      "authors": "Yuejiang Liu, Jubayer Ibn Hamid, Annie Xie, Yoonho Lee, Max Du, Chelsea Finn",
      "paper_url": "https://openreview.net/pdf?id=qZmn2hkuzw",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_F07ic7huE3",
      "paper_id": "F07ic7huE3",
      "title": "Bisimulation Metric for Model Predictive Control",
      "authors": "Yutaka Shimizu, Masayoshi Tomizuka",
      "paper_url": "https://openreview.net/pdf?id=F07ic7huE3",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_eJ0dzPJq1F",
      "paper_id": "eJ0dzPJq1F",
      "title": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement",
      "authors": "Xuefeng Liu, Takuma Yoneda, Rick Stevens, Matthew Walter, Yuxin Chen",
      "paper_url": "https://openreview.net/pdf?id=eJ0dzPJq1F",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_RqCC_00Bg7V",
      "paper_id": "RqCC_00Bg7V",
      "title": "Blending MPC & Value Function Approximation for Efficient Reinforcement Learning",
      "authors": "Mohak Bhardwaj, Sanjiban Choudhury, Byron Boots",
      "paper_url": "https://openreview.net/pdf/50c99bb8be8ec7784b7ca8b4a8b59da987b66045.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_60i0ksMAhd",
      "paper_id": "60i0ksMAhd",
      "title": "BlendRL: A Framework for Merging Symbolic and Neural Policy Learning",
      "authors": "Hikaru Shindo, Quentin Delfosse, Devendra Singh Dhami, Kristian Kersting",
      "paper_url": "https://openreview.net/pdf?id=60i0ksMAhd",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_anbBFlX1tJ1",
      "paper_id": "anbBFlX1tJ1",
      "title": "Boosted Curriculum Reinforcement Learning",
      "authors": "Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen",
      "paper_url": "https://openreview.net/pdf/066eed802f996fdef355f574e65bcaba5794933a.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_OxNQXyZK-K8",
      "paper_id": "OxNQXyZK-K8",
      "title": "Boosting Multiagent Reinforcement Learning via Permutation Invariant and Permutation Equivariant Networks",
      "authors": "Jianye HAO, Xiaotian Hao, Hangyu Mao, Weixun Wang, Yaodong Yang, Dong Li, YAN ZHENG, Zhen Wang",
      "paper_url": "https://openreview.net/pdf/12d1e22292ed56512748543827e4cf87c98d1534.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_i7jAYFYDcM",
      "paper_id": "i7jAYFYDcM",
      "title": "Bootstrapped Model Predictive Control",
      "authors": "Yuhang Wang, Hanwei Guo, Sizhe Wang, Long Qian, Xuguang Lan",
      "paper_url": "https://openreview.net/pdf?id=i7jAYFYDcM",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_ms0VgzSGF2",
      "paper_id": "ms0VgzSGF2",
      "title": "Bridging State and History Representations: Understanding Self-Predictive RL",
      "authors": "Tianwei Ni, Benjamin Eysenbach, Erfan SeyedSalehi, Michel Ma, Clement Gehring, Aditya Mahajan, Pierre-Luc Bacon",
      "paper_url": "https://openreview.net/pdf?id=ms0VgzSGF2",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_o-1v9hdSult",
      "paper_id": "o-1v9hdSult",
      "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations",
      "authors": "Sarath Sreedharan, Utkarsh Soni, Mudit Verma, Siddharth Srivastava, Subbarao Kambhampati",
      "paper_url": "https://openreview.net/pdf/2558c3735ba361f65aac84ecf8e9f4624e87dec8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_z6KS9D1dxt",
      "paper_id": "z6KS9D1dxt",
      "title": "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game",
      "authors": "Simin Li, Jun Guo, Jingqiao Xiu, Ruixiao Xu, Xin Yu, Jiakai Wang, Aishan Liu, Yaodong Yang, Xianglong Liu",
      "paper_url": "https://openreview.net/pdf?id=z6KS9D1dxt",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_W3Wf_wKmqm9",
      "paper_id": "W3Wf_wKmqm9",
      "title": "C-Learning: Horizon-Aware Cumulative Accessibility Estimation",
      "authors": "Panteha Naderian, Gabriel Loaiza-Ganem, Harry J. Braviner, Anthony L. Caterini, Jesse C. Cresswell, Tong Li, Animesh Garg",
      "paper_url": "https://openreview.net/pdf/a50d45f24c305299cc3ac8aff9cd1d83ec4861e5.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_tc5qisoB-C",
      "paper_id": "tc5qisoB-C",
      "title": "C-Learning: Learning to Achieve Goals via Recursive Classification",
      "authors": "Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/6a06ad37cef81666dc0ffbc9cffba623fcb34843.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_K2JfSnLBD9",
      "paper_id": "K2JfSnLBD9",
      "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
      "authors": "Tianjun Zhang, Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine, Joseph E. Gonzalez",
      "paper_url": "https://openreview.net/pdf/94d8bdac5cba49cee62dd6963b40612d903f60af.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_ipflrGaf7ry",
      "paper_id": "ipflrGaf7ry",
      "title": "Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories",
      "authors": "Li-Cheng Lan, Huan Zhang, Cho-Jui Hsieh",
      "paper_url": "https://openreview.net/pdf/80245884d3c21d7b21166281784b35962b9f3e1f.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_KRv9NubipP",
      "paper_id": "KRv9NubipP",
      "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation",
      "authors": "Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, Jan-Jakob Sonke, Efstratios Gavves",
      "paper_url": "https://openreview.net/pdf?id=KRv9NubipP",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_KjOAHlKMF5",
      "paper_id": "KjOAHlKMF5",
      "title": "Cascading Reinforcement Learning",
      "authors": "Yihan Du, R. Srikant, Wei Chen",
      "paper_url": "https://openreview.net/pdf?id=KjOAHlKMF5",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_ZDaSIkWT-AP",
      "paper_id": "ZDaSIkWT-AP",
      "title": "Case-based reasoning for better generalization in textual reinforcement learning",
      "authors": "Mattia Atzeni, Shehzaad Zuzar Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan",
      "paper_url": "https://openreview.net/pdf/426ad0e0a618d416dbdc8a2fbaa7f29661e1f920.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_R0Xxvr_X3ZA",
      "paper_id": "R0Xxvr_X3ZA",
      "title": "Causal Confusion and Reward Misidentification in Preference-Based Reward Learning",
      "authors": "Jeremy Tien, Jerry Zhi-Yang He, Zackory Erickson, Anca Dragan, Daniel S. Brown",
      "paper_url": "https://openreview.net/pdf/f41368bc311fd0e894120cf88134acdbc361ec94.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_B-z41MBL_tH",
      "paper_id": "B-z41MBL_tH",
      "title": "Causal Imitation Learning via Inverse Reinforcement Learning",
      "authors": "Kangrui Ruan, Junzhe Zhang, Xuan Di, Elias Bareinboim",
      "paper_url": "https://openreview.net/pdf/2d0bee07a9f373073524d04d2dae5fab301d34be.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_nDj45w5wam",
      "paper_id": "nDj45w5wam",
      "title": "Causal Information Prioritization for Efficient Reinforcement Learning",
      "authors": "Hongye Cao, Fan Feng, Tianpei Yang, Jing Huo, Yang Gao",
      "paper_url": "https://openreview.net/pdf?id=nDj45w5wam",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_SK7A5pdrgov",
      "paper_id": "SK7A5pdrgov",
      "title": "CausalWorld: A Robotic Manipulation Benchmark for Causal Structure and Transfer Learning",
      "authors": "Ossama Ahmed, Frederik Träuble, Anirudh Goyal, Alexander Neitz, Manuel Wuthrich, Yoshua Bengio, Bernhard Schölkopf, Stefan Bauer",
      "paper_url": "https://openreview.net/pdf/824ca65f541287b48a971348ef2dff33ffce0ffd.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_LQ6LQ8f4y8",
      "paper_id": "LQ6LQ8f4y8",
      "title": "CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning",
      "authors": "Liyiming Ke, Yunchu Zhang, Abhay Deshpande, Siddhartha Srinivasa, Abhishek Gupta",
      "paper_url": "https://openreview.net/pdf?id=LQ6LQ8f4y8",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_dCOL0inGl3e",
      "paper_id": "dCOL0inGl3e",
      "title": "Certifiably Robust Policy Learning against Adversarial Multi-Agent Communication",
      "authors": "Yanchao Sun, Ruijie Zheng, Parisa Hassanzadeh, Yongyuan Liang, Soheil Feizi, Sumitra Ganesh, Furong Huang",
      "paper_url": "https://openreview.net/pdf/f1c6ea43513dada0ace7e97e3a9c8f26b83250a8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_cddbeL1HWaD",
      "paper_id": "cddbeL1HWaD",
      "title": "Cheap Talk Discovery and Utilization in Multi-Agent Reinforcement Learning",
      "authors": "Yat Long Lo, Christian Schroeder de Witt, Samuel Sokota, Jakob Nicolaus Foerster, Shimon Whiteson",
      "paper_url": "https://openreview.net/pdf/efb6725925bb04b66d9a794a929e5ed57ea8ef69.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_UBVNwD3hPN",
      "paper_id": "UBVNwD3hPN",
      "title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents",
      "authors": "Siyuan Qi, Shuo Chen, Yexin Li, Xiangyu Kong, Junqi Wang, Bangcheng Yang, Pring Wong, Yifan Zhong, Xiaoyuan Zhang, Zhaowei Zhang, Nian Liu, Yaodong Yang, Song-Chun Zhu",
      "paper_url": "https://openreview.net/pdf?id=UBVNwD3hPN",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_5aT4ganOd98",
      "paper_id": "5aT4ganOd98",
      "title": "CLARE: Conservative Model-Based Reward Learning for Offline Inverse Reinforcement Learning",
      "authors": "Sheng Yue, Guanbo Wang, Wei Shao, Zhaofeng Zhang, Sen Lin, Ju Ren, Junshan Zhang",
      "paper_url": "https://openreview.net/pdf/ab0104788311808f8c526bb4a5471ed9eb68e476.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_Diq6urt3lS",
      "paper_id": "Diq6urt3lS",
      "title": "Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform",
      "authors": "Shengyi Huang, Jiayi Weng, Rujikorn Charakorn, Min Lin, Zhongwen Xu, Santiago Ontanon",
      "paper_url": "https://openreview.net/pdf?id=Diq6urt3lS",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_qg5JENs0N4",
      "paper_id": "qg5JENs0N4",
      "title": "Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.",
      "authors": "Raj Ghugare, Matthieu Geist, Glen Berseth, Benjamin Eysenbach",
      "paper_url": "https://openreview.net/pdf?id=qg5JENs0N4",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_5o9JJJPPm6",
      "paper_id": "5o9JJJPPm6",
      "title": "ComaDICE: Offline Cooperative Multi-Agent Reinforcement Learning with Stationary Distribution Shift Regularization",
      "authors": "The Viet Bui, Thanh Hong Nguyen, Tien Anh Mai",
      "paper_url": "https://openreview.net/pdf?id=5o9JJJPPm6",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_qpsl2dR9twy",
      "paper_id": "qpsl2dR9twy",
      "title": "Communication in Multi-Agent Reinforcement Learning: Intention Sharing",
      "authors": "Woojun Kim, Jongeui Park, Youngchul Sung",
      "paper_url": "https://openreview.net/pdf/8ba121ac29f04d881d760a1f3b9fd0349bb591a2.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_DrtSx1z40Ib",
      "paper_id": "DrtSx1z40Ib",
      "title": "Composing Task Knowledge With Modular Successor Feature Approximators",
      "authors": "Wilka Torrico Carvalho, Angelos Filos, Richard Lewis, Honglak Lee, Satinder Singh",
      "paper_url": "https://openreview.net/pdf/f6e1ffd51a2415a8b0d1b98c2fabdf7bc677dfeb.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_HRkyLbBRHI",
      "paper_id": "HRkyLbBRHI",
      "title": "Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning",
      "authors": "Yeda Song, Dongwook Lee, Gunhee Kim",
      "paper_url": "https://openreview.net/pdf?id=HRkyLbBRHI",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_PVJ6j87gOHz",
      "paper_id": "PVJ6j87gOHz",
      "title": "CoMPS: Continual Meta Policy Search",
      "authors": "Glen Berseth, Zhiwei Zhang, Grace Zhang, Chelsea Finn, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/3ca19a998e5306a18adb13bd58c7b521611ff1f2.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_hyfe5q5TD0",
      "paper_id": "hyfe5q5TD0",
      "title": "Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics",
      "authors": "Runzhe Wu, Ayush Sekhari, Akshay Krishnamurthy, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=hyfe5q5TD0",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_Zeb5mTuqT5",
      "paper_id": "Zeb5mTuqT5",
      "title": "Confidence-Conditioned Value Functions for Offline Reinforcement Learning",
      "authors": "Joey Hong, Aviral Kumar, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/83d1be96a20a4accfffcc8dd593c0f0a3c5b5776.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_Ym2RNPX6la",
      "paper_id": "Ym2RNPX6la",
      "title": "Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback",
      "authors": "Michelle D Zhao, Henny Admoni, Reid Simmons, Aaditya Ramdas, Andrea Bajcsy",
      "paper_url": "https://openreview.net/pdf?id=Ym2RNPX6la",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_eo9dHwtTFt",
      "paper_id": "eo9dHwtTFt",
      "title": "Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning",
      "authors": "Harry Zhao, Safa Alver, Harm van Seijen, Romain Laroche, Doina Precup, Yoshua Bengio",
      "paper_url": "https://openreview.net/pdf?id=eo9dHwtTFt",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_dNqxZgyjcYA",
      "paper_id": "dNqxZgyjcYA",
      "title": "Conservative Bayesian Model-Based Value Expansion for Offline Policy Optimization",
      "authors": "Jihwan Jeong, Xiaoyu Wang, Michael Gimelfarb, Hyunwoo Kim, Baher abdulhai, Scott Sanner",
      "paper_url": "https://openreview.net/pdf/893cd27f203e1c4d6cd462eea1596210361ea469.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_iaO86DUuKi",
      "paper_id": "iaO86DUuKi",
      "title": "Conservative Safety Critics for Exploration",
      "authors": "Homanga Bharadhwaj, Aviral Kumar, Nicholas Rhinehart, Sergey Levine, Florian Shkurti, Animesh Garg",
      "paper_url": "https://openreview.net/pdf/31cfa17ce6b5a4dd1c7e3bf3ce4c025642d3199e.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_v8jdwkUNXb",
      "paper_id": "v8jdwkUNXb",
      "title": "Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning",
      "authors": "Zihan Ding, Chi Jin",
      "paper_url": "https://openreview.net/pdf?id=v8jdwkUNXb",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_PRZoSmCinhf",
      "paper_id": "PRZoSmCinhf",
      "title": "Constrained Policy Optimization via Bayesian World Models",
      "authors": "Yarden As, Ilnura Usmanova, Sebastian Curi, Andreas Krause",
      "paper_url": "https://openreview.net/pdf/649d2990399ada19288169dd3031ecbb109a02aa.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_nrRkAAAufl",
      "paper_id": "nrRkAAAufl",
      "title": "Constraint-Conditioned Actor-Critic for Offline Safe Reinforcement Learning",
      "authors": "Zijian Guo, Weichao Zhou, Shengao Wang, Wenchao Li",
      "paper_url": "https://openreview.net/pdf?id=nrRkAAAufl",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_7IWGzQ6gZ1D",
      "paper_id": "7IWGzQ6gZ1D",
      "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates",
      "authors": "Safa Alver, Doina Precup",
      "paper_url": "https://openreview.net/pdf/99cd11d061fb209a0dffb177bc34b326b5d4d7a6.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_hcQHRHKfN_",
      "paper_id": "hcQHRHKfN_",
      "title": "Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization",
      "authors": "Zihan Zhou, Wei Fu, Bingliang Zhang, Yi Wu",
      "paper_url": "https://openreview.net/pdf/a123c43ffc76a63f5bbe2eccdf4bba5a4233b9ed.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_lILEtkWOXD",
      "paper_id": "lILEtkWOXD",
      "title": "Contractive Dynamical Imitation Policies for Efficient Out-of-Sample Recovery",
      "authors": "Amin Abyaneh, Mahrokh Ghoddousi Boroujeni, Hsiu-Chin Lin, Giancarlo Ferrari-Trecate",
      "paper_url": "https://openreview.net/pdf?id=lILEtkWOXD",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_XMOaOigOQo",
      "paper_id": "XMOaOigOQo",
      "title": "ContraDiff: Planning Towards High Return States via Contrastive Learning",
      "authors": "Yixiang Shan, Zhengbang Zhu, Ting Long, Liang Qifan, Yi Chang, Weinan Zhang, Liang Yin",
      "paper_url": "https://openreview.net/pdf?id=XMOaOigOQo",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_qda7-sVg84",
      "paper_id": "qda7-sVg84",
      "title": "Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning",
      "authors": "Rishabh Agarwal, Marlos C. Machado, Pablo Samuel Castro, Marc G Bellemare",
      "paper_url": "https://openreview.net/pdf/18d8a7a260105accf754ef2ec331bcf48e817b1a.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_Ud3DSz72nYR",
      "paper_id": "Ud3DSz72nYR",
      "title": "Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions",
      "authors": "Zhengxian Lin, Kin-Ho Lam, Alan Fern",
      "paper_url": "https://openreview.net/pdf/0b44de227203c9a6da82618d99fd47af97f88da6.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_iX1RjVQODj",
      "paper_id": "iX1RjVQODj",
      "title": "Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning",
      "authors": "Joey Hejna, Rafael Rafailov, Harshit Sikchi, Chelsea Finn, Scott Niekum, W. Bradley Knox, Dorsa Sadigh",
      "paper_url": "https://openreview.net/pdf?id=iX1RjVQODj",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_dgd4EJqsbW5",
      "paper_id": "dgd4EJqsbW5",
      "title": "Control-Aware Representations for Model-based Reinforcement Learning",
      "authors": "Brandon Cui, Yinlam Chow, Mohammad Ghavamzadeh",
      "paper_url": "https://openreview.net/pdf/f0d80d862dab33f2ed69b44a0f14fda119006af8.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_ERce2rgMQC",
      "paper_id": "ERce2rgMQC",
      "title": "Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements",
      "authors": "Jingyu Zhang, Ahmed Elgohary, Ahmed Magooda, Daniel Khashabi, Benjamin Van Durme",
      "paper_url": "https://openreview.net/pdf?id=ERce2rgMQC",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_OJm3HZuj4r7",
      "paper_id": "OJm3HZuj4r7",
      "title": "Convergent and Efficient Deep Q Learning Algorithm",
      "authors": "Zhikang T. Wang, Masahito Ueda",
      "paper_url": "https://openreview.net/pdf/d999c3cb704da4722ea5330b5dd48600eb9c4ef4.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_psh0oeMSBiF",
      "paper_id": "psh0oeMSBiF",
      "title": "COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks",
      "authors": "Fan Wu, Linyi Li, Huan Zhang, Bhavya Kailkhura, Krishnaram Kenthapadi, Ding Zhao, Bo Li",
      "paper_url": "https://openreview.net/pdf/0a24a116cb24a1e99cd715566dae243e36472472.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_jnFcKjtUPN",
      "paper_id": "jnFcKjtUPN",
      "title": "COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL",
      "authors": "Xiyao Wang, Ruijie Zheng, Yanchao Sun, Ruonan Jia, Wichayaporn Wongkamjan, Huazhe Xu, Furong Huang",
      "paper_url": "https://openreview.net/pdf?id=jnFcKjtUPN",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_FLA55mBee6Q",
      "paper_id": "FLA55mBee6Q",
      "title": "COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation",
      "authors": "Jongmin Lee, Cosmin Paduraru, Daniel J Mankowitz, Nicolas Heess, Doina Precup, Kee-Eung Kim, Arthur Guez",
      "paper_url": "https://openreview.net/pdf/072227698fafd08a9854a8816e3cc5d5a8eb5754.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_xvxPuCkCNPO",
      "paper_id": "xvxPuCkCNPO",
      "title": "Correcting experience replay for multi-agent communication",
      "authors": "Sanjeevan Ahilan, Peter Dayan",
      "paper_url": "https://openreview.net/pdf/85eff27bc850ea7f5ee060f1c1d0156c4703f81b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_86zAUE80pP",
      "paper_id": "86zAUE80pP",
      "title": "CPPO: Continual Learning for Reinforcement Learning with Human Feedback",
      "authors": "Han Zhang, Yu Lei, Lin Gui, Min Yang, Yulan He, Hui Wang, Ruifeng Xu",
      "paper_url": "https://openreview.net/pdf?id=86zAUE80pP",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_HOjLHrlZhmx",
      "paper_id": "HOjLHrlZhmx",
      "title": "CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing",
      "authors": "Fan Wu, Linyi Li, Zijian Huang, Yevgeniy Vorobeychik, Ding Zhao, Bo Li",
      "paper_url": "https://openreview.net/pdf/b79f87ced196c2a5a13ca10bae3d39a8924b08b8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_xP3cPq2hQC",
      "paper_id": "xP3cPq2hQC",
      "title": "Cross-Domain Imitation Learning via Optimal Transport",
      "authors": "Arnaud Fickinger, Samuel Cohen, Stuart Russell, Brandon Amos",
      "paper_url": "https://openreview.net/pdf/0e1aa9f9ddcbcd903dbecbe6f034779d158d2260.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_LRrbD8EZJl",
      "paper_id": "LRrbD8EZJl",
      "title": "Cross-Domain Offline Policy Adaptation with Optimal Transport and Dataset Constraint",
      "authors": "Jiafei Lyu, Mengbei Yan, Zhongjian Qiao, Runze Liu, Xiaoteng Ma, Deheng Ye, Jing-Wen Yang, Zongqing Lu, Xiu Li",
      "paper_url": "https://openreview.net/pdf?id=LRrbD8EZJl",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_XOh5x-vxsrV",
      "paper_id": "XOh5x-vxsrV",
      "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL",
      "authors": "Bogdan Mazoure, Ahmed M Ahmed, R Devon Hjelm, Andrey Kolobov, Patrick MacAlpine",
      "paper_url": "https://openreview.net/pdf/64c9cd96c4583a048d9effe87d02766bc94a2e07.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_PczQtTsTIX",
      "paper_id": "PczQtTsTIX",
      "title": "CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity",
      "authors": "Aditya Bhatt, Daniel Palenicek, Boris Belousov, Max Argus, Artemij Amiranashvili, Thomas Brox, Jan Peters",
      "paper_url": "https://openreview.net/pdf?id=PczQtTsTIX",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_qyTBxTztIpQ",
      "paper_id": "qyTBxTztIpQ",
      "title": "CrowdPlay: Crowdsourcing Human Demonstrations for Offline Learning",
      "authors": "Matthias Gerstgrasser, Rakshit Trivedi, David C. Parkes",
      "paper_url": "https://openreview.net/pdf/b52b98ab7e0985b4d419899df029ac52613153b4.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_9SDQB3b68K",
      "paper_id": "9SDQB3b68K",
      "title": "DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning",
      "authors": "Jinxin Liu, Zhang Hongyin, Donglin Wang",
      "paper_url": "https://openreview.net/pdf/b68b505b8daf0a76ad9d4d5e4cd43976ba9864db.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_W8xukd70cU",
      "paper_id": "W8xukd70cU",
      "title": "Data Center Cooling System Optimization Using Offline Reinforcement Learning",
      "authors": "Xianyuan Zhan, Xiangyu Zhu, Peng Cheng, Xiao Hu, Ziteng He, Hanfei Geng, Jichao Leng, Huiwen Zheng, Chenhui Liu, Tianshun Hong, Yan Liang, Yunxin Liu, Feng Zhao",
      "paper_url": "https://openreview.net/pdf?id=W8xukd70cU",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_uCQfPZwRaUu",
      "paper_id": "uCQfPZwRaUu",
      "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations",
      "authors": "Max Schwarzer, Ankesh Anand, Rishab Goel, R Devon Hjelm, Aaron Courville, Philip Bachman",
      "paper_url": "https://openreview.net/pdf/1332dd3bfd157968abcdfda3acf4d4a7499d6143.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_00SnKBGTsz",
      "paper_id": "00SnKBGTsz",
      "title": "DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback",
      "authors": "Zaid Khan, Elias Stengel-Eskin, Jaemin Cho, Mohit Bansal",
      "paper_url": "https://openreview.net/pdf?id=00SnKBGTsz",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_XHUxf5aRB3s",
      "paper_id": "XHUxf5aRB3s",
      "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
      "authors": "Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Hongyuan Zha",
      "paper_url": "https://openreview.net/pdf/533ea53e5b32c81e14b06b4528f54a68836c63a0.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_NmZXv4467ai",
      "paper_id": "NmZXv4467ai",
      "title": "Decision Transformer under Random Frame Dropping",
      "authors": "Kaizhe Hu, Ray Chen Zheng, Yang Gao, Huazhe Xu",
      "paper_url": "https://openreview.net/pdf/40b5d8cc3e6627b100c8764c3b83c1a43756e10f.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_UaMgmoKEBj",
      "paper_id": "UaMgmoKEBj",
      "title": "Decoupling regularization from the action space",
      "authors": "Sobhan Mohammadpour, Emma Frejinger, Pierre-Luc Bacon",
      "paper_url": "https://openreview.net/pdf?id=UaMgmoKEBj",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_0WVNuEnqVu",
      "paper_id": "0WVNuEnqVu",
      "title": "Deep Reinforcement Learning for Cost-Effective Medical Diagnosis",
      "authors": "Zheng Yu, Yikuan Li, Joseph Chahn Kim, Kaixuan Huang, Yuan Luo, Mengdi Wang",
      "paper_url": "https://openreview.net/pdf/97d4ec3502e11b43bdc708cf3305416092c7863c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_eMP1j9efXtX",
      "paper_id": "eMP1j9efXtX",
      "title": "DeepAveragers: Offline Reinforcement Learning By Solving Derived Non-Parametric MDPs",
      "authors": "Aayam Kumar Shrestha, Stefan Lee, Prasad Tadepalli, Alan Fern",
      "paper_url": "https://openreview.net/pdf/41ec2c7a3d80d8e07956f446e858586b83aa7620.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_9pW2J49flQ",
      "paper_id": "9pW2J49flQ",
      "title": "DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL",
      "authors": "Mathias Jackermeier, Alessandro Abate",
      "paper_url": "https://openreview.net/pdf?id=9pW2J49flQ",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_lUYY2qsRTI",
      "paper_id": "lUYY2qsRTI",
      "title": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding",
      "authors": "Alizée Pace, Hugo Yèche, Bernhard Schölkopf, Gunnar Ratsch, Guy Tennenholtz",
      "paper_url": "https://openreview.net/pdf?id=lUYY2qsRTI",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_BrPdX1bDZkQ",
      "paper_id": "BrPdX1bDZkQ",
      "title": "DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations",
      "authors": "Geon-Hyeong Kim, Seokin Seo, Jongmin Lee, Wonseok Jeon, HyeongJoo Hwang, Hongseok Yang, Kee-Eung Kim",
      "paper_url": "https://openreview.net/pdf/e5325598f049024b1d7f5b5d86157b8d521d2547.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_lF2aip4Scn",
      "paper_id": "lF2aip4Scn",
      "title": "Demonstration-Regularized RL",
      "authors": "Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Eric Moulines, Alexey Naumov, Pierre Perrault, Michal Valko, Pierre Menard",
      "paper_url": "https://openreview.net/pdf?id=lF2aip4Scn",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_RDSj6S8WJe",
      "paper_id": "RDSj6S8WJe",
      "title": "Demystifying Linear MDPs and Novel Dynamics Aggregation Framework",
      "authors": "Joongkyu Lee, Min-hwan Oh",
      "paper_url": "https://openreview.net/pdf?id=RDSj6S8WJe",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_3hGNqpI4WS",
      "paper_id": "3hGNqpI4WS",
      "title": "Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization",
      "authors": "Tatsuya Matsushima, Hiroki Furuta, Yutaka Matsuo, Ofir Nachum, Shixiang Gu",
      "paper_url": "https://openreview.net/pdf/b73e1d0a56094306542cc2020c438a4e4942e58f.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_qYZD-AO1Vn",
      "paper_id": "qYZD-AO1Vn",
      "title": "Differentiable Trust Region Layers for Deep Reinforcement Learning",
      "authors": "Fabian Otto, Philipp Becker, Vien Anh Ngo, Hanna Carolin Maria Ziesche, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf/16d7f0bd8f02047e8ca8dbcf7a7f000f5d685020.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_kWRKNDU6uN",
      "paper_id": "kWRKNDU6uN",
      "title": "Diffusing States and Matching Scores: A New Framework for Imitation Learning",
      "authors": "Runzhe Wu, Yiding Chen, Gokul Swamy, Kianté Brantley, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=kWRKNDU6uN",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_ldVkAO09Km",
      "paper_id": "ldVkAO09Km",
      "title": "Diffusion Actor-Critic: Formulating Constrained Policy Iteration as Diffusion Noise Regression for Offline Reinforcement Learning",
      "authors": "Linjiajie Fang, Ruoxue Liu, Jing Zhang, Wenjia Wang, Bingyi Jing",
      "paper_url": "https://openreview.net/pdf?id=ldVkAO09Km",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_AHvFDPi-FA",
      "paper_id": "AHvFDPi-FA",
      "title": "Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning",
      "authors": "Zhendong Wang, Jonathan J Hunt, Mingyuan Zhou",
      "paper_url": "https://openreview.net/pdf/a55a26f03a11dcb7991b40527008d900c4a75044.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_mEpqHvbD2h",
      "paper_id": "mEpqHvbD2h",
      "title": "Diffusion Policy Policy Optimization",
      "authors": "Allen Z. Ren, Justin Lidard, Lars Lien Ankile, Anthony Simeonov, Pulkit Agrawal, Anirudha Majumdar, Benjamin Burchfiel, Hongkai Dai, Max Simchowitz",
      "paper_url": "https://openreview.net/pdf?id=mEpqHvbD2h",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_CjfQssZtAb",
      "paper_id": "CjfQssZtAb",
      "title": "Digi-Q: Learning VLM Q-Value Functions for Training Device-Control Agents",
      "authors": "Hao Bai, Yifei Zhou, Li Erran Li, Sergey Levine, Aviral Kumar",
      "paper_url": "https://openreview.net/pdf?id=CjfQssZtAb",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_H4Ncs5jhTCu",
      "paper_id": "H4Ncs5jhTCu",
      "title": "Diminishing Return of Value Expansion Methods in Model-Based Reinforcement Learning",
      "authors": "Daniel Palenicek, Michael Lutter, Joao Carvalho, Jan Peters",
      "paper_url": "https://openreview.net/pdf/8b53504b104f38c8d1f9cc40263dff77628eedee.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_25kzAhUB1lz",
      "paper_id": "25kzAhUB1lz",
      "title": "Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching",
      "authors": "Pierre-Alexandre Kamienny, Jean Tarbouriech, sylvain lamprier, Alessandro Lazaric, Ludovic Denoyer",
      "paper_url": "https://openreview.net/pdf/cc127fb35d524312500353fa6195db8fc4418285.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_PUkhWz65dy5",
      "paper_id": "PUkhWz65dy5",
      "title": "Discovering a set of policies for the worst case reward",
      "authors": "Tom Zahavy, Andre Barreto, Daniel J Mankowitz, Shaobo Hou, Brendan O'Donoghue, Iurii Kemaev, Satinder Singh",
      "paper_url": "https://openreview.net/pdf/7a579d5544cfac14ef616dd30d162838a87cf7e4.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_lvRTC669EY_",
      "paper_id": "lvRTC669EY_",
      "title": "Discovering Diverse Multi-Agent Strategic Behavior via Reward Randomization",
      "authors": "Zhenggang Tang, Chao Yu, Boyuan Chen, Huazhe Xu, Xiaolong Wang, Fei Fang, Simon Shaolei Du, Yu Wang, Yi Wu",
      "paper_url": "https://openreview.net/pdf/2062fdf1e8a1dbc3c1d293239ad291f853463ba8.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_53FyUAdP7d",
      "paper_id": "53FyUAdP7d",
      "title": "Discovering Generalizable Multi-agent Coordination Skills from Multi-task Offline Data",
      "authors": "Fuxiang Zhang, Chengxing Jia, Yi-Chen Li, Lei Yuan, Yang Yu, Zongzhang Zhang",
      "paper_url": "https://openreview.net/pdf/d365ffe4e9b099c3b0b62134ead3eaeba4105768.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_kjkdzBW3b8p",
      "paper_id": "kjkdzBW3b8p",
      "title": "Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality",
      "authors": "Tom Zahavy, Yannick Schroecker, Feryal Behbahani, Kate Baumli, Sebastian Flennerhag, Shaobo Hou, Satinder Singh",
      "paper_url": "https://openreview.net/pdf/6afcd9948e9a8f36dcac913dfe67d5311fc6c5df.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_MJJcs3zbmi",
      "paper_id": "MJJcs3zbmi",
      "title": "Discovering Temporally-Aware Reinforcement Learning Algorithms",
      "authors": "Matthew Thomas Jackson, Chris Lu, Louis Kirsch, Robert Tjarko Lange, Shimon Whiteson, Jakob Nicolaus Foerster",
      "paper_url": "https://openreview.net/pdf?id=MJJcs3zbmi",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_lfRYzd8ady",
      "paper_id": "lfRYzd8ady",
      "title": "Discrete Codebook World Models for Continuous Control",
      "authors": "Aidan Scannell, Mohammadreza Nakhaeinezhadfard, Kalle Kujanpää, Yi Zhao, Kevin Sebastian Luck, Arno Solin, Joni Pajarinen",
      "paper_url": "https://openreview.net/pdf?id=lfRYzd8ady",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_1X1R7P6yzt",
      "paper_id": "1X1R7P6yzt",
      "title": "Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control",
      "authors": "Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan",
      "paper_url": "https://openreview.net/pdf?id=1X1R7P6yzt",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_BfUugGfBE5",
      "paper_id": "BfUugGfBE5",
      "title": "Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning",
      "authors": "Jaehyeon Son, Soochan Lee, Gunhee Kim",
      "paper_url": "https://openreview.net/pdf?id=BfUugGfBE5",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_LGkmUauBUL",
      "paper_id": "LGkmUauBUL",
      "title": "Distributional Meta-Gradient Reinforcement Learning",
      "authors": "Haiyan Yin, Shuicheng YAN, Zhongwen Xu",
      "paper_url": "https://openreview.net/pdf/fbd330b31dd69cf244b53291887b18ab9c2989b8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_C8Ltz08PtBp",
      "paper_id": "C8Ltz08PtBp",
      "title": "Distributional Reinforcement Learning with Monotonic Splines",
      "authors": "Yudong Luo, Guiliang Liu, Haonan Duan, Oliver Schulte, Pascal Poupart",
      "paper_url": "https://openreview.net/pdf/376a906de470631ee01098610befe6addc3d72de.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_LPG8pPSfQD",
      "paper_id": "LPG8pPSfQD",
      "title": "DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agent",
      "authors": "Taiyi Wang, Zhihao Wu, Jianheng Liu, Jianye HAO, Jun Wang, Kun Shao",
      "paper_url": "https://openreview.net/pdf?id=LPG8pPSfQD",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_6Ai8SuDsh3",
      "paper_id": "6Ai8SuDsh3",
      "title": "Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning",
      "authors": "Hanlin Yang, Jian Yao, Weiming Liu, Qing Wang, Hanmin Qin, Kong hansheng, Kirk Tang, Jiechao Xiong, Chao Yu, Kai Li, Junliang Xing, Hongwu Chen, Juchao Zhuo, QIANG FU, Yang Wei, Haobo Fu",
      "paper_url": "https://openreview.net/pdf?id=6Ai8SuDsh3",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_qe49ybvvPs",
      "paper_id": "qe49ybvvPs",
      "title": "Diverse Projection Ensembles for Distributional Reinforcement Learning",
      "authors": "Moritz Akiya Zanger, Wendelin Boehmer, Matthijs T. J. Spaan",
      "paper_url": "https://openreview.net/pdf?id=qe49ybvvPs",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_ZULjcYLWKe",
      "paper_id": "ZULjcYLWKe",
      "title": "DMBP: Diffusion model-based predictor for robust offline reinforcement learning against state observation perturbations",
      "authors": "Zhihe YANG, Yunjian Xu",
      "paper_url": "https://openreview.net/pdf?id=ZULjcYLWKe",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_MYEap_OcQI",
      "paper_id": "MYEap_OcQI",
      "title": "Does Zero-Shot Reinforcement Learning Exist?",
      "authors": "Ahmed Touati, Jérémy Rapin, Yann Ollivier",
      "paper_url": "https://openreview.net/pdf/63a8b5a5af811abc3b027de6cccef1854dbedc3c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_OTFKVkxSlL",
      "paper_id": "OTFKVkxSlL",
      "title": "DoF: A Diffusion Factorization Framework for Offline Multi-Agent Reinforcement Learning",
      "authors": "Chao Li, Ziwei Deng, Chenxing Lin, Wenqi Chen, Yongquan Fu, Weiquan Liu, Chenglu Wen, Cheng Wang, Siqi Shen",
      "paper_url": "https://openreview.net/pdf?id=OTFKVkxSlL",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_GXtmuiVrOM",
      "paper_id": "GXtmuiVrOM",
      "title": "Domain Randomization via Entropy Maximization",
      "authors": "Gabriele Tiboni, Pascal Klink, Jan Peters, Tatiana Tommasi, Carlo D'Eramo, Georgia Chalvatzaki",
      "paper_url": "https://openreview.net/pdf?id=GXtmuiVrOM",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_QubpWYfdNry",
      "paper_id": "QubpWYfdNry",
      "title": "Domain-Robust Visual Imitation Learning with Mutual Information Constraints",
      "authors": "Edoardo Cetin, Oya Celiktutan",
      "paper_url": "https://openreview.net/pdf/ffeade3d551ddc81dea27db706160b3bc6510cec.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_6FqKiVAdI3Y",
      "paper_id": "6FqKiVAdI3Y",
      "title": "DOP: Off-Policy Multi-Agent Decomposed Policy Gradients",
      "authors": "Yihan Wang, Beining Han, Tonghan Wang, Heng Dong, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/3f81a57de106341a8eae39f9a550980090df7241.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_60GeEoG5kD",
      "paper_id": "60GeEoG5kD",
      "title": "Doubly Optimal Policy Evaluation for Reinforcement Learning",
      "authors": "Shuze Liu, Claire Chen, Shangtong Zhang",
      "paper_url": "https://openreview.net/pdf?id=60GeEoG5kD",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_POvMvLi91f",
      "paper_id": "POvMvLi91f",
      "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
      "authors": "Aviral Kumar, Rishabh Agarwal, Tengyu Ma, Aaron Courville, George Tucker, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/4682f104a198c9218cf0cdcdbdea5d55d4cf56d8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_7XIkRgYjK3",
      "paper_id": "7XIkRgYjK3",
      "title": "Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient",
      "authors": "Wenlong Wang, Ivana Dusparic, Yucheng Shi, Ke Zhang, Vinny Cahill",
      "paper_url": "https://openreview.net/pdf?id=7XIkRgYjK3",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_GruDNzQ4ux",
      "paper_id": "GruDNzQ4ux",
      "title": "DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing",
      "authors": "Vint Lee, Pieter Abbeel, Youngwoon Lee",
      "paper_url": "https://openreview.net/pdf?id=GruDNzQ4ux",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_MSe8YFbhUE",
      "paper_id": "MSe8YFbhUE",
      "title": "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization",
      "authors": "Guowei Xu, Ruijie Zheng, Yongyuan Liang, Xiyao Wang, Zhecheng Yuan, Tianying Ji, Yu Luo, Xiaoyu Liu, Jiaxin Yuan, Pu Hua, Shuzhen Li, Yanjie Ze, Hal Daumé III, Furong Huang, Huazhe Xu",
      "paper_url": "https://openreview.net/pdf?id=MSe8YFbhUE",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_xCVJMsPv3RT",
      "paper_id": "xCVJMsPv3RT",
      "title": "Dropout Q-Functions for Doubly Efficient Reinforcement Learning",
      "authors": "Takuya Hiraoka, Takahisa Imagawa, Taisei Hashimoto, Takashi Onishi, Yoshimasa Tsuruoka",
      "paper_url": "https://openreview.net/pdf/b31fb60261f2746e9fc9ccca341e609e0b152e43.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_6CZ50WgfCG",
      "paper_id": "6CZ50WgfCG",
      "title": "DrS: Learning Reusable Dense Rewards for Multi-Stage Tasks",
      "authors": "Tongzhou Mu, Minghua Liu, Hao Su",
      "paper_url": "https://openreview.net/pdf?id=6CZ50WgfCG",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_xt9Bu66rqv",
      "paper_id": "xt9Bu66rqv",
      "title": "Dual RL: Unification and New Methods for Reinforcement and Imitation Learning",
      "authors": "Harshit Sikchi, Qinqing Zheng, Amy Zhang, Scott Niekum",
      "paper_url": "https://openreview.net/pdf?id=xt9Bu66rqv",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_8egnwady4b",
      "paper_id": "8egnwady4b",
      "title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment",
      "authors": "Jinwoo Choi, Seung-Woo Seo",
      "paper_url": "https://openreview.net/pdf?id=8egnwady4b",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_80wh3jjCZf",
      "paper_id": "80wh3jjCZf",
      "title": "Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces",
      "authors": "Fabian Akkerman, Julius Luy, Wouter van Heeswijk, Maximilian Schiffer",
      "paper_url": "https://openreview.net/pdf?id=80wh3jjCZf",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_ZIkHSXzd9O7",
      "paper_id": "ZIkHSXzd9O7",
      "title": "Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting",
      "authors": "Nicolai Dorka, Tim Welschehold, Wolfram Burgard",
      "paper_url": "https://openreview.net/pdf/148ac4c92f161ae4747fc29e9fbe9b7170b7b947.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_CALFyKVs87",
      "paper_id": "CALFyKVs87",
      "title": "Dynamics-Aware Comparison of Learned Reward Functions",
      "authors": "Blake Wulfe, Logan Michael Ellis, Jean Mercat, Rowan Thomas McAllister, Adrien Gaidon",
      "paper_url": "https://openreview.net/pdf/14a7ecb3498b71a8fba347a8d3438e054084f561.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_AgMpK7z4bz",
      "paper_id": "AgMpK7z4bz",
      "title": "Efficient Action-Constrained Reinforcement Learning via Acceptance-Rejection Method and Augmented MDPs",
      "authors": "Wei Hung, Shao-Hua Sun, Ping-Chun Hsieh",
      "paper_url": "https://openreview.net/pdf?id=AgMpK7z4bz",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_GFgn2LprFR",
      "paper_id": "GFgn2LprFR",
      "title": "Efficient Active Imitation Learning with Random Network Distillation",
      "authors": "Emilien Biré, Anthony Kobanda, Ludovic Denoyer, Rémy Portelas",
      "paper_url": "https://openreview.net/pdf?id=GFgn2LprFR",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_UENQuayzr1",
      "paper_id": "UENQuayzr1",
      "title": "Efficient Cross-Episode Meta-RL",
      "authors": "Gresa Shala, André Biedenkapp, Pierre Krack, Florian Walter, Josif Grabocka",
      "paper_url": "https://openreview.net/pdf?id=UENQuayzr1",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_14-kr46GvP-",
      "paper_id": "14-kr46GvP-",
      "title": "Efficient Deep Reinforcement Learning Requires Regulating Overfitting",
      "authors": "Qiyang Li, Aviral Kumar, Ilya Kostrikov, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/971c9a6302832063d4fc1590b444b3ccd8f33e44.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_nDmwloEl3N",
      "paper_id": "nDmwloEl3N",
      "title": "Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning",
      "authors": "Moritz Reuss, Jyothish Pari, Pulkit Agrawal, Rudolf Lioutikov",
      "paper_url": "https://openreview.net/pdf?id=nDmwloEl3N",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_fDGPIuCdGi",
      "paper_id": "fDGPIuCdGi",
      "title": "Efficient Discovery of Pareto Front for Multi-Objective Reinforcement Learning",
      "authors": "Ruohong Liu, Yuxin Pan, Linjie Xu, Lei Song, Pengcheng You, Yize Chen, Jiang Bian",
      "paper_url": "https://openreview.net/pdf?id=fDGPIuCdGi",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_u2YNJPcQlwq",
      "paper_id": "u2YNJPcQlwq",
      "title": "Efficient Empowerment Estimation for Unsupervised Stabilization",
      "authors": "Ruihan Zhao, Kevin Lu, Pieter Abbeel, Stas Tiomkin",
      "paper_url": "https://openreview.net/pdf/59dc834b878ff1144857f1787ea553243043395c.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_LjivA1SLZ6",
      "paper_id": "LjivA1SLZ6",
      "title": "Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning",
      "authors": "Hyungho Na, Yunkyeong Seo, Il-chul Moon",
      "paper_url": "https://openreview.net/pdf?id=LjivA1SLZ6",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_fn36V5qsCw",
      "paper_id": "fn36V5qsCw",
      "title": "Efficient Imitation under Misspecification",
      "authors": "Nicolas Espinosa-Dice, Sanjiban Choudhury, Wen Sun, Gokul Swamy",
      "paper_url": "https://openreview.net/pdf?id=fn36V5qsCw",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_JzvIWvC9MG",
      "paper_id": "JzvIWvC9MG",
      "title": "Efficient Inverse Multiagent Learning",
      "authors": "Denizalp Goktas, Amy Greenwald, Sadie Zhao, Alec Koppel, Sumitra Ganesh",
      "paper_url": "https://openreview.net/pdf?id=JzvIWvC9MG",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_0cgU-BZp2ky",
      "paper_id": "0cgU-BZp2ky",
      "title": "Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization",
      "authors": "Quanyi Li, Zhenghao Peng, Bolei Zhou",
      "paper_url": "https://openreview.net/pdf/c0b165aabfc0cf4dea07b0341e17033a3bc5722b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_Ian00SaFHg",
      "paper_id": "Ian00SaFHg",
      "title": "Efficient Model-Based Reinforcement Learning Through Optimistic Thompson Sampling",
      "authors": "Jasmine Bayrooti, Carl Henrik Ek, Amanda Prorok",
      "paper_url": "https://openreview.net/pdf?id=Ian00SaFHg",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_EpnZEzYDUT",
      "paper_id": "EpnZEzYDUT",
      "title": "Efficient Multi-agent Offline Coordination via Diffusion-based Trajectory Stitching",
      "authors": "Lei Yuan, Yuqi Bian, Lihe Li, Ziqian Zhang, Cong Guan, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=EpnZEzYDUT",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_CpnKq3UJwp",
      "paper_id": "CpnKq3UJwp",
      "title": "Efficient Multi-agent Reinforcement Learning by Planning",
      "authors": "Qihan Liu, Jianing Ye, Xiaoteng Ma, Jun Yang, Bin Liang, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf?id=CpnKq3UJwp",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_JDzTI9rKls",
      "paper_id": "JDzTI9rKls",
      "title": "Efficient Off-Policy Learning for High-Dimensional Action Spaces",
      "authors": "Fabian Otto, Philipp Becker, Vien Anh Ngo, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf?id=JDzTI9rKls",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_Yt-yM-JbYFO",
      "paper_id": "Yt-yM-JbYFO",
      "title": "Efficient Offline Policy Optimization with a Learned Model",
      "authors": "Zichen Liu, Siyi Li, Wee Sun Lee, Shuicheng YAN, Zhongwen Xu",
      "paper_url": "https://openreview.net/pdf/a81d03d3b79d745279c3247be0d1b9b248e37300.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_HN0CYZbAPw",
      "paper_id": "HN0CYZbAPw",
      "title": "Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data",
      "authors": "Zhiyuan Zhou, Andy Peng, Qiyang Li, Sergey Levine, Aviral Kumar",
      "paper_url": "https://openreview.net/pdf?id=HN0CYZbAPw",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_cA77NrVEuqn",
      "paper_id": "cA77NrVEuqn",
      "title": "Efficient Planning in a Compact Latent Action Space",
      "authors": "zhengyao jiang, Tianjun Zhang, Michael Janner, Yueying Li, Tim Rocktäschel, Edward Grefenstette, Yuandong Tian",
      "paper_url": "https://openreview.net/pdf/18c1efd356786f3071db813b03dac9cd5621a032.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_btpgDo4u4j",
      "paper_id": "btpgDo4u4j",
      "title": "Efficient Planning with Latent Diffusion",
      "authors": "Wenhao Li",
      "paper_url": "https://openreview.net/pdf?id=btpgDo4u4j",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_Dem5LyVk8R",
      "paper_id": "Dem5LyVk8R",
      "title": "Efficient Policy Evaluation with Safety Constraint for Reinforcement Learning",
      "authors": "Claire Chen, Shuze Liu, Shangtong Zhang",
      "paper_url": "https://openreview.net/pdf?id=Dem5LyVk8R",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_fmtSg8591Q",
      "paper_id": "fmtSg8591Q",
      "title": "Efficient Reinforcement Learning in Factored MDPs with Application to Constrained RL",
      "authors": "Xiaoyu Chen, Jiachen Hu, Lihong Li, Liwei Wang",
      "paper_url": "https://openreview.net/pdf/a8950d55072da9151823a07d4c8c83043c445db5.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_uR9LaO_QxF",
      "paper_id": "uR9LaO_QxF",
      "title": "Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation",
      "authors": "Emilio Parisotto, Russ Salakhutdinov",
      "paper_url": "https://openreview.net/pdf/2384835e520b07abfe36d0826a5cd6dc0673f653.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_OHgnfSrn2jv",
      "paper_id": "OHgnfSrn2jv",
      "title": "Efficient Wasserstein Natural Gradients for Reinforcement Learning",
      "authors": "Ted Moskovitz, Michael Arbel, Ferenc Huszar, Arthur Gretton",
      "paper_url": "https://openreview.net/pdf/1c8cd7b02df8016f8cf8a6a2e70844ad5ae87de9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_d8Q1mt2Ghw",
      "paper_id": "d8Q1mt2Ghw",
      "title": "Emergent Road Rules In Multi-Agent Driving Environments",
      "authors": "Avik Pal, Jonah Philion, Yuan-Hong Liao, Sanja Fidler",
      "paper_url": "https://openreview.net/pdf/858edcf2544391055e14f4c41482bcc25bb9ae3f.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_fXb9BbuyAD",
      "paper_id": "fXb9BbuyAD",
      "title": "Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference",
      "authors": "Matthew Riemer, Gopeshh Subbaraj, Glen Berseth, Irina Rish",
      "paper_url": "https://openreview.net/pdf?id=fXb9BbuyAD",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_HA0oLUvuGI",
      "paper_id": "HA0oLUvuGI",
      "title": "Energy-Weighted Flow Matching for Offline Reinforcement Learning",
      "authors": "Shiyuan Zhang, Weitong Zhang, Quanquan Gu",
      "paper_url": "https://openreview.net/pdf?id=HA0oLUvuGI",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_5lhWG3Hj2By",
      "paper_id": "5lhWG3Hj2By",
      "title": "Enforcing robust control guarantees within neural network policies",
      "authors": "Priya L. Donti, Melrose Roderick, Mahyar Fazlyab, J Zico Kolter",
      "paper_url": "https://openreview.net/pdf/c31f3f12091e950c7b2a58373e1af5225f1b5377.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_cR5GTis5II",
      "paper_id": "cR5GTis5II",
      "title": "eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels",
      "authors": "Alexander DeRieux, Walid Saad",
      "paper_url": "https://openreview.net/pdf?id=cR5GTis5II",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_FYZCHEtt6H0",
      "paper_id": "FYZCHEtt6H0",
      "title": "ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation",
      "authors": "Jianye HAO, Pengyi Li, Hongyao Tang, YAN ZHENG, Xian Fu, Zhaopeng Meng",
      "paper_url": "https://openreview.net/pdf/9b3a060321395c18a721125540f51db282b2e6a6.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_OheAR2xrtb",
      "paper_id": "OheAR2xrtb",
      "title": "ET-SEED: EFFICIENT TRAJECTORY-LEVEL SE(3) EQUIVARIANT DIFFUSION POLICY",
      "authors": "Chenrui Tie, Yue Chen, Ruihai Wu, Boxuan Dong, Zeyi Li, Chongkai Gao, Hao Dong",
      "paper_url": "https://openreview.net/pdf?id=OheAR2xrtb",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_xQAjSr64PTc",
      "paper_id": "xQAjSr64PTc",
      "title": "EUCLID: Towards Efficient Unsupervised Reinforcement Learning with Multi-choice Dynamics Model",
      "authors": "Yifu Yuan, Jianye HAO, Fei Ni, Yao Mu, YAN ZHENG, Yujing Hu, Jinyi Liu, Yingfeng Chen, Changjie Fan",
      "paper_url": "https://openreview.net/pdf/e0e5ffe815fc27390865398ac70e8e25250b12a7.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_SS8F6tFX3-",
      "paper_id": "SS8F6tFX3-",
      "title": "Evaluating Model-Based Planning and Planner Amortization for Continuous Control",
      "authors": "Arunkumar Byravan, Leonard Hasenclever, Piotr Trochim, Mehdi Mirza, Alessandro Davide Ialongo, Yuval Tassa, Jost Tobias Springenberg, Abbas Abdolmaleki, Nicolas Heess, Josh Merel, Martin Riedmiller",
      "paper_url": "https://openreview.net/pdf/ae6d13b114d9f64756fe8146f4c5b0e55037ad9a.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_74x5BXs4bWD",
      "paper_id": "74x5BXs4bWD",
      "title": "Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning",
      "authors": "Yutong Wang, Ke Xue, Chao Qian",
      "paper_url": "https://openreview.net/pdf/b887e71bcdd86242a6fbbc501be12552141c01ed.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_CBfYffLqWqb",
      "paper_id": "CBfYffLqWqb",
      "title": "Evolving Populations of Diverse RL Agents with MAP-Elites",
      "authors": "Thomas PIERROT, Arthur Flajolet",
      "paper_url": "https://openreview.net/pdf/7647093a5e985828f881513eb78bf7d36bde7a04.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_0XXpJ4OtjW",
      "paper_id": "0XXpJ4OtjW",
      "title": "Evolving Reinforcement Learning Algorithms",
      "authors": "John D Co-Reyes, Yingjie Miao, Daiyi Peng, Esteban Real, Quoc V Le, Sergey Levine, Honglak Lee, Aleksandra Faust",
      "paper_url": "https://openreview.net/pdf/78e8fae1b2cfbbae3e7010ca2f27649cb057ae84.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_GBIUbwW9D8",
      "paper_id": "GBIUbwW9D8",
      "title": "ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning",
      "authors": "Xiao Yu, Baolin Peng, Vineeth Vajipey, Hao Cheng, Michel Galley, Jianfeng Gao, Zhou Yu",
      "paper_url": "https://openreview.net/pdf?id=GBIUbwW9D8",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_unI5ucw_Jk",
      "paper_id": "unI5ucw_Jk",
      "title": "Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning",
      "authors": "Alihan Hüyük, Daniel Jarrett, Cem Tekin, Mihaela van der Schaar",
      "paper_url": "https://openreview.net/pdf/87d4ea3176fd5ca710f4f3d549c2f1c25b5898cf.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_5Egggz1q575",
      "paper_id": "5Egggz1q575",
      "title": "Explaining RL Decisions with Trajectories",
      "authors": "Shripad Vilasrao Deshmukh, Arpan Dasgupta, Balaji Krishnamurthy, Nan Jiang, Chirag Agarwal, Georgios Theocharous, Jayakumar Subramanian",
      "paper_url": "https://openreview.net/pdf/8c14263279e4c45dd0a74d7e52a0c6d707338882.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_M0xK8nPGvt",
      "paper_id": "M0xK8nPGvt",
      "title": "Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning",
      "authors": "Mirco Mutti, Riccardo De Santi, Marcello Restelli, Alexander Marx, Giorgia Ramponi",
      "paper_url": "https://openreview.net/pdf?id=M0xK8nPGvt",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_AOlm45AUVS",
      "paper_id": "AOlm45AUVS",
      "title": "Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank",
      "authors": "Wenhao Zhan, Scott Fujimoto, Zheqing Zhu, Jason D. Lee, Daniel Jiang, Yonathan Efroni",
      "paper_url": "https://openreview.net/pdf?id=AOlm45AUVS",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_CL3U0GxFRD",
      "paper_id": "CL3U0GxFRD",
      "title": "Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning",
      "authors": "Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang",
      "paper_url": "https://openreview.net/pdf?id=CL3U0GxFRD",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_Nc3TJqbcl3",
      "paper_id": "Nc3TJqbcl3",
      "title": "Extracting Strong Policies for Robotics Tasks from Zero-Order Trajectory Optimizers",
      "authors": "Cristina Pinneri, Shambhuraj Sawant, Sebastian Blaes, Georg Martius",
      "paper_url": "https://openreview.net/pdf/1e36a9b55c2b184bab1395be47101e4beb882f41.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_SJ0Lde3tRL",
      "paper_id": "SJ0Lde3tRL",
      "title": "Extreme Q-Learning: MaxEnt RL without Entropy",
      "authors": "Divyansh Garg, Joey Hejna, Matthieu Geist, Stefano Ermon",
      "paper_url": "https://openreview.net/pdf/fe4a8907cc4cf7607754d21d04e1da5914902db2.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_VVdmjgu7pKM",
      "paper_id": "VVdmjgu7pKM",
      "title": "Factorizing Declarative and Procedural Knowledge in Structured, Dynamical Environments",
      "authors": "Anirudh Goyal, Alex Lamb, Phanideep Gampa, Philippe Beaudoin, Charles Blundell, Sergey Levine, Yoshua Bengio, Michael Curtis Mozer",
      "paper_url": "https://openreview.net/pdf/927b511da0f53c9d48b5dbe33f31772d15ec97ca.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_7JsGYvjE88d",
      "paper_id": "7JsGYvjE88d",
      "title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search",
      "authors": "Michał Zawalski, Michał Tyrolski, Konrad Czechowski, Tomasz Odrzygóźdź, Damian Stachura, Piotr Piękos, Yuhuai Wu, Łukasz Kuciński, Piotr Miłoś",
      "paper_url": "https://openreview.net/pdf/361fb386c64c303b0467dd1fb8d3946766d58d4c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_Lc28QAB4ypz",
      "paper_id": "Lc28QAB4ypz",
      "title": "Fast And Slow Learning Of Recurrent Independent Mechanisms",
      "authors": "Kanika Madan, Nan Rosemary Ke, Anirudh Goyal, Bernhard Schölkopf, Yoshua Bengio",
      "paper_url": "https://openreview.net/pdf/023176cca43806a7d1f2ee58f5d0b4940b4331b2.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_qnWtw3l0jb",
      "paper_id": "qnWtw3l0jb",
      "title": "Fast Imitation via Behavior Foundation Models",
      "authors": "Matteo Pirotta, Andrea Tirinzoni, Ahmed Touati, Alessandro Lazaric, Yann Ollivier",
      "paper_url": "https://openreview.net/pdf?id=qnWtw3l0jb",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_LZIOBA2oDU",
      "paper_id": "LZIOBA2oDU",
      "title": "Fast Value Tracking for Deep Reinforcement Learning",
      "authors": "Frank Shih, Faming Liang",
      "paper_url": "https://openreview.net/pdf?id=LZIOBA2oDU",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_SRjzerUpB2",
      "paper_id": "SRjzerUpB2",
      "title": "Fat-to-Thin Policy Optimization: Offline Reinforcement Learning with Sparse Policies",
      "authors": "Lingwei Zhu, Han Wang, Yukie Nagai",
      "paper_url": "https://openreview.net/pdf?id=SRjzerUpB2",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_zqtql1YmlS",
      "paper_id": "zqtql1YmlS",
      "title": "Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset",
      "authors": "Yiqin Yang, Quanwei Wang, Chenghao Li, Hao Hu, Chengjie Wu, Yuhua Jiang, Dianyu Zhong, Ziyou Zhang, Qianchuan Zhao, Chongjie Zhang, Bo XU",
      "paper_url": "https://openreview.net/pdf?id=zqtql1YmlS",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_04pGUg0-pdZ",
      "paper_id": "04pGUg0-pdZ",
      "title": "Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward",
      "authors": "FNU Hairi, Jia Liu, Songtao Lu",
      "paper_url": "https://openreview.net/pdf/88771b44b2b7e3d534226c24b2a2e7d9739fc960.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_4OaO3GjP7k",
      "paper_id": "4OaO3GjP7k",
      "title": "Flat Reward in Policy Parameter Space Implies Robust Reinforcement Learning",
      "authors": "Hyun Kyu Lee, Sung Whan Yoon",
      "paper_url": "https://openreview.net/pdf?id=4OaO3GjP7k",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_MRYyOaNxh3",
      "paper_id": "MRYyOaNxh3",
      "title": "FlickerFusion: Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning",
      "authors": "Woosung Koh, Wonbeen Oh, Siyeol Kim, Suhin Shin, Hyeongjin Kim, Jaein Jang, Junghyun Lee, Se-Young Yun",
      "paper_url": "https://openreview.net/pdf?id=MRYyOaNxh3",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_EG68RSznLT",
      "paper_id": "EG68RSznLT",
      "title": "Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation",
      "authors": "Zhilong Zhang, Yihao Sun, Junyin Ye, Tian-Shuo Liu, Jiaji Zhang, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=EG68RSznLT",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_8cpHIfgY4Dj",
      "paper_id": "8cpHIfgY4Dj",
      "title": "FOCAL: Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization",
      "authors": "Lanqing Li, Rui Yang, Dijun Luo",
      "paper_url": "https://openreview.net/pdf/44984a3c82f19e6fc4db9819ab9140e0cc3ca7e0.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_dbuFJg7eaw",
      "paper_id": "dbuFJg7eaw",
      "title": "FOSP: Fine-tuning Offline Safe Policy through World Models",
      "authors": "Chenyang Cao, Yucheng Xin, Silang Wu, Longxiang He, Zichen Yan, Junbo Tan, Xueqian Wang",
      "paper_url": "https://openreview.net/pdf?id=dbuFJg7eaw",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_7zY781bMDO",
      "paper_id": "7zY781bMDO",
      "title": "Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning",
      "authors": "Zhaoyi Zhou, Chuning Zhu, Runlong Zhou, Qiwen Cui, Abhishek Gupta, Simon Shaolei Du",
      "paper_url": "https://openreview.net/pdf?id=7zY781bMDO",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_zElset1Klrp",
      "paper_id": "zElset1Klrp",
      "title": "Fuzzy Tiling Activations: A Simple Approach to Learning Sparse Representations Online",
      "authors": "Yangchen Pan, Kirby Banman, Martha White",
      "paper_url": "https://openreview.net/pdf/37f746394b25e91e61274da8ebafc304ae3d32a0.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_wZWTHU7AsQ",
      "paper_id": "wZWTHU7AsQ",
      "title": "Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations",
      "authors": "Yongyuan Liang, Yanchao Sun, Ruijie Zheng, Xiangyu Liu, Benjamin Eysenbach, Tuomas Sandholm, Furong Huang, Stephen Marcus McAleer",
      "paper_url": "https://openreview.net/pdf?id=wZWTHU7AsQ",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_6tyPSkshtF",
      "paper_id": "6tyPSkshtF",
      "title": "Gap-Dependent Bounds for Q-Learning using Reference-Advantage Decomposition",
      "authors": "Zhong Zheng, Haochen Zhang, Lingzhou Xue",
      "paper_url": "https://openreview.net/pdf?id=6tyPSkshtF",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_r8H7xhYPwz",
      "paper_id": "r8H7xhYPwz",
      "title": "Gated Delta Networks: Improving Mamba2 with Delta Rule",
      "authors": "Songlin Yang, Jan Kautz, Ali Hatamizadeh",
      "paper_url": "https://openreview.net/pdf?id=r8H7xhYPwz",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_ZOcX-eybqoL",
      "paper_id": "ZOcX-eybqoL",
      "title": "Generalisation in Lifelong Reinforcement Learning through Logical Composition",
      "authors": "Geraud Nangue Tasse, Steven James, Benjamin Rosman",
      "paper_url": "https://openreview.net/pdf/89cb79a9b9bb6a9a833a7a8ae73c8c5a87792970.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_Q7EjHroO1w",
      "paper_id": "Q7EjHroO1w",
      "title": "Generalized Behavior Learning from Diverse Demonstrations",
      "authors": "Varshith Sreeramdass, Rohan R Paleja, Letian Chen, Sanne van Waveren, Matthew Gombolay",
      "paper_url": "https://openreview.net/pdf?id=Q7EjHroO1w",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_CAjxVodl_v",
      "paper_id": "CAjxVodl_v",
      "title": "Generalized Decision Transformer for Offline Hindsight Information Matching",
      "authors": "Hiroki Furuta, Yutaka Matsuo, Shixiang Shane Gu",
      "paper_url": "https://openreview.net/pdf/86d7058e78842b10462a9f0e0311ca3040adfe97.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_csukJcpYDe",
      "paper_id": "csukJcpYDe",
      "title": "Generalized Policy Iteration using Tensor Approximation for Hybrid Control",
      "authors": "Suhan Shetty, Teng Xue, Sylvain Calinon",
      "paper_url": "https://openreview.net/pdf?id=csukJcpYDe",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_LqTz13JS2P",
      "paper_id": "LqTz13JS2P",
      "title": "Generalized Principal-Agent Problem with a Learning Agent",
      "authors": "Tao Lin, Yiling Chen",
      "paper_url": "https://openreview.net/pdf?id=LqTz13JS2P",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_UkU05GOH7_6",
      "paper_id": "UkU05GOH7_6",
      "title": "Generating Diverse Cooperative Agents by Learning Incompatible Policies",
      "authors": "Rujikorn Charakorn, Poramate Manoonpong, Nat Dilokthanakul",
      "paper_url": "https://openreview.net/pdf/ac9e4f47a8a7afc2d31fe69575bb97700dd88071.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_YZHES8wIdE",
      "paper_id": "YZHES8wIdE",
      "title": "Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning",
      "authors": "Haichao Zhang, Wei Xu, Haonan Yu",
      "paper_url": "https://openreview.net/pdf/0e68ff1fa269567c6c6101685f2f721afcc5d0aa.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_TGFO0DbD_pk",
      "paper_id": "TGFO0DbD_pk",
      "title": "Genetic Soft Updates for Policy Evolution in Deep Reinforcement Learning",
      "authors": "Enrico Marchesini, Davide Corsi, Alessandro Farinelli",
      "paper_url": "https://openreview.net/pdf/2a012533ff0b6880941f619b1e03b63abd1414c6.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_AP0ndQloqR",
      "paper_id": "AP0ndQloqR",
      "title": "Geometry of Neural Reinforcement Learning in Continuous State and Action Spaces",
      "authors": "Saket Tiwari, Omer Gottesman, George Konidaris",
      "paper_url": "https://openreview.net/pdf?id=AP0ndQloqR",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_bB2drc7DPuB",
      "paper_id": "bB2drc7DPuB",
      "title": "Global optimality of softmax policy gradient with single hidden layer neural networks in the mean-field regime",
      "authors": "Andrea Agazzi, Jianfeng Lu",
      "paper_url": "https://openreview.net/pdf/17d9d92e96c6ed3bfb2eeaec3ea3cfacdcbfc029.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_6NePxZwfae",
      "paper_id": "6NePxZwfae",
      "title": "Goal-Directed Planning via Hindsight Experience Replay",
      "authors": "Lorenzo Moro, Amarildo Likmeta, Enrico Prati, Marcello Restelli",
      "paper_url": "https://openreview.net/pdf/97fe32650bb5e2dbad89bb4c2de9b120fc5caea0.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_5o9G4XF1LI",
      "paper_id": "5o9G4XF1LI",
      "title": "Goodhart's Law in Reinforcement Learning",
      "authors": "Jacek Karwowski, Oliver Hayman, Xingjian Bai, Klaus Kiendlhofer, Charlie Griffin, Joar Max Viktor Skalse",
      "paper_url": "https://openreview.net/pdf?id=5o9G4XF1LI",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_ERv8ptegFi",
      "paper_id": "ERv8ptegFi",
      "title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS",
      "authors": "Saman Kazemkhani, Aarav Pandya, Daphne Cornelisse, Brennan Shacklett, Eugene Vinitsky",
      "paper_url": "https://openreview.net/pdf?id=ERv8ptegFi",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_rzvOQrnclO0",
      "paper_id": "rzvOQrnclO0",
      "title": "Gradient Information Matters in Policy Optimization by Back-propagating through Model",
      "authors": "Chongchong Li, Yue Wang, Wei Chen, Yuting Liu, Zhi-Ming Ma, Tie-Yan Liu",
      "paper_url": "https://openreview.net/pdf/f6890ab3f174fcc59f2441755d0529b472b382da.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_rmoMvptXK7M",
      "paper_id": "rmoMvptXK7M",
      "title": "Gray-Box Gaussian Processes for Automated Reinforcement Learning",
      "authors": "Gresa Shala, André Biedenkapp, Frank Hutter, Josif Grabocka",
      "paper_url": "https://openreview.net/pdf/07c32d1c893bba5b63fecd20c32849da78820520.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_eSQh8rG8Oa",
      "paper_id": "eSQh8rG8Oa",
      "title": "Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement",
      "authors": "Samuel Neumann, Sungsu Lim, Ajin George Joseph, Yangchen Pan, Adam White, Martha White",
      "paper_url": "https://openreview.net/pdf/ffefa87b3379d501de4cdc645c3a08611e72b7ee.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_6t_dLShIUyZ",
      "paper_id": "6t_dLShIUyZ",
      "title": "Greedy-GQ with Variance Reduction: Finite-time Analysis and Improved Complexity",
      "authors": "Shaocong Ma, Ziyi Chen, Yi Zhou, Shaofeng Zou",
      "paper_url": "https://openreview.net/pdf/70ad48e9c8d6cee0c23e74dba794453ea0ba809d.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_O5rKg7IRQIO",
      "paper_id": "O5rKg7IRQIO",
      "title": "Guarded Policy Optimization with Imperfect Online Demonstrations",
      "authors": "Zhenghai Xue, Zhenghao Peng, Quanyi Li, Zhihan Liu, Bolei Zhou",
      "paper_url": "https://openreview.net/pdf/e19dee281e43ab70ef8f8640d6ccb689bed45bd8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_zzqBoIFOQ1",
      "paper_id": "zzqBoIFOQ1",
      "title": "Guiding Safe Exploration with Weakest Preconditions",
      "authors": "Greg Anderson, Swarat Chaudhuri, Isil Dillig",
      "paper_url": "https://openreview.net/pdf/31fba2ce53b7314f1c3b3ec7719c818d82414a6d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_YOc5t8PHf2",
      "paper_id": "YOc5t8PHf2",
      "title": "Handling Delay in Real-Time Reinforcement Learning",
      "authors": "Ivan Anokhin, Rishav Rishav, Matthew Riemer, Stephen Chung, Irina Rish, Samira Ebrahimi Kahou",
      "paper_url": "https://openreview.net/pdf?id=YOc5t8PHf2",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_THJEa8adBn",
      "paper_id": "THJEa8adBn",
      "title": "Harnessing Density Ratios for Online Reinforcement Learning",
      "authors": "Philip Amortila, Dylan J Foster, Nan Jiang, Ayush Sekhari, Tengyang Xie",
      "paper_url": "https://openreview.net/pdf?id=THJEa8adBn",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_OhUAblg27z",
      "paper_id": "OhUAblg27z",
      "title": "Harnessing Mixed Offline Reinforcement Learning Datasets via Trajectory Weighting",
      "authors": "Zhang-Wei Hong, Pulkit Agrawal, Remi Tachet des Combes, Romain Laroche",
      "paper_url": "https://openreview.net/pdf/b83963010af384d9aa84006520ff14a6370f893e.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_5BRFddsAai",
      "paper_id": "5BRFddsAai",
      "title": "HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents",
      "authors": "Tristan Tomilin, Meng Fang, Mykola Pechenizkiy",
      "paper_url": "https://openreview.net/pdf?id=5BRFddsAai",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_r-gPPHEjpmw",
      "paper_id": "r-gPPHEjpmw",
      "title": "Hierarchical Reinforcement Learning by Discovering Intrinsic Options",
      "authors": "Jesse Zhang, Haonan Yu, Wei Xu",
      "paper_url": "https://openreview.net/pdf/8ab82acd2672b63eb1d694fcb5fc26a32c2f6d74.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_QOfWubPhdS",
      "paper_id": "QOfWubPhdS",
      "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
      "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong",
      "paper_url": "https://openreview.net/pdf?id=QOfWubPhdS",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_P7OVkHEoHOZ",
      "paper_id": "P7OVkHEoHOZ",
      "title": "Hindsight Foresight Relabeling for Meta-Reinforcement Learning",
      "authors": "Michael Wan, Jian Peng, Tanmay Gangwani",
      "paper_url": "https://openreview.net/pdf/73f685c6746fdb65b8e4aa08ea1ed0d6b49a34a8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_NLevOah0CJ",
      "paper_id": "NLevOah0CJ",
      "title": "Hindsight PRIORs for Reward Learning from Human Preferences",
      "authors": "Mudit Verma, Katherine Metcalf",
      "paper_url": "https://openreview.net/pdf?id=NLevOah0CJ",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_VuuDXDgujAc",
      "paper_id": "VuuDXDgujAc",
      "title": "HiT-MDP: Learning the SMDP option framework on MDPs with Hidden Temporal Embeddings",
      "authors": "Chang Li, Dongjin Song, Dacheng Tao",
      "paper_url": "https://openreview.net/pdf/61698cdc4d4f3090830fd86c25540ed087f4ae78.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_BH8Nrt2dPf",
      "paper_id": "BH8Nrt2dPf",
      "title": "Horizon Generalization in Reinforcement Learning",
      "authors": "Vivek Myers, Catherine Ji, Benjamin Eysenbach",
      "paper_url": "https://openreview.net/pdf?id=BH8Nrt2dPf",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_SdBApv9iT4",
      "paper_id": "SdBApv9iT4",
      "title": "Horizon-Free Regret for Linear Markov Decision Processes",
      "authors": "Zihan Zhang, Jason D. Lee, Yuxin Chen, Simon Shaolei Du",
      "paper_url": "https://openreview.net/pdf?id=SdBApv9iT4",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_aPNwsJgnZJ",
      "paper_id": "aPNwsJgnZJ",
      "title": "Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs",
      "authors": "Kaixuan Ji, Qingyue Zhao, Jiafan He, Weitong Zhang, Quanquan Gu",
      "paper_url": "https://openreview.net/pdf?id=aPNwsJgnZJ",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_JtC6yOHRoJJ",
      "paper_id": "JtC6yOHRoJJ",
      "title": "Human-level Atari 200x faster",
      "authors": "Steven Kapturowski, Víctor Campos, Ray Jiang, Nemanja Rakicevic, Hado van Hasselt, Charles Blundell, Adria Puigdomenech Badia",
      "paper_url": "https://openreview.net/pdf/b23bc123e103d66e46f6b7516e3fb6dffd1d2cba.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_0-uUGPbIjD",
      "paper_id": "0-uUGPbIjD",
      "title": "Human-Level Performance in No-Press Diplomacy via Equilibrium Search",
      "authors": "Jonathan Gray, Adam Lerer, Anton Bakhtin, Noam Brown",
      "paper_url": "https://openreview.net/pdf/59e1f6ceb25265194013bc67945a7001ef36ca84.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_64trBbOhdGU",
      "paper_id": "64trBbOhdGU",
      "title": "HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation",
      "authors": "Boyan Li, Hongyao Tang, YAN ZHENG, Jianye HAO, Pengyi Li, Zhen Wang, Zhaopeng Meng, LI Wang",
      "paper_url": "https://openreview.net/pdf/21005c7fdccb6d12eff7a0a9deba69320225bd53.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_yyBis80iUuU",
      "paper_id": "yyBis80iUuU",
      "title": "Hybrid RL: Using both offline and online data can make RL efficient",
      "authors": "Yuda Song, Yifei Zhou, Ayush Sekhari, Drew Bagnell, Akshay Krishnamurthy, Wen Sun",
      "paper_url": "https://openreview.net/pdf/dc7cd7793233a77b76033b4b3a179d9a40bc657c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_AatUEvC-Wjv",
      "paper_id": "AatUEvC-Wjv",
      "title": "Hyper-Decision Transformer for Efficient Online Policy Adaptation",
      "authors": "Mengdi Xu, Yuchen Lu, Yikang Shen, Shun Zhang, Ding Zhao, Chuang Gan",
      "paper_url": "https://openreview.net/pdf/1f0b37a019fe4936d828e553d436ca30059a9540.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_TfBHFLgv77",
      "paper_id": "TfBHFLgv77",
      "title": "Hyperbolic Deep Reinforcement Learning",
      "authors": "Edoardo Cetin, Benjamin Paul Chamberlain, Michael M. Bronstein, Jonathan J Hunt",
      "paper_url": "https://openreview.net/pdf/9fac2de989afbbe7a7767c39f7d03bdb640f3016.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_X0nrKAXu7g-",
      "paper_id": "X0nrKAXu7g-",
      "title": "HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning",
      "authors": "Ziniu Li, Yingru Li, Yushun Zhang, Tong Zhang, Zhi-Quan Luo",
      "paper_url": "https://openreview.net/pdf/30b6b4ed73060d9df3e0281db73cefda2f68ce5d.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_pHXfe1cOmA",
      "paper_id": "pHXfe1cOmA",
      "title": "HyperDynamics: Meta-Learning Object and Agent Dynamics with Hypernetworks",
      "authors": "Zhou Xian, Shamit Lal, Hsiao-Yu Tung, Emmanouil Antonios Platanios, Katerina Fragkiadaki",
      "paper_url": "https://openreview.net/pdf/08774c9cdcc696092021d165f4b6e807b414198c.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_CJWMXqAnAy",
      "paper_id": "CJWMXqAnAy",
      "title": "HyPoGen: Optimization-Biased Hypernetworks for Generalizable Policy Generation",
      "authors": "Hanxiang Ren, Li Sun, Xulong Wang, Pei Zhou, Zewen Wu, Siyan Dong, Difan Zou, Youyi Zheng, Yanchao Yang",
      "paper_url": "https://openreview.net/pdf?id=CJWMXqAnAy",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_iPWxqnt2ke",
      "paper_id": "iPWxqnt2ke",
      "title": "Identifying Policy Gradient Subspaces",
      "authors": "Jan Schneider, Pierre Schumacher, Simon Guist, Le Chen, Daniel Haeufle, Bernhard Schölkopf, Dieter Büchler",
      "paper_url": "https://openreview.net/pdf?id=iPWxqnt2ke",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_GY6-6sTvGaf",
      "paper_id": "GY6-6sTvGaf",
      "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels",
      "authors": "Denis Yarats, Ilya Kostrikov, Rob Fergus",
      "paper_url": "https://openreview.net/pdf/b8b967965ff52b2eb545d1a7d4284f59f0fc181f.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_6lUEy1J5R7p",
      "paper_id": "6lUEy1J5R7p",
      "title": "Imitating Graph-Based Planning with Goal-Conditioned Policies",
      "authors": "Junsu Kim, Younggyo Seo, Sungsoo Ahn, Kyunghwan Son, Jinwoo Shin",
      "paper_url": "https://openreview.net/pdf/fa60437d007be2312f49bfe0e1aebfab94534575.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_1zwleytEpYx",
      "paper_id": "1zwleytEpYx",
      "title": "Imitation Learning by Reinforcement Learning",
      "authors": "Kamil Ciosek",
      "paper_url": "https://openreview.net/pdf/18385148f0590e0d9a4ea379bd07c26c43414141.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_pPJTQYOpNI",
      "paper_id": "pPJTQYOpNI",
      "title": "Imitation Learning from Observation with Automatic Discount Scheduling",
      "authors": "Yuyang Liu, Weijun Dong, Yingdong Hu, Chuan Wen, Zhao-Heng Yin, Chongjie Zhang, Yang Gao",
      "paper_url": "https://openreview.net/pdf?id=pPJTQYOpNI",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_twv2QlJhXzo",
      "paper_id": "twv2QlJhXzo",
      "title": "Imitation Learning from Observations under Transition Model Disparity",
      "authors": "Tanmay Gangwani, Yuan Zhou, Jian Peng",
      "paper_url": "https://openreview.net/pdf/7fd85a0997ef411d5948afe26129e044734df91a.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_xJEd8PkdNz",
      "paper_id": "xJEd8PkdNz",
      "title": "Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control",
      "authors": "Wenhan Cao, Wei Pan",
      "paper_url": "https://openreview.net/pdf?id=xJEd8PkdNz",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_O9bnihsFfXU",
      "paper_id": "O9bnihsFfXU",
      "title": "Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning",
      "authors": "Aviral Kumar, Rishabh Agarwal, Dibya Ghosh, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/766d703650bcb86c35c53681b89ad0a2aba30504.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_jpsw-KuOi7r",
      "paper_id": "jpsw-KuOi7r",
      "title": "Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs",
      "authors": "Yuan Cheng, Ruiquan Huang, Yingbin Liang, Jing Yang",
      "paper_url": "https://openreview.net/pdf/7e35ca55c657bd4a6cd5f8b5855b554ea5a1b927.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_6qZC7pfenQm",
      "paper_id": "6qZC7pfenQm",
      "title": "Improving Deep Policy Gradients with Value Function Search",
      "authors": "Enrico Marchesini, Christopher Amato",
      "paper_url": "https://openreview.net/pdf/f7835d07853f4262b59ffe0f6dde2458de1d5eed.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_YbZxT0SON4",
      "paper_id": "YbZxT0SON4",
      "title": "Improving Intrinsic Exploration by Creating Stationary Objectives",
      "authors": "Roger Creus Castanyer, Joshua Romoff, Glen Berseth",
      "paper_url": "https://openreview.net/pdf?id=YbZxT0SON4",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_MCl0TLboP1",
      "paper_id": "MCl0TLboP1",
      "title": "Improving Offline RL by Blending Heuristics",
      "authors": "Sinong Geng, Aldo Pacchiano, Andrey Kolobov, Ching-An Cheng",
      "paper_url": "https://openreview.net/pdf?id=MCl0TLboP1",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_uIKZSStON3",
      "paper_id": "uIKZSStON3",
      "title": "In-context Exploration-Exploitation for Reinforcement Learning",
      "authors": "Zhenwen Dai, Federico Tomasi, Sina Ghiassian",
      "paper_url": "https://openreview.net/pdf?id=uIKZSStON3",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_hy0a5MMPUv",
      "paper_id": "hy0a5MMPUv",
      "title": "In-context Reinforcement Learning with Algorithm Distillation",
      "authors": "Michael Laskin, Luyu Wang, Junhyuk Oh, Emilio Parisotto, Stephen Spencer, Richie Steigerwald, DJ Strouse, Steven Stenberg Hansen, Angelos Filos, Ethan Brooks, maxime gazeau, Himanshu Sahni, Satinder Singh, Volodymyr Mnih",
      "paper_url": "https://openreview.net/pdf/c985c5523f4d0b869ac3914fad93d499e71fcb5a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_dfDv0WU853R",
      "paper_id": "dfDv0WU853R",
      "title": "In-sample Actor Critic for Offline Reinforcement Learning",
      "authors": "Hongchang Zhang, Yixiu Mao, Boyuan Wang, Shuncheng He, Yi Xu, Xiangyang Ji",
      "paper_url": "https://openreview.net/pdf/036a9dbc3c8ddf37986fc41037cbd871a2d0b950.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_DfUjyyRW90",
      "paper_id": "DfUjyyRW90",
      "title": "Information Prioritization through Empowerment in Visual Model-based RL",
      "authors": "Homanga Bharadhwaj, Mohammad Babaeizadeh, Dumitru Erhan, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/13e706cf08e60f2727651883527c31c53558ed33.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_kxD2LlPr40",
      "paper_id": "kxD2LlPr40",
      "title": "INS: Interaction-aware Synthesis to Enhance Offline Multi-agent Reinforcement Learning",
      "authors": "Yuqian Fu, Yuanheng Zhu, Jian Zhao, Jiajun Chai, Dongbin Zhao",
      "paper_url": "https://openreview.net/pdf?id=kxD2LlPr40",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_je3GZissZc",
      "paper_id": "je3GZissZc",
      "title": "Instant Policy: In-Context Imitation Learning via Graph Diffusion",
      "authors": "Vitalis Vosylius, Edward Johns",
      "paper_url": "https://openreview.net/pdf?id=je3GZissZc",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_z21DkDDdgq",
      "paper_id": "z21DkDDdgq",
      "title": "Integral Performance Approximation for Continuous-Time Reinforcement Learning Control",
      "authors": "Brent A. Wallace, Jennie Si",
      "paper_url": "https://openreview.net/pdf?id=z21DkDDdgq",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_PR6RMsxuW7",
      "paper_id": "PR6RMsxuW7",
      "title": "Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures",
      "authors": "Jung-Chun Liu, Chi-Hsien Chang, Shao-Hua Sun, Tian-Li Yu",
      "paper_url": "https://openreview.net/pdf?id=PR6RMsxuW7",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_Nq45xeghcL",
      "paper_id": "Nq45xeghcL",
      "title": "Intelligent Switching for Reset-Free RL",
      "authors": "Darshan Patil, Janarthanan Rajendran, Glen Berseth, Sarath Chandar",
      "paper_url": "https://openreview.net/pdf?id=Nq45xeghcL",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_DzGe40glxs",
      "paper_id": "DzGe40glxs",
      "title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning",
      "authors": "Thomas Bush, Stephen Chung, Usman Anwar, Adrià Garriga-Alonso, David Krueger",
      "paper_url": "https://openreview.net/pdf?id=DzGe40glxs",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_XoulHHQGFi",
      "paper_id": "XoulHHQGFi",
      "title": "IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning",
      "authors": "Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Zhongxia Yan, Cathy Wu",
      "paper_url": "https://openreview.net/pdf?id=XoulHHQGFi",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_OaoDVZntGe",
      "paper_id": "OaoDVZntGe",
      "title": "Inverse Attention Agents for Multi-Agent Systems",
      "authors": "Qian Long, Ruoyan Li, Minglu Zhao, Tao Gao, Demetri Terzopoulos",
      "paper_url": "https://openreview.net/pdf?id=OaoDVZntGe",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_zxO4WuVGns",
      "paper_id": "zxO4WuVGns",
      "title": "Inverse decision-making using neural amortized Bayesian actors",
      "authors": "Dominik Straub, Tobias F. Niehues, Jan Peters, Constantin A. Rothkopf",
      "paper_url": "https://openreview.net/pdf?id=zxO4WuVGns",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_DYypjaRdph2",
      "paper_id": "DYypjaRdph2",
      "title": "Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies",
      "authors": "Alex Chan, Alicia Curth, Mihaela van der Schaar",
      "paper_url": "https://openreview.net/pdf/dc7c6c1afc5a4d35d2f621c9684cf86f140adf79.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_2TasVD7FXp",
      "paper_id": "2TasVD7FXp",
      "title": "InvestESG: A multi-agent reinforcement learning benchmark for studying climate investment as a social dilemma",
      "authors": "Xiaoxuan Hou, Jiayi Yuan, Joel Z Leibo, Natasha Jaques",
      "paper_url": "https://openreview.net/pdf?id=2TasVD7FXp",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_sSt9fROSZRO",
      "paper_id": "sSt9fROSZRO",
      "title": "Investigating Multi-task Pretraining and Generalization in Reinforcement Learning",
      "authors": "Adrien Ali Taiga, Rishabh Agarwal, Jesse Farebrother, Aaron Courville, Marc G Bellemare",
      "paper_url": "https://openreview.net/pdf/dc00572cbf1ba37d6927b5663d6ca68300b6678e.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_sP1fo2K9DFG",
      "paper_id": "sP1fo2K9DFG",
      "title": "Is Conditional Generative Modeling all you need for Decision Making?",
      "authors": "Anurag Ajay, Yilun Du, Abhi Gupta, Joshua B. Tenenbaum, Tommi S. Jaakkola, Pulkit Agrawal",
      "paper_url": "https://openreview.net/pdf/e4e0b6540b8164996a357a85347d96a324cf5647.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_9xhgmsNVHu",
      "paper_id": "9xhgmsNVHu",
      "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
      "authors": "Johan Bjorck, Carla P Gomes, Kilian Q Weinberger",
      "paper_url": "https://openreview.net/pdf/231cc619ca2bc7ec04038f562613fdfa22ef8634.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_hNyJBk3CwR",
      "paper_id": "hNyJBk3CwR",
      "title": "Is Model Ensemble Necessary? Model-based RL via a Single Model with Lipschitz Regularized Value Function",
      "authors": "Ruijie Zheng, Xiyao Wang, Huazhe Xu, Furong Huang",
      "paper_url": "https://openreview.net/pdf/4569591fe6e09e958df0e03906a9bb0411ab14e0.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_q4tZR1Y-UIs",
      "paper_id": "q4tZR1Y-UIs",
      "title": "It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation",
      "authors": "Yuqing Du, Pieter Abbeel, Aditya Grover",
      "paper_url": "https://openreview.net/pdf/68a6237e79699c723ce9c9c39537422391df3e2b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_giBFoa-uS12",
      "paper_id": "giBFoa-uS12",
      "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming",
      "authors": "Sachin G Konan, Esmaeil Seraj, Matthew Gombolay",
      "paper_url": "https://openreview.net/pdf/6aa48ac42e21539265419c747bb0aedda2b1992d.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_R4aWTjmrEKM",
      "paper_id": "R4aWTjmrEKM",
      "title": "Iterative Empirical Game Solving via Single Policy Best Response",
      "authors": "Max Smith, Thomas Anthony, Michael Wellman",
      "paper_url": "https://openreview.net/pdf/fb60abf7fdce06cdc3bb6ee76b85965240d6427d.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_C4CxQmp9wc",
      "paper_id": "C4CxQmp9wc",
      "title": "Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX",
      "authors": "Clément Bonnet, Daniel Luo, Donal John Byrne, Shikha Surana, Sasha Abramowitz, Paul Duckworth, Vincent Coyette, Laurence Illing Midgley, Elshadai Tegegn, Tristan Kalloniatis, Omayma Mahjoub, Matthew Macfarlane, Andries Petrus Smit, Nathan Grinsztajn, Raphael Boige, Cemlyn Neil Waters, Mohamed Ali Ali Mimouni, Ulrich Armel Mbou Sob, Ruan John de Kock, Siddarth Singh, Daniel Furelos-Blanco, Victor Le, Arnu Pretorius, Alexandre Laterre",
      "paper_url": "https://openreview.net/pdf?id=C4CxQmp9wc",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_plebgsdiiV",
      "paper_id": "plebgsdiiV",
      "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies",
      "authors": "Haanvid Lee, Tri Wahyu Guntara, Jongmin Lee, Yung-Kyun Noh, Kee-Eung Kim",
      "paper_url": "https://openreview.net/pdf?id=plebgsdiiV",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_MljXVdp4A3N",
      "paper_id": "MljXVdp4A3N",
      "title": "Know Your Action Set: Learning Action Relations for Reinforcement Learning",
      "authors": "Ayush Jain, Norio Kosaka, Kyung-Min Kim, Joseph J Lim",
      "paper_url": "https://openreview.net/pdf/e227e96a6b5847d80aeaa7803fa8a32a8b03f28c.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_FvQsk3la17",
      "paper_id": "FvQsk3la17",
      "title": "Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning",
      "authors": "Haque Ishfaq, Guangyuan Wang, Sami Nur Islam, Doina Precup",
      "paper_url": "https://openreview.net/pdf?id=FvQsk3la17",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_cP5IcoAkfKa",
      "paper_id": "cP5IcoAkfKa",
      "title": "Large Batch Simulation for Deep Reinforcement Learning",
      "authors": "Brennan Shacklett, Erik Wijmans, Aleksei Petrenko, Manolis Savva, Dhruv Batra, Vladlen Koltun, Kayvon Fatahalian",
      "paper_url": "https://openreview.net/pdf/623f84dd47e44c85099947df02e289ec8005ddc3.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_bDt5qc7TfO",
      "paper_id": "bDt5qc7TfO",
      "title": "Latent Safety-Constrained Policy Approach for Safe Offline Reinforcement Learning",
      "authors": "Prajwal Koirala, Zhanhong Jiang, Soumik Sarkar, Cody Fleming",
      "paper_url": "https://openreview.net/pdf?id=bDt5qc7TfO",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_jXe91kq3jAq",
      "paper_id": "jXe91kq3jAq",
      "title": "Latent Skill Planning for Exploration and Transfer",
      "authors": "Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, Animesh Garg, Florian Shkurti",
      "paper_url": "https://openreview.net/pdf/fe4b11b44759390e66cce050dfae61286ab48d51.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_b0UksKFcTOL",
      "paper_id": "b0UksKFcTOL",
      "title": "Latent State Marginalization as a Low-cost Approach for Improving Exploration",
      "authors": "Dinghuai Zhang, Aaron Courville, Yoshua Bengio, Qinqing Zheng, Amy Zhang, Ricky T. Q. Chen",
      "paper_url": "https://openreview.net/pdf/f2dd0f2e03f758d3b57efe5cb6cf0b05f6ce3fe3.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_mQpmZVzXK1h",
      "paper_id": "mQpmZVzXK1h",
      "title": "Latent Variable Representation for Reinforcement Learning",
      "authors": "Tongzheng Ren, Chenjun Xiao, Tianjun Zhang, Na Li, Zhaoran Wang, sujay sanghavi, Dale Schuurmans, Bo Dai",
      "paper_url": "https://openreview.net/pdf/5c972a086aefc63dad4305fc71633c970805fb48.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_3UKOzGWCVY",
      "paper_id": "3UKOzGWCVY",
      "title": "Learn-by-interact: A Data-Centric Framework For Self-Adaptive Agents in Realistic Environments",
      "authors": "Hongjin SU, Ruoxi Sun, Jinsung Yoon, Pengcheng Yin, Tao Yu, Sercan O Arik",
      "paper_url": "https://openreview.net/pdf?id=3UKOzGWCVY",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_FeWvD0L_a4",
      "paper_id": "FeWvD0L_a4",
      "title": "Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection",
      "authors": "Jiajun Fan, Yuzheng Zhuang, Yuecheng Liu, Jianye HAO, Bin Wang, Jiangcheng Zhu, Hao Wang, Shu-Tao Xia",
      "paper_url": "https://openreview.net/pdf/6576875018fe482d865d62a571a8b8df3278b360.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_h0de3QWtGG",
      "paper_id": "h0de3QWtGG",
      "title": "Learning \"What-if\" Explanations for Sequential Decision-Making",
      "authors": "Ioana Bica, Daniel Jarrett, Alihan Hüyük, Mihaela van der Schaar",
      "paper_url": "https://openreview.net/pdf/8007445a08db8481ba43eaac1f01ad2c9495810b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_41WIgfdd5o",
      "paper_id": "41WIgfdd5o",
      "title": "Learning a Fast Mixing Exogenous Block MDP using a Single Trajectory",
      "authors": "Alexander Levine, Peter Stone, Amy Zhang",
      "paper_url": "https://openreview.net/pdf?id=41WIgfdd5o",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_4Muj-t_4o4",
      "paper_id": "4Muj-t_4o4",
      "title": "Learning a subspace of policies for online adaptation in Reinforcement Learning",
      "authors": "Jean-Baptiste Gaya, Laure Soulier, Ludovic Denoyer",
      "paper_url": "https://openreview.net/pdf/2845a7c71512ebc0d2961233b0ec523e86dd65a8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_NDWl9qcUpvy",
      "paper_id": "NDWl9qcUpvy",
      "title": "Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward",
      "authors": "Zihan Zhou, Animesh Garg",
      "paper_url": "https://openreview.net/pdf/8462e2f1cef7cf3f3aede9507b7197a763a436ed.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_KxbhdyiPHE",
      "paper_id": "KxbhdyiPHE",
      "title": "Learning Altruistic Behaviours in Reinforcement Learning without External Rewards",
      "authors": "Tim Franzmeyer, Mateusz Malinowski, Joao F. Henriques",
      "paper_url": "https://openreview.net/pdf/1af1674dc962e470709ff0dba09d61b75acd8daa.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_QIRlze3I6hX",
      "paper_id": "QIRlze3I6hX",
      "title": "Learning Cross-Domain Correspondence for Control with Dynamics Cycle-Consistency",
      "authors": "Qiang Zhang, Tete Xiao, Alexei A Efros, Lerrel Pinto, Xiaolong Wang",
      "paper_url": "https://openreview.net/pdf/2d895dd1e0137048768cefacc5fe9d81daa35d58.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_4WM0OogPTx",
      "paper_id": "4WM0OogPTx",
      "title": "Learning from Sparse Offline Datasets via Conservative Density Estimation",
      "authors": "Zhepeng Cen, Zuxin Liu, Zitong Wang, Yihang Yao, Henry Lam, Ding Zhao",
      "paper_url": "https://openreview.net/pdf?id=4WM0OogPTx",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_zBOI9LFpESK",
      "paper_id": "zBOI9LFpESK",
      "title": "Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities",
      "authors": "Jianda Chen, Sinno Pan",
      "paper_url": "https://openreview.net/pdf/6abafd4c0174bd9684e716b9b972429d4b2ae350.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_HR1ujVR0ig",
      "paper_id": "HR1ujVR0ig",
      "title": "Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation",
      "authors": "Sicong Liu, Yang Shu, Chenjuan Guo, Bin Yang",
      "paper_url": "https://openreview.net/pdf?id=HR1ujVR0ig",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_TjCDNssXKU",
      "paper_id": "TjCDNssXKU",
      "title": "Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics",
      "authors": "Christian Gumbsch, Noor Sajid, Georg Martius, Martin V. Butz",
      "paper_url": "https://openreview.net/pdf?id=TjCDNssXKU",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_-2FCwDKRREu",
      "paper_id": "-2FCwDKRREu",
      "title": "Learning Invariant Representations for Reinforcement Learning without Reconstruction",
      "authors": "Amy Zhang, Rowan Thomas McAllister, Roberto Calandra, Yarin Gal, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/603fb2b2d3c728fdb6a0d1f23a60748227ff46c7.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_lpkGn3k2YdD",
      "paper_id": "lpkGn3k2YdD",
      "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition",
      "authors": "Zhizhou Ren, Ruihan Guo, Yuan Zhou, Jian Peng",
      "paper_url": "https://openreview.net/pdf/9d37ef647d9bba0c4b6fe1976563d07da74d311e.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_Qox9rO0kN0",
      "paper_id": "Qox9rO0kN0",
      "title": "Learning Multi-Agent Communication from Graph Modeling Perspective",
      "authors": "Shengchao Hu, Li Shen, Ya Zhang, Dacheng Tao",
      "paper_url": "https://openreview.net/pdf?id=Qox9rO0kN0",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_vZZ4hhniJU",
      "paper_id": "vZZ4hhniJU",
      "title": "Learning Multi-Agent Communication with Contrastive Learning",
      "authors": "Yat Long Lo, Biswa Sengupta, Jakob Nicolaus Foerster, Michael Noukhovitch",
      "paper_url": "https://openreview.net/pdf?id=vZZ4hhniJU",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_upkxzurnLC",
      "paper_id": "upkxzurnLC",
      "title": "Learning on One Mode: Addressing Multi-modality in Offline Reinforcement Learning",
      "authors": "Mianchu Wang, Yue Jin, Giovanni Montana",
      "paper_url": "https://openreview.net/pdf?id=upkxzurnLC",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_PDtMrogheZ",
      "paper_id": "PDtMrogheZ",
      "title": "Learning Robust Representations with Long-Term Information for Generalization in Visual Reinforcement Learning",
      "authors": "Rui Yang, Jie Wang, Qijie Peng, Ruibo Guo, Guoping Wu, Bin Li",
      "paper_url": "https://openreview.net/pdf?id=PDtMrogheZ",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_fmOOI2a3tQP",
      "paper_id": "fmOOI2a3tQP",
      "title": "Learning Robust State Abstractions for Hidden-Parameter Block MDPs",
      "authors": "Amy Zhang, Shagun Sodhani, Khimya Khetarpal, Joelle Pineau",
      "paper_url": "https://openreview.net/pdf/acd2e5fe7849505e5c63b1341d5225ee12a494be.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_P6_q1BRxY8Q",
      "paper_id": "P6_q1BRxY8Q",
      "title": "Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates",
      "authors": "Zengyi Qin, Kaiqing Zhang, Yuxiao Chen, Jingkai Chen, Chuchu Fan",
      "paper_url": "https://openreview.net/pdf/f4c73ba388f2e06c4eb91e11f62979b68fb177f2.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_8sSnD78NqTN",
      "paper_id": "8sSnD78NqTN",
      "title": "Learning Soft Constraints From Constrained Expert Demonstrations",
      "authors": "Ashish Gaurav, Kasra Rezaee, Guiliang Liu, Pascal Poupart",
      "paper_url": "https://openreview.net/pdf/8fcf77a080574ee36abb6525663524292f7b5217.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_CLpxpXqqBV",
      "paper_id": "CLpxpXqqBV",
      "title": "Learning State Representations via Retracing in Reinforcement Learning",
      "authors": "Changmin Yu, Dong Li, Jianye HAO, Jun Wang, Neil Burgess",
      "paper_url": "https://openreview.net/pdf/04d24e2870546f3dcff312162e1b4006ecd641b7.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_wxRwhSdORKG",
      "paper_id": "wxRwhSdORKG",
      "title": "Learning Subgoal Representations with Slow Dynamics",
      "authors": "Siyuan Li, Lulu Zheng, Jianhao Wang, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/72f082bc7ce485bf0a24a86ed48e9d0b9f0fb493.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_wYJII5BRYU",
      "paper_id": "wYJII5BRYU",
      "title": "Learning Successor Features with Distributed Hebbian Temporal Memory",
      "authors": "Evgenii Aleksandrovich Dzhivelikian, Petr Kuderov, Aleksandr Panov",
      "paper_url": "https://openreview.net/pdf?id=wYJII5BRYU",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_C1_esHN6AVn",
      "paper_id": "C1_esHN6AVn",
      "title": "Learning Synthetic Environments and Reward Networks for Reinforcement Learning",
      "authors": "Fabio Ferreira, Thomas Nierhoff, Andreas Sälinger, Frank Hutter",
      "paper_url": "https://openreview.net/pdf/706b0f26d6790fba3e56e1ae94751cce8f4a0789.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_5YbuOTUFQ4",
      "paper_id": "5YbuOTUFQ4",
      "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning",
      "authors": "Menglong Zhang, Fuyuan Qian, Quanying Liu",
      "paper_url": "https://openreview.net/pdf?id=5YbuOTUFQ4",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_vcopnwZ7bC",
      "paper_id": "vcopnwZ7bC",
      "title": "Learning Task Decomposition with Ordered Memory Policy Network",
      "authors": "Yuchen Lu, Yikang Shen, Siyuan Zhou, Aaron Courville, Joshua B. Tenenbaum, Chuang Gan",
      "paper_url": "https://openreview.net/pdf/7f228b5f98840f6f20f111e8ed6608d54277730d.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_rALA0Xo6yNJ",
      "paper_id": "rALA0Xo6yNJ",
      "title": "Learning to Reach Goals via Iterated Supervised Learning",
      "authors": "Dibya Ghosh, Abhishek Gupta, Ashwin Reddy, Justin Fu, Coline Manon Devin, Benjamin Eysenbach, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/34b6d953408a7aaff3549569738b80162e8e6dbc.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_Xv_s64FiXTv",
      "paper_id": "Xv_s64FiXTv",
      "title": "Learning to Represent Action Values as a Hypergraph on the Action Vertices",
      "authors": "Arash Tavakoli, Mehdi Fatemi, Petar Kormushev",
      "paper_url": "https://openreview.net/pdf/1ffba349384a4d39e139b3deafa3e80e587e2dc1.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_gJYlaqL8i8",
      "paper_id": "gJYlaqL8i8",
      "title": "Learning to Sample with Local and Global Contexts  in Experience Replay Buffer",
      "authors": "Youngmin Oh, Kimin Lee, Jinwoo Shin, Eunho Yang, Sung Ju Hwang",
      "paper_url": "https://openreview.net/pdf/92ef8e632b99778a17bd8e0187962812d2cd42c5.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_IzYczpPqKq",
      "paper_id": "IzYczpPqKq",
      "title": "Learning to Steer Markovian Agents under Model Uncertainty",
      "authors": "Jiawei Huang, Vinzenz Thoma, Zebang Shen, Heinrich H. Nax, Niao He",
      "paper_url": "https://openreview.net/pdf?id=IzYczpPqKq",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_qTHBE7E9iej",
      "paper_id": "qTHBE7E9iej",
      "title": "Learning transferable motor skills with hierarchical latent mixture policies",
      "authors": "Dushyant Rao, Fereshteh Sadeghi, Leonard Hasenclever, Markus Wulfmeier, Martina Zambelli, Giulia Vezzani, Dhruva Tirumala, Yusuf Aytar, Josh Merel, Nicolas Heess, raia hadsell",
      "paper_url": "https://openreview.net/pdf/da585a69d336f46f18b80d4a026fd3a7dcb40eae.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_6Pe99Juo9gd",
      "paper_id": "6Pe99Juo9gd",
      "title": "Learning Value Functions from Undirected State-only Experience",
      "authors": "Matthew Chang, Arjun Gupta, Saurabh Gupta",
      "paper_url": "https://openreview.net/pdf/165580641e9ae16c0919513d98c7a95e8f701683.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_NX1He-aFO_F",
      "paper_id": "NX1He-aFO_F",
      "title": "Learning Value Functions in Deep Policy Gradients using Residual Variance",
      "authors": "Yannis Flet-Berliac, reda ouhamma, odalric-ambrym maillard, Philippe Preux",
      "paper_url": "https://openreview.net/pdf/d19c38b4919b1481e2aa3972a928c866f4502b44.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_kBVJ2NtiY-",
      "paper_id": "kBVJ2NtiY-",
      "title": "Learning What To Do by Simulating the Past",
      "authors": "David Lindner, Rohin Shah, Pieter Abbeel, Anca Dragan",
      "paper_url": "https://openreview.net/pdf/42dbf5584d4a07037b331115be1963b8650f85fd.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_ETBc_MIMgoX",
      "paper_id": "ETBc_MIMgoX",
      "title": "Learning with AMIGo: Adversarially Motivated Intrinsic Goals",
      "authors": "Andres Campero, Roberta Raileanu, Heinrich Kuttler, Joshua B. Tenenbaum, Tim Rocktäschel, Edward Grefenstette",
      "paper_url": "https://openreview.net/pdf/2424de49f541b07d5245c6d926cf266b520cb248.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_TrwE8l9aJzs",
      "paper_id": "TrwE8l9aJzs",
      "title": "Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased",
      "authors": "Chao Yu, Jiaxuan Gao, Weilin Liu, Botian Xu, Hao Tang, Jiaqi Yang, Yu Wang, Yi Wu",
      "paper_url": "https://openreview.net/pdf/009d6d3a093049a11f22f96153117bbec6e44c65.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_DSyHRkpI7v",
      "paper_id": "DSyHRkpI7v",
      "title": "Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning",
      "authors": "Calarina Muslimani, Matthew E. Taylor",
      "paper_url": "https://openreview.net/pdf?id=DSyHRkpI7v",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_Mjn53GtMxi",
      "paper_id": "Mjn53GtMxi",
      "title": "LICORICE: Label-Efficient Concept-Based Interpretable Reinforcement Learning",
      "authors": "Zhuorui Ye, Stephanie Milani, Geoffrey J. Gordon, Fei Fang",
      "paper_url": "https://openreview.net/pdf?id=Mjn53GtMxi",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_ADWd4TJO13G",
      "paper_id": "ADWd4TJO13G",
      "title": "Lifelong Learning of Compositional Structures",
      "authors": "Jorge A Mendez, ERIC EATON",
      "paper_url": "https://openreview.net/pdf/4098c1ce3205eddbf5c4ba54920410460b0861cb.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_CpTuR2ECuW",
      "paper_id": "CpTuR2ECuW",
      "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning",
      "authors": "David Henry Mguni, Taher Jafferjee, Jianhong Wang, Nicolas Perez-Nieves, Oliver Slumbers, Feifei Tong, Yang Li, Jiangcheng Zhu, Yaodong Yang, Jun Wang",
      "paper_url": "https://openreview.net/pdf/e236eaa5e5c72be5b36faf18dc589c2d09c9f470.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_Sq0-tgDyHe4",
      "paper_id": "Sq0-tgDyHe4",
      "title": "Local Feature Swapping for Generalization in Reinforcement Learning",
      "authors": "David Bertoin, Emmanuel Rachelson",
      "paper_url": "https://openreview.net/pdf/679f3a9bf9ae7a8121b4cb0bb53f30887f029b89.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_i8PjQT3Uig",
      "paper_id": "i8PjQT3Uig",
      "title": "Locality Sensitive Sparse Encoding for Learning World Models Online",
      "authors": "Zichen Liu, Chao Du, Wee Sun Lee, Min Lin",
      "paper_url": "https://openreview.net/pdf?id=i8PjQT3Uig",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_NHMuM84tRT",
      "paper_id": "NHMuM84tRT",
      "title": "Long-Short Decision Transformer: Bridging Global and Local Dependencies for Generalized Decision-Making",
      "authors": "Jincheng Wang, Penny Karanasou, Pengyuan Wei, Elia Gatti, Diego Martinez Plasencia, Dimitrios Kanoulas",
      "paper_url": "https://openreview.net/pdf?id=NHMuM84tRT",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_fNMKqyvuZT",
      "paper_id": "fNMKqyvuZT",
      "title": "Looking Backward: Retrospective Backward Synthesis for Goal-Conditioned GFlowNets",
      "authors": "Haoran He, Can Chang, Huazhe Xu, Ling Pan",
      "paper_url": "https://openreview.net/pdf?id=fNMKqyvuZT",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_FDQF6A1s6M",
      "paper_id": "FDQF6A1s6M",
      "title": "LOQA: Learning with Opponent Q-Learning Awareness",
      "authors": "Milad Aghajohari, Juan Agustin Duque, Tim Cooijmans, Aaron Courville",
      "paper_url": "https://openreview.net/pdf?id=FDQF6A1s6M",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_o3Q4m8jg4BR",
      "paper_id": "o3Q4m8jg4BR",
      "title": "LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning",
      "authors": "Firas Al-Hafez, Davide Tateo, Oleg Arenz, Guoping Zhao, Jan Peters",
      "paper_url": "https://openreview.net/pdf/b623965b13d278d6941aa06a425e84985098cecf.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_inOwd7hZC1",
      "paper_id": "inOwd7hZC1",
      "title": "M^3PC: Test-time Model Predictive Control using Pretrained Masked Trajectory Model",
      "authors": "Kehan Wen, Yutong Hu, Yao Mu, Lei Ke",
      "paper_url": "https://openreview.net/pdf?id=inOwd7hZC1",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_klpdEThT8q",
      "paper_id": "klpdEThT8q",
      "title": "MA$^2$E: Addressing Partial Observability in Multi-Agent Reinforcement Learning with Masked Auto-Encoder",
      "authors": "Sehyeok Kang, Yongsik Lee, Gahee Kim, Song Chong, Se-Young Yun",
      "paper_url": "https://openreview.net/pdf?id=klpdEThT8q",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_CDlHZ78-Xzi",
      "paper_id": "CDlHZ78-Xzi",
      "title": "MACTA: A Multi-agent Reinforcement Learning Approach for Cache Timing Attacks and Detection",
      "authors": "Jiaxun Cui, Xiaomeng Yang, Mulong Luo, Geunbae Lee, Peter Stone, Hsien-Hsin S. Lee, Benjamin Lee, G. Edward Suh, Wenjie Xiong, Yuandong Tian",
      "paper_url": "https://openreview.net/pdf/8d7f2a48891a6f825223343bc81e59d3c5f6afbe.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_6RtRsg8ZV1",
      "paper_id": "6RtRsg8ZV1",
      "title": "MAD-TD: Model-Augmented Data stabilizes High Update Ratio RL",
      "authors": "Claas A Voelcker, Marcel Hussing, Eric Eaton, Amir-massoud Farahmand, Igor Gilitschenski",
      "paper_url": "https://openreview.net/pdf?id=6RtRsg8ZV1",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_sKWlRDzPfd7",
      "paper_id": "sKWlRDzPfd7",
      "title": "MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement Learning",
      "authors": "Mikayel Samvelyan, Akbir Khan, Michael D Dennis, Minqi Jiang, Jack Parker-Holder, Jakob Nicolaus Foerster, Roberta Raileanu, Tim Rocktäschel",
      "paper_url": "https://openreview.net/pdf/e65b3ee9b4e5db11d48c773dc4e02702868ef8e6.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_r8Mu7idxyF",
      "paper_id": "r8Mu7idxyF",
      "title": "Making Better Decision by Directly Planning in Continuous Control",
      "authors": "Jinhua Zhu, Yue Wang, Lijun Wu, Tao Qin, Wengang Zhou, Tie-Yan Liu, Houqiang Li",
      "paper_url": "https://openreview.net/pdf/d5862528e904b0999da130078b73a4adb326c44d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_Pe2lo3QOvo",
      "paper_id": "Pe2lo3QOvo",
      "title": "Making RL with Preference-based Feedback Efficient via Randomization",
      "authors": "Runzhe Wu, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=Pe2lo3QOvo",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_1RE0H6mU7M",
      "paper_id": "1RE0H6mU7M",
      "title": "MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning",
      "authors": "Zohar Rimon, Tom Jurgenson, Orr Krupnik, Gilad Adler, Aviv Tamar",
      "paper_url": "https://openreview.net/pdf?id=1RE0H6mU7M",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_z3L59iGALM",
      "paper_id": "z3L59iGALM",
      "title": "Massively Scalable Inverse Reinforcement Learning in Google Maps",
      "authors": "Matt Barnes, Matthew Abueg, Oliver F. Lange, Matt Deeds, Jason Trader, Denali Molitor, Markus Wulfmeier, Shawn O'Banion",
      "paper_url": "https://openreview.net/pdf?id=z3L59iGALM",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_0oabwyZbOu",
      "paper_id": "0oabwyZbOu",
      "title": "Mastering Atari with Discrete World Models",
      "authors": "Danijar Hafner, Timothy P Lillicrap, Mohammad Norouzi, Jimmy Ba",
      "paper_url": "https://openreview.net/pdf/1a697645438f4372744f991c8a726b8b9a004598.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_F61FwJTZhb",
      "paper_id": "F61FwJTZhb",
      "title": "Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning",
      "authors": "Anton Bakhtin, David J Wu, Adam Lerer, Jonathan Gray, Athul Paul Jacob, Gabriele Farina, Alexander H Miller, Noam Brown",
      "paper_url": "https://openreview.net/pdf/5355b9a9bc1eabd198a78654d7dbfa4e5f1664b0.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22__SJ-_yyes8",
      "paper_id": "_SJ-_yyes8",
      "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning",
      "authors": "Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto",
      "paper_url": "https://openreview.net/pdf/41fe3ddc3b234237036d092d185d57e0ad50b43c.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_hjd-kcpDpf2",
      "paper_id": "hjd-kcpDpf2",
      "title": "Maximizing Ensemble Diversity in Deep Reinforcement Learning",
      "authors": "Hassam Sheikh, Mariano Phielipp, Ladislau Boloni",
      "paper_url": "https://openreview.net/pdf/01f7a1ad9dd4d2d9285af9a2c926b0cc1a282f4f.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_tmqOhBC4a5",
      "paper_id": "tmqOhBC4a5",
      "title": "Maximum Entropy Heterogeneous-Agent Reinforcement Learning",
      "authors": "Jiarong Liu, Yifan Zhong, Siyi Hu, Haobo Fu, QIANG FU, Xiaojun Chang, Yaodong Yang",
      "paper_url": "https://openreview.net/pdf?id=tmqOhBC4a5",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_kNpSUN0uCc",
      "paper_id": "kNpSUN0uCc",
      "title": "Maximum Entropy Model Correction in Reinforcement Learning",
      "authors": "Amin Rakhsha, Mete Kemertas, Mohammad Ghavamzadeh, Amir-massoud Farahmand",
      "paper_url": "https://openreview.net/pdf?id=kNpSUN0uCc",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_PtSAD3caaA2",
      "paper_id": "PtSAD3caaA2",
      "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
      "authors": "Benjamin Eysenbach, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/3fb82fdb60ea0802001d004d0b6951f5226c3ff0.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_R4q3cY3kQf",
      "paper_id": "R4q3cY3kQf",
      "title": "MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization",
      "authors": "Bhavya Sukhija, Stelian Coros, Andreas Krause, Pieter Abbeel, Carmelo Sferrazza",
      "paper_url": "https://openreview.net/pdf?id=R4q3cY3kQf",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_R3Tf7LDdX4",
      "paper_id": "R3Tf7LDdX4",
      "title": "Memory-Consistent Neural Networks for Imitation Learning",
      "authors": "Kaustubh Sridhar, Souradeep Dutta, Dinesh Jayaraman, James Weimer, Insup Lee",
      "paper_url": "https://openreview.net/pdf?id=R3Tf7LDdX4",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_bJ3gFiwRgi",
      "paper_id": "bJ3gFiwRgi",
      "title": "Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis",
      "authors": "Shicheng Liu, Minghui Zhu",
      "paper_url": "https://openreview.net/pdf?id=bJ3gFiwRgi",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_RthOl4jHw5",
      "paper_id": "RthOl4jHw5",
      "title": "Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer",
      "authors": "Xingyu Liu, Deepak Pathak, Ding Zhao",
      "paper_url": "https://openreview.net/pdf?id=RthOl4jHw5",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_KTPuIsx4pmo",
      "paper_id": "KTPuIsx4pmo",
      "title": "Meta-Imitation Learning by Watching Video Demonstrations",
      "authors": "Jiayi Li, Tao Lu, Xiaoge Cao, Yinghao Cai, Shuo Wang",
      "paper_url": "https://openreview.net/pdf/c676abf58096dad39810f6901eb441d104797d02.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_--gvHfE3Xf5",
      "paper_id": "--gvHfE3Xf5",
      "title": "Meta-Learning of Structured Task Distributions in Humans and Machines",
      "authors": "Sreejan Kumar, Ishita Dasgupta, Jonathan Cohen, Nathaniel Daw, Thomas Griffiths",
      "paper_url": "https://openreview.net/pdf/ead1cbc3c9174506e0aa95f2a8fe5deb881931c1.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_Opmqtk_GvYL",
      "paper_id": "Opmqtk_GvYL",
      "title": "MetaMorph: Learning Universal Controllers with Transformers",
      "authors": "Agrim Gupta, Linxi Fan, Surya Ganguli, Li Fei-Fei",
      "paper_url": "https://openreview.net/pdf/7ef00fd81bdb696532e182f6073e6e6d9cb15e98.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_c5pwL0Soay",
      "paper_id": "c5pwL0Soay",
      "title": "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction",
      "authors": "Seohong Park, Oleh Rybkin, Sergey Levine",
      "paper_url": "https://openreview.net/pdf?id=c5pwL0Soay",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_WumysvcMvV6",
      "paper_id": "WumysvcMvV6",
      "title": "Mind the Gap: Offline Policy Optimization for Imperfect Rewards",
      "authors": "Jianxiong Li, Xiao Hu, Haoran Xu, Jingjing Liu, Xianyuan Zhan, Qing-Shan Jia, Ya-Qin Zhang",
      "paper_url": "https://openreview.net/pdf/294d37fbe5e33afb6db7a747e408f4ff688a1f9a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_i8LCUpKvAz",
      "paper_id": "i8LCUpKvAz",
      "title": "Minimax Optimal Reinforcement Learning with Quasi-Optimism",
      "authors": "Harin Lee, Min-hwan Oh",
      "paper_url": "https://openreview.net/pdf?id=i8LCUpKvAz",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_nIEjY4a2Lf",
      "paper_id": "nIEjY4a2Lf",
      "title": "Misspecified  $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error",
      "authors": "Ally Yalei Du, Lin Yang, Ruosong Wang",
      "paper_url": "https://openreview.net/pdf?id=nIEjY4a2Lf",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_qpXctF2aLZ",
      "paper_id": "qpXctF2aLZ",
      "title": "Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization",
      "authors": "Sascha Marton, Tim Grams, Florian Vogt, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt",
      "paper_url": "https://openreview.net/pdf?id=qpXctF2aLZ",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_h6k4809xVV",
      "paper_id": "h6k4809xVV",
      "title": "Model Risk-sensitive Offline Reinforcement Learning",
      "authors": "Gwangpyo Yoo, Honguk Woo",
      "paper_url": "https://openreview.net/pdf?id=h6k4809xVV",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_3ep9ZYMZS3",
      "paper_id": "3ep9ZYMZS3",
      "title": "Model-Agnostic Knowledge Guided Correction for Improved Neural Surrogate Rollout",
      "authors": "Bharat Srikishan, Daniel O'Malley, Mohamed Mehana, Nicholas Lubbers, Nikhil Muralidhar",
      "paper_url": "https://openreview.net/pdf?id=3ep9ZYMZS3",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_WuEiafqdy9H",
      "paper_id": "WuEiafqdy9H",
      "title": "Model-augmented Prioritized Experience Replay",
      "authors": "Youngmin Oh, Jinwoo Shin, Eunho Yang, Sung Ju Hwang",
      "paper_url": "https://openreview.net/pdf/b9c58544a23c255f84c3ebd3f597d7e15dd8f541.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_p5uylG94S68",
      "paper_id": "p5uylG94S68",
      "title": "Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?",
      "authors": "Balázs Kégl, Gabriel Hurtado, Albert Thomas",
      "paper_url": "https://openreview.net/pdf/04313ea0678f51bf6e97525219f5b92003b041b9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_EBn0uInJZWh",
      "paper_id": "EBn0uInJZWh",
      "title": "Model-Based Offline Meta-Reinforcement Learning with Regularization",
      "authors": "Sen Lin, Jialin Wan, Tengyu Xu, Yingbin Liang, Junshan Zhang",
      "paper_url": "https://openreview.net/pdf/af10847f3163c50846528554895671f12dd3f6bd.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_OMNB1G5xzd4",
      "paper_id": "OMNB1G5xzd4",
      "title": "Model-Based Offline Planning",
      "authors": "Arthur Argenson, Gabriel Dulac-Arnold",
      "paper_url": "https://openreview.net/pdf/81c53a9c5e305d1d030b2fa5e47206fbd6535dcf.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_OATPSB5JK1",
      "paper_id": "OATPSB5JK1",
      "title": "Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning",
      "authors": "Kwanyoung Park, Youngwoon Lee",
      "paper_url": "https://openreview.net/pdf?id=OATPSB5JK1",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_txD9llAYn9",
      "paper_id": "txD9llAYn9",
      "title": "Model-based RL as a Minimalist Approach to Horizon-Free and Second-Order Bounds",
      "authors": "Zhiyong Wang, Dongruo Zhou, John C.S. Lui, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=txD9llAYn9",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_UcoXdfrORC",
      "paper_id": "UcoXdfrORC",
      "title": "Model-Based Visual Planning with Self-Supervised Functional Distances",
      "authors": "Stephen Tian, Suraj Nair, Frederik Ebert, Sudeep Dasari, Benjamin Eysenbach, Chelsea Finn, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/e7d9842e2ee26ac0242d6efcf7a863c669541594.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_QyVLJ7EnAC",
      "paper_id": "QyVLJ7EnAC",
      "title": "Model-Free Offline Reinforcement Learning with Enhanced Robustness",
      "authors": "Chi Zhang, Zain Ulabedeen Farhat, George K. Atia, Yue Wang",
      "paper_url": "https://openreview.net/pdf?id=QyVLJ7EnAC",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_W3VsHuga3j",
      "paper_id": "W3VsHuga3j",
      "title": "Modeling Boundedly Rational Agents with Latent Inference Budgets",
      "authors": "Athul Paul Jacob, Abhishek Gupta, Jacob Andreas",
      "paper_url": "https://openreview.net/pdf?id=W3VsHuga3j",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_JdTnc9gjVfJ",
      "paper_id": "JdTnc9gjVfJ",
      "title": "MoDem: Accelerating Visual Model-Based Reinforcement Learning with Demonstrations",
      "authors": "Nicklas Hansen, Yixin Lin, Hao Su, Xiaolong Wang, Vikash Kumar, Aravind Rajeswaran",
      "paper_url": "https://openreview.net/pdf/6a5db4c4bb6e33558fd94164736145a682ec92a3.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_5XmLzdslFNN",
      "paper_id": "5XmLzdslFNN",
      "title": "Modular Lifelong Reinforcement Learning via Neural Composition",
      "authors": "Jorge A Mendez, Harm van Seijen, ERIC EATON",
      "paper_url": "https://openreview.net/pdf/a7e9350f0b9a40fc77e2f196fa086d7759fbbbd7.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_znLlSgN-4S0",
      "paper_id": "znLlSgN-4S0",
      "title": "More Centralized Training, Still Decentralized Execution: Multi-Agent Conditional Policy Factorization",
      "authors": "Jiangxing Wang, Deheng Ye, Zongqing Lu",
      "paper_url": "https://openreview.net/pdf/8258fe1c50fe61494176aa41b2c207716e3d556b.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_GkWA6NjePN",
      "paper_id": "GkWA6NjePN",
      "title": "Multi-agent cooperation through learning-aware policy gradients",
      "authors": "Alexander Meulemans, Seijin Kobayashi, Johannes Von Oswald, Nino Scherrer, Eric Elmoznino, Blake Aaron Richards, Guillaume Lajoie, Blaise Aguera y Arcas, Joao Sacramento",
      "paper_url": "https://openreview.net/pdf?id=GkWA6NjePN",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_H7HDG--DJF0",
      "paper_id": "H7HDG--DJF0",
      "title": "Multi-Agent MDP Homomorphic Networks",
      "authors": "Elise van der Pol, Herke van Hoof, Frans A Oliehoek, Max Welling",
      "paper_url": "https://openreview.net/pdf/3a8f28592a8f20859b54c37f57cb659f7b0664fa.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_rJvY_5OzoI",
      "paper_id": "rJvY_5OzoI",
      "title": "Multi-Critic Actor Learning: Teaching RL Policies to Act with Style",
      "authors": "Siddharth Mysore, George Cheng, Yunqi Zhao, Kate Saenko, Meng Wu",
      "paper_url": "https://openreview.net/pdf/9ba47239c3de56ba46f2cac821cf17c1791a8444.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_X2x2DuGIbx",
      "paper_id": "X2x2DuGIbx",
      "title": "Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning",
      "authors": "Shijie Liu, Andrew Craig Cullen, Paul Montague, Sarah Monazam Erfani, Benjamin I. P. Rubinstein",
      "paper_url": "https://openreview.net/pdf?id=X2x2DuGIbx",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_Ek7PSN7Y77z",
      "paper_id": "Ek7PSN7Y77z",
      "title": "Multi-Stage Episodic Control for Strategic Exploration in Text Games",
      "authors": "Jens Tuyls, Shunyu Yao, Sham M. Kakade, Karthik R Narasimhan",
      "paper_url": "https://openreview.net/pdf/b67d131e9b9afd599358ce78865538bd83521d24.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_aZH1dM3GOX",
      "paper_id": "aZH1dM3GOX",
      "title": "Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts",
      "authors": "Ahmed Hendawy, Jan Peters, Carlo D'Eramo",
      "paper_url": "https://openreview.net/pdf?id=aZH1dM3GOX",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_OthEq8I5v1",
      "paper_id": "OthEq8I5v1",
      "title": "Mutual Information State Intrinsic Control",
      "authors": "Rui Zhao, Yang Gao, Pieter Abbeel, Volker Tresp, Wei Xu",
      "paper_url": "https://openreview.net/pdf/6dac086e50a2341e09a0b7d6c417b5cdfd9ed47a.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_N3zUDGN5lO",
      "paper_id": "N3zUDGN5lO",
      "title": "My Body is a Cage: the Role of Morphology in Graph-Based Incompatible Control",
      "authors": "Vitaly Kurin, Maximilian Igl, Tim Rocktäschel, Wendelin Boehmer, Shimon Whiteson",
      "paper_url": "https://openreview.net/pdf/130809fe4dd2abe36b6f0c395f8cc2f51174bc4d.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_i9ogGQHYbkY",
      "paper_id": "i9ogGQHYbkY",
      "title": "Near-Optimal Adversarial Reinforcement Learning with Switching Costs",
      "authors": "Ming Shi, Yingbin Liang, Ness Shroff",
      "paper_url": "https://openreview.net/pdf/c49c1d1fb9288fba31814bc7cccd62fe483bf469.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_SNwH0dDGl7_",
      "paper_id": "SNwH0dDGl7_",
      "title": "Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation",
      "authors": "Dan Qiao, Yu-Xiang Wang",
      "paper_url": "https://openreview.net/pdf/126aa9751c7215e2be8182af8e11d1d39167d337.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_KLaDXLAzzFT",
      "paper_id": "KLaDXLAzzFT",
      "title": "Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism",
      "authors": "Ming Yin, Yaqi Duan, Mengdi Wang, Yu-Xiang Wang",
      "paper_url": "https://openreview.net/pdf/4fcfeb93b8187d6d055e04332a5c8b1c37b10970.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_3OR2tbtnYC-",
      "paper_id": "3OR2tbtnYC-",
      "title": "Near-optimal Policy Identification in Active Reinforcement Learning",
      "authors": "Xiang Li, Viraj Mehta, Johannes Kirschner, Ian Char, Willie Neiswanger, Jeff Schneider, Andreas Krause, Ilija Bogunovic",
      "paper_url": "https://openreview.net/pdf/3f2fd20ea112039f10550e677478e83b1f6260a7.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_G5sPv4KSjR",
      "paper_id": "G5sPv4KSjR",
      "title": "Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form",
      "authors": "Toshinori Kitamura, Tadashi Kozuno, Wataru Kumagai, Kenta Hoshino, Yohei Hosoe, Kazumi Kasaura, Masashi Hamaya, Paavo Parmas, Yutaka Matsuo",
      "paper_url": "https://openreview.net/pdf?id=G5sPv4KSjR",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_SidzxAb9k30",
      "paper_id": "SidzxAb9k30",
      "title": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver",
      "authors": "Xiaoyu Chen, Jiachen Hu, Lin Yang, Liwei Wang",
      "paper_url": "https://openreview.net/pdf/91c23b5592d358e7283f6fdfe3f0cf6890b65e1c.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_UP_GHHPw7rP",
      "paper_id": "UP_GHHPw7rP",
      "title": "Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game",
      "authors": "Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Liwei Wang, Tong Zhang",
      "paper_url": "https://openreview.net/pdf/4ec7b1dd165364db85e719d8b2232962869eb44d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_iAW2EQXfwb",
      "paper_id": "iAW2EQXfwb",
      "title": "Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation",
      "authors": "Ziqi Wang, Chengpeng Hu, Jialin Liu, Xin Yao",
      "paper_url": "https://openreview.net/pdf?id=iAW2EQXfwb",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_C2fsSj3ZGiU",
      "paper_id": "C2fsSj3ZGiU",
      "title": "Neural Episodic Control with State Abstraction",
      "authors": "Zhuo Li, Derui Zhu, Yujing Hu, Xiaofei Xie, Lei Ma, YAN ZHENG, Yan Song, Yingfeng Chen, Jianjun Zhao",
      "paper_url": "https://openreview.net/pdf/48c93f23de2f99bd3c38419a3f4bf1aba384c134.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_2NpAw2QJBY",
      "paper_id": "2NpAw2QJBY",
      "title": "Neural Neighborhood Search for Multi-agent Path Finding",
      "authors": "Zhongxia Yan, Cathy Wu",
      "paper_url": "https://openreview.net/pdf?id=2NpAw2QJBY",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_hxUMQ4fic3",
      "paper_id": "hxUMQ4fic3",
      "title": "Neural Stochastic Differential Equations for Uncertainty-Aware Offline RL",
      "authors": "Cevahir Koprulu, Franck Djeumou, ufuk topcu",
      "paper_url": "https://openreview.net/pdf?id=hxUMQ4fic3",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_6BHlZgyPOZY",
      "paper_id": "6BHlZgyPOZY",
      "title": "Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery",
      "authors": "Felix Chalumeau, Raphael Boige, Bryan Lim, Valentin Macé, Maxime Allard, Arthur Flajolet, Antoine Cully, Thomas PIERROT",
      "paper_url": "https://openreview.net/pdf/1c63093c2dc46ae51a5d9ec802a0d85f3455069d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_20qZK2T7fa",
      "paper_id": "20qZK2T7fa",
      "title": "Neuroplastic Expansion in Deep Reinforcement Learning",
      "authors": "Jiashun Liu, Johan Samir Obando Ceron, Aaron Courville, Ling Pan",
      "paper_url": "https://openreview.net/pdf?id=20qZK2T7fa",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_DL9txImSzm",
      "paper_id": "DL9txImSzm",
      "title": "Noise-conditioned Energy-based Annealed Rewards (NEAR): A Generative Framework for Imitation Learning from Observation",
      "authors": "Anish Abhijit Diwan, Julen Urain, Jens Kober, Jan Peters",
      "paper_url": "https://openreview.net/pdf?id=DL9txImSzm",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_LvRQgsvd5V",
      "paper_id": "LvRQgsvd5V",
      "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching",
      "authors": "Arnav Kumar Jain, Harley Wiltzer, Jesse Farebrother, Irina Rish, Glen Berseth, Sanjiban Choudhury",
      "paper_url": "https://openreview.net/pdf?id=LvRQgsvd5V",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_dKg5D1Z1Lm",
      "paper_id": "dKg5D1Z1Lm",
      "title": "Non-asymptotic Confidence Intervals of Off-policy Evaluation:  Primal and Dual Bounds",
      "authors": "Yihao Feng, Ziyang Tang, na zhang, qiang liu",
      "paper_url": "https://openreview.net/pdf/05280659a19a8436c51ea6a8b704610bdf16c3e9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_2uPZ4aX1VV",
      "paper_id": "2uPZ4aX1VV",
      "title": "Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning",
      "authors": "Caleb Chuck, Fan Feng, Carl Qi, Chang Shi, Siddhant Agarwal, Amy Zhang, Scott Niekum",
      "paper_url": "https://openreview.net/pdf?id=2uPZ4aX1VV",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_S5Yo6w3n3f",
      "paper_id": "S5Yo6w3n3f",
      "title": "ODE-based Smoothing Neural Network for Reinforcement Learning Tasks",
      "authors": "Yinuo Wang, Wenxuan Wang, Xujie Song, Tong Liu, Yuming Yin, Liangfa Chen, Likun Wang, Jingliang Duan, Shengbo Eben Li",
      "paper_url": "https://openreview.net/pdf?id=S5Yo6w3n3f",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_L8UNn7Llt4",
      "paper_id": "L8UNn7Llt4",
      "title": "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update",
      "authors": "Liyuan Mao, Haoran Xu, Weinan Zhang, Xianyuan Zhan",
      "paper_url": "https://openreview.net/pdf?id=L8UNn7Llt4",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_eqBwg3AcIAK",
      "paper_id": "eqBwg3AcIAK",
      "title": "Off-Dynamics Reinforcement Learning: Training for Transfer with Domain Classifiers",
      "authors": "Benjamin Eysenbach, Shreyas Chaudhari, Swapnil Asawa, Sergey Levine, Ruslan Salakhutdinov",
      "paper_url": "https://openreview.net/pdf/cc68f287d3416da646309bf4689396ac35e2be5c.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_vy42bYs1Wo",
      "paper_id": "vy42bYs1Wo",
      "title": "Off-Policy Primal-Dual Safe Reinforcement Learning",
      "authors": "Zifan Wu, Bo Tang, Qian Lin, Chao Yu, Shangqin Mao, Qianlong Xie, Xingxing Wang, Dong Wang",
      "paper_url": "https://openreview.net/pdf?id=vy42bYs1Wo",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_RMgqvQGTwH",
      "paper_id": "RMgqvQGTwH",
      "title": "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees",
      "authors": "Yifei Zhou, Ayush Sekhari, Yuda Song, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=RMgqvQGTwH",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_dTPz4rEDok",
      "paper_id": "dTPz4rEDok",
      "title": "Offline Hierarchical Reinforcement Learning via Inverse Optimization",
      "authors": "Carolin Schmidt, Daniele Gammelli, James Harrison, Marco Pavone, Filipe Rodrigues",
      "paper_url": "https://openreview.net/pdf?id=dTPz4rEDok",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_4-k7kUavAj",
      "paper_id": "4-k7kUavAj",
      "title": "Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes",
      "authors": "Aviral Kumar, Rishabh Agarwal, Xinyang Geng, George Tucker, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/c4fe1442235b5f185dc41908f09f0b65f8faa938.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_42zs3qa2kpy",
      "paper_id": "42zs3qa2kpy",
      "title": "Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling",
      "authors": "Huayu Chen, Cheng Lu, Chengyang Ying, Hang Su, Jun Zhu",
      "paper_url": "https://openreview.net/pdf/20c4b3fc4c6f763a48b751e9c6af706646df4083.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_6jfbOWzWTcE",
      "paper_id": "6jfbOWzWTcE",
      "title": "Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient",
      "authors": "Ming Yin, Mengdi Wang, Yu-Xiang Wang",
      "paper_url": "https://openreview.net/pdf/b38ef477c7170fbb93d3cc004ca6860e5537faa9.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_68n2s9ZJWF8",
      "paper_id": "68n2s9ZJWF8",
      "title": "Offline Reinforcement Learning with Implicit Q-Learning",
      "authors": "Ilya Kostrikov, Ashvin Nair, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/40ae9547c1a21998c591513e30da199c204553ac.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_RCZqv9NXlZ",
      "paper_id": "RCZqv9NXlZ",
      "title": "Offline Reinforcement Learning with Value-based Episodic Memory",
      "authors": "Xiaoteng Ma, Yiqin Yang, Hao Hu, Jun Yang, Chongjie Zhang, Qianchuan Zhao, Bin Liang, Qihan Liu",
      "paper_url": "https://openreview.net/pdf/02371afec918d5a82c74580cda7e3efbf18411d5.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_EW6bNEqalF",
      "paper_id": "EW6bNEqalF",
      "title": "Offline RL in Regular Decision Processes: Sample Efficiency via Language Metrics",
      "authors": "Ahana Deb, Roberto Cipollone, Anders Jonsson, Alessandro Ronca, Mohammad Sadegh Talebi",
      "paper_url": "https://openreview.net/pdf?id=EW6bNEqalF",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_ueYYgo2pSSU",
      "paper_id": "ueYYgo2pSSU",
      "title": "Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization",
      "authors": "Haoran Xu, Li Jiang, Jianxiong Li, Zhuoran Yang, Zhaoran Wang, Victor Wai Kin Chan, Xianyuan Zhan",
      "paper_url": "https://openreview.net/pdf/dbd2c001478b511324bdbec3a393c6f1552fbb3d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_GnOLWS4Llt",
      "paper_id": "GnOLWS4Llt",
      "title": "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity",
      "authors": "Joey Hong, Anca Dragan, Sergey Levine",
      "paper_url": "https://openreview.net/pdf?id=GnOLWS4Llt",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_eY5JNJE56i",
      "paper_id": "eY5JNJE56i",
      "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood",
      "authors": "Qingmao Yao, Zhichao Lei, Tianyuan Chen, Ziyue Yuan, Xuefan Chen, Jianxiang Liu, Faguo Wu, Xiao Zhang",
      "paper_url": "https://openreview.net/pdf?id=eY5JNJE56i",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_M992mjgKzI",
      "paper_id": "M992mjgKzI",
      "title": "OGBench: Benchmarking Offline Goal-Conditioned RL",
      "authors": "Seohong Park, Kevin Frans, Benjamin Eysenbach, Sergey Levine",
      "paper_url": "https://openreview.net/pdf?id=M992mjgKzI",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_w01vBAcewNX",
      "paper_id": "w01vBAcewNX",
      "title": "On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning",
      "authors": "Guy Tennenholtz, Assaf Hallak, Gal Dalal, Shie Mannor, Gal Chechik, Uri Shalit",
      "paper_url": "https://openreview.net/pdf/34d8c65ffe15df7deaa72adf4835d3f9164844de.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_9RIbNmx984",
      "paper_id": "9RIbNmx984",
      "title": "On Double Descent in Reinforcement Learning with LSTD and Random Features",
      "authors": "David Brellmann, Eloïse Berthier, David Filliat, Goran Frehse",
      "paper_url": "https://openreview.net/pdf?id=9RIbNmx984",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_Fl3Mg_MZR-",
      "paper_id": "Fl3Mg_MZR-",
      "title": "On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning",
      "authors": "Marc Vischer, Robert Tjarko Lange, Henning Sprekeler",
      "paper_url": "https://openreview.net/pdf/8e8fd56ca3b46bba9d6db9d68f6fc7df8c828705.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_eUEMjwh5wK",
      "paper_id": "eUEMjwh5wK",
      "title": "On Minimizing Adversarial Counterfactual Error in Adversarial Reinforcement Learning",
      "authors": "Roman Belaire, Arunesh Sinha, Pradeep Varakantham",
      "paper_url": "https://openreview.net/pdf?id=eUEMjwh5wK",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_3K3s9qxSn7",
      "paper_id": "3K3s9qxSn7",
      "title": "On Representation Complexity of Model-based and Model-free Reinforcement Learning",
      "authors": "Hanlin Zhu, Baihe Huang, Stuart Russell",
      "paper_url": "https://openreview.net/pdf?id=3K3s9qxSn7",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_Uh5GRmLlvt",
      "paper_id": "Uh5GRmLlvt",
      "title": "On Rollouts in Model-Based Reinforcement Learning",
      "authors": "Bernd Frauenknecht, Devdutt Subhasish, Friedrich Solowjow, Sebastian Trimpe",
      "paper_url": "https://openreview.net/pdf?id=Uh5GRmLlvt",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_JzNB0eA2-M4",
      "paper_id": "JzNB0eA2-M4",
      "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning",
      "authors": "Che Wang, Shuhan Yuan, Kai Shao, Keith W. Ross",
      "paper_url": "https://openreview.net/pdf/8c7929143db896ebc14d388427a6dc8f388a5e43.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_8Ln-Bq0mZcy",
      "paper_id": "8Ln-Bq0mZcy",
      "title": "On the Critical Role of Conventions in Adaptive Human-AI Collaboration",
      "authors": "Andy Shih, Arjun Sawhney, Jovana Kondic, Stefano Ermon, Dorsa Sadigh",
      "paper_url": "https://openreview.net/pdf/ed63d04dd420c1736ec72390fdca146d1c0a4c85.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_-nm-rHXi5ga",
      "paper_id": "-nm-rHXi5ga",
      "title": "On the Data-Efficiency with Contrastive Image Transformation in Reinforcement Learning",
      "authors": "Sicong Liu, Xi Sheryl Zhang, Yushuo Li, Yifan Zhang, Jian Cheng",
      "paper_url": "https://openreview.net/pdf/42916f46ac828e86998f6f3ae44feae52efdb5ae.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_qr4ECbGcSj",
      "paper_id": "qr4ECbGcSj",
      "title": "On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning",
      "authors": "Rohan Subramani, Marcus Williams, Max Heitmann, Halfdan Holm, Charlie Griffin, Joar Max Viktor Skalse",
      "paper_url": "https://openreview.net/pdf?id=qr4ECbGcSj",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_KB1sc5pNKFv",
      "paper_id": "KB1sc5pNKFv",
      "title": "On the Feasibility of Cross-Task Transfer with Model-Based Reinforcement Learning",
      "authors": "Yifan Xu, Nicklas Hansen, Zirui Wang, Yung-Chieh Chan, Hao Su, Zhuowen Tu",
      "paper_url": "https://openreview.net/pdf/989f4c93e3c9b7bc38369560e925cdfc8ce7b1ed.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_wFWuX1Fhtj",
      "paper_id": "wFWuX1Fhtj",
      "title": "On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning",
      "authors": "Ziyi Chen, Yi Zhou, Heng Huang",
      "paper_url": "https://openreview.net/pdf?id=wFWuX1Fhtj",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_6JMXLWX68Kj",
      "paper_id": "6JMXLWX68Kj",
      "title": "On the Performance of Temporal Difference Learning With Neural Networks",
      "authors": "HAOXING TIAN, Ioannis Paschalidis, Alex Olshevsky",
      "paper_url": "https://openreview.net/pdf/5fcb43e6457009730f100f462843e8388d5d4972.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_jbIYfq4Tr-",
      "paper_id": "jbIYfq4Tr-",
      "title": "On the Robustness of Safe Reinforcement Learning under Observational Perturbations",
      "authors": "Zuxin Liu, Zijian Guo, Zhepeng Cen, Huan Zhang, Jie Tan, Bo Li, Ding Zhao",
      "paper_url": "https://openreview.net/pdf/692f539d83940961224b9d5f7a3aff0536fc6fdd.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_JSS9rKHySk",
      "paper_id": "JSS9rKHySk",
      "title": "On the Role of General Function Approximation in Offline Reinforcement Learning",
      "authors": "Chenjie Mao, Qiaosheng Zhang, Zhen Wang, Xuelong Li",
      "paper_url": "https://openreview.net/pdf?id=JSS9rKHySk",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_IrM64DGB21",
      "paper_id": "IrM64DGB21",
      "title": "On the role of planning in model-based deep reinforcement learning",
      "authors": "Jessica B Hamrick, Abram L. Friesen, Feryal Behbahani, Arthur Guez, Fabio Viola, Sims Witherspoon, Thomas Anthony, Lars Holger Buesing, Petar Veličković, Theophane Weber",
      "paper_url": "https://openreview.net/pdf/e451ad8cff01119850da4fdb852266ebaa8184ce.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_hJqGbUpDGV",
      "paper_id": "hJqGbUpDGV",
      "title": "On the Sensitivity of Reward Inference to Misspecified Human Models",
      "authors": "Joey Hong, Kush Bhatia, Anca Dragan",
      "paper_url": "https://openreview.net/pdf/787489763506d1437ac7b05b15f89ea0beb8c3b1.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_eMNN0wIyVw",
      "paper_id": "eMNN0wIyVw",
      "title": "On Trajectory Augmentations for Off-Policy Evaluation",
      "authors": "Ge Gao, Qitong Gao, Xi Yang, Song Ju, Miroslav Pajic, Min Chi",
      "paper_url": "https://openreview.net/pdf?id=eMNN0wIyVw",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_81e1aeOt-sd",
      "paper_id": "81e1aeOt-sd",
      "title": "On-Policy Model Errors in Reinforcement Learning",
      "authors": "Lukas Froehlich, Maksym Lefarov, Melanie Zeilinger, Felix Berkenkamp",
      "paper_url": "https://openreview.net/pdf/a579d018b07ad6fa046ecc55697be2a1ea96eace.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_18Ys0-PzyPI",
      "paper_id": "18Ys0-PzyPI",
      "title": "Online Ad Hoc Teamwork under Partial Observability",
      "authors": "Pengjie Gu, Mengchen Zhao, Jianye Hao, Bo An",
      "paper_url": "https://openreview.net/pdf/69ebe98356c87ca06fb980028a882b8bf4ea9078.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_l6QnSQizmN",
      "paper_id": "l6QnSQizmN",
      "title": "Online Reinforcement Learning in Non-Stationary Context-Driven Environments",
      "authors": "Pouya Hamadanian, Arash Nasr-Esfahany, Malte Schwarzkopf, Siddhartha Sen, Mohammad Alizadeh",
      "paper_url": "https://openreview.net/pdf?id=l6QnSQizmN",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_HMJdXzbWKH",
      "paper_id": "HMJdXzbWKH",
      "title": "Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs",
      "authors": "Naman Agarwal, Syomantak Chaudhuri, Prateek Jain, Dheeraj Mysore Nagaraj, Praneeth Netrapalli",
      "paper_url": "https://openreview.net/pdf/6b594a687dec20908b7cad9a357b456275c44067.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_V69LGwJ0lIN",
      "paper_id": "V69LGwJ0lIN",
      "title": "OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning",
      "authors": "Anurag Ajay, Aviral Kumar, Pulkit Agrawal, Sergey Levine, Ofir Nachum",
      "paper_url": "https://openreview.net/pdf/b57bd58e05e17b49da003dded33a75506b9ddbac.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_mnipav175N",
      "paper_id": "mnipav175N",
      "title": "Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning",
      "authors": "Ge Li, Hongyi Zhou, Dominik Roth, Serge Thilges, Fabian Otto, Rudolf Lioutikov, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf?id=mnipav175N",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_vzItLaEoDa",
      "paper_id": "vzItLaEoDa",
      "title": "Open-World Reinforcement Learning over Long Short-Term Imagination",
      "authors": "Jiajian Li, Qi Wang, Yunbo Wang, Xin Jin, Yang Li, Wenjun Zeng, Xiaokang Yang",
      "paper_url": "https://openreview.net/pdf?id=vzItLaEoDa",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_fGIqGfmgkW",
      "paper_id": "fGIqGfmgkW",
      "title": "OpenPRM: Building Open-domain Process-based Reward Models with Preference Trees",
      "authors": "Kaiyan Zhang, Jiayuan Zhang, Haoxin Li, Xuekai Zhu, Ermo Hua, Xingtai Lv, Ning Ding, Biqing Qi, Bowen Zhou",
      "paper_url": "https://openreview.net/pdf?id=fGIqGfmgkW",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_ZsvWb6mJnMv",
      "paper_id": "ZsvWb6mJnMv",
      "title": "Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian",
      "authors": "Paria Rashidinejad, Hanlin Zhu, Kunhe Yang, Stuart Russell, Jiantao Jiao",
      "paper_url": "https://openreview.net/pdf/1e66fdaab805cebe5a84c568baa5b2a817e6b6f3.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_WuTczPV8WC",
      "paper_id": "WuTczPV8WC",
      "title": "Optimal Non-Asymptotic Rates of Value Iteration for Average-Reward Markov Decision Processes",
      "authors": "Jongmin Lee, Ernest K. Ryu",
      "paper_url": "https://openreview.net/pdf?id=WuTczPV8WC",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_jOm5p3q7c7",
      "paper_id": "jOm5p3q7c7",
      "title": "Optimal Sample Complexity for Average Reward Markov Decision Processes",
      "authors": "Shengbo Wang, Jose Blanchet, Peter Glynn",
      "paper_url": "https://openreview.net/pdf?id=jOm5p3q7c7",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_8eNLKk5by4",
      "paper_id": "8eNLKk5by4",
      "title": "Optimal Strong Regret and Violation in Constrained MDPs via Policy Optimization",
      "authors": "Francesco Emanuele Stradi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti",
      "paper_url": "https://openreview.net/pdf?id=8eNLKk5by4",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_MhuFzFsrfvH",
      "paper_id": "MhuFzFsrfvH",
      "title": "Optimal Transport for Offline Imitation Learning",
      "authors": "Yicheng Luo, zhengyao jiang, Samuel Cohen, Edward Grefenstette, Marc Peter Deisenroth",
      "paper_url": "https://openreview.net/pdf/3c2503af4f49d5f2f79a720075d8cfc042c50960.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_CBmJwzneppz",
      "paper_id": "CBmJwzneppz",
      "title": "Optimism in Reinforcement Learning with Generalized Linear Function Approximation",
      "authors": "Yining Wang, Ruosong Wang, Simon Shaolei Du, Akshay Krishnamurthy",
      "paper_url": "https://openreview.net/pdf/a233880f2576e4e435aefcdb4dce873e39557072.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_9kBCMNb5mc",
      "paper_id": "9kBCMNb5mc",
      "title": "Optimistic Exploration with Learned Features Provably Solves Markov Decision Processes with Neural Dynamics",
      "authors": "Sirui Zheng, Lingxiao Wang, Shuang Qiu, Zuyue Fu, Zhuoran Yang, Csaba Szepesvari, Zhaoran Wang",
      "paper_url": "https://openreview.net/pdf/6687b0c4eba4ceed801d08a370d455f00edc668e.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_Xj66fkrlTk",
      "paper_id": "Xj66fkrlTk",
      "title": "Optimizing Backward Policies in GFlowNets via Trajectory Likelihood Maximization",
      "authors": "Timofei Gritsaev, Nikita Morozov, Sergey Samsonov, Daniil Tiapkin",
      "paper_url": "https://openreview.net/pdf?id=Xj66fkrlTk",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_3IFRygQKGL",
      "paper_id": "3IFRygQKGL",
      "title": "OptionZero: Planning with Learned Options",
      "authors": "Po-Wei Huang, Pei-Chiun Peng, Hung Guei, Ti-Rong Wu",
      "paper_url": "https://openreview.net/pdf?id=3IFRygQKGL",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_c87d0TS4yX",
      "paper_id": "c87d0TS4yX",
      "title": "Orchestrated Value Mapping for Reinforcement Learning",
      "authors": "Mehdi Fatemi, Arash Tavakoli",
      "paper_url": "https://openreview.net/pdf/9ef3cef089b9f45f5bdb93fddb0ed8ccfa9e3268.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_Q-neeWNVv1",
      "paper_id": "Q-neeWNVv1",
      "title": "Order Matters: Agent-by-agent Policy Optimization",
      "authors": "Xihuai Wang, Zheng Tian, Ziyu Wan, Ying Wen, Jun Wang, Weinan Zhang",
      "paper_url": "https://openreview.net/pdf/b7c35e63818d65e4523a6ae4314674a0eeb7bb36.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_0uRc3CfJIQ",
      "paper_id": "0uRc3CfJIQ",
      "title": "ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization",
      "authors": "Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal",
      "paper_url": "https://openreview.net/pdf?id=0uRc3CfJIQ",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_v69itrHLEu",
      "paper_id": "v69itrHLEu",
      "title": "Outcome-directed Reinforcement Learning by Uncertainty \\& Temporal Distance-Aware Curriculum Goal Generation",
      "authors": "Daesol Cho, Seungjae Lee, H. Jin Kim",
      "paper_url": "https://openreview.net/pdf/2c6db8a4ff69ca681456fe5e686ec86f942d3e12.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_w3iM4WLuvy",
      "paper_id": "w3iM4WLuvy",
      "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control",
      "authors": "Devdhar Patel, Hava T Siegelmann",
      "paper_url": "https://openreview.net/pdf?id=w3iM4WLuvy",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_hlvLM3GX8R",
      "paper_id": "hlvLM3GX8R",
      "title": "OvercookedV2: Rethinking Overcooked for Zero-Shot Coordination",
      "authors": "Tobias Gessler, Tin Dizdarevic, Ani Calinescu, Benjamin Ellis, Andrei Lupu, Jakob Nicolaus Foerster",
      "paper_url": "https://openreview.net/pdf?id=hlvLM3GX8R",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_FVW7Mi2ph6C",
      "paper_id": "FVW7Mi2ph6C",
      "title": "PAC Reinforcement Learning for Predictive State Representations",
      "authors": "Wenhao Zhan, Masatoshi Uehara, Wen Sun, Jason D. Lee",
      "paper_url": "https://openreview.net/pdf/941de44dfb72523d9b742410898c1ab3b02009fe.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_R7rZUSGOPD",
      "paper_id": "R7rZUSGOPD",
      "title": "PAE: Reinforcement Learning from External Knowledge for Efficient Exploration",
      "authors": "Zhe Wu, Haofei Lu, Junliang Xing, You Wu, Renye Yan, Yaozhong Gan, Yuanchun Shi",
      "paper_url": "https://openreview.net/pdf?id=R7rZUSGOPD",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_tV6oBfuyLTQ",
      "paper_id": "tV6oBfuyLTQ",
      "title": "Parameter-Based Value Functions",
      "authors": "Francesco Faccio, Louis Kirsch, Jürgen Schmidhuber",
      "paper_url": "https://openreview.net/pdf/c79ef13431e3c5decbd9f2ba989bc20a847b37be.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_OqcZu8JIIzS",
      "paper_id": "OqcZu8JIIzS",
      "title": "Pareto Policy Pool for Model-based Offline Reinforcement Learning",
      "authors": "Yijun Yang, Jing Jiang, Tianyi Zhou, Jie Ma, Yuhui Shi",
      "paper_url": "https://openreview.net/pdf/811177d23b2117fa0be0cc22952e7c1e3325bf59.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_ByR3NdDSZB",
      "paper_id": "ByR3NdDSZB",
      "title": "PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback",
      "authors": "Souradip Chakraborty, Amrit Bedi, Alec Koppel, Huazheng Wang, Dinesh Manocha, Mengdi Wang, Furong Huang",
      "paper_url": "https://openreview.net/pdf?id=ByR3NdDSZB",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_Ysuv-WOFeKR",
      "paper_id": "Ysuv-WOFeKR",
      "title": "Parrot: Data-Driven Behavioral Priors for Reinforcement Learning",
      "authors": "Avi Singh, Huihan Liu, Gaoyue Zhou, Albert Yu, Nicholas Rhinehart, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/7ace651a0c4f40194198a9ab3ea9aefadb191c77.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_n05upKp02kQ",
      "paper_id": "n05upKp02kQ",
      "title": "Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms",
      "authors": "Fan Chen, Yu Bai, Song Mei",
      "paper_url": "https://openreview.net/pdf/72aa8e574f037ca63f878f9b771e8fdb68841877.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_0nJEgNpb4l",
      "paper_id": "0nJEgNpb4l",
      "title": "PEAR: Primitive Enabled Adaptive Relabeling for Boosting Hierarchical Reinforcement Learning",
      "authors": "Utsav Singh, Vinay P. Namboodiri",
      "paper_url": "https://openreview.net/pdf?id=0nJEgNpb4l",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_-HSOjDPfhBJ",
      "paper_id": "-HSOjDPfhBJ",
      "title": "PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method",
      "authors": "Ziwei Guan, Tengyu Xu, Yingbin Liang",
      "paper_url": "https://openreview.net/pdf/d54fba2211a4e058d2052bf8de3fb0bdb631060b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_20gBzEzgtiI",
      "paper_id": "20gBzEzgtiI",
      "title": "Performance Bounds for Model and Policy Transfer in Hidden-parameter MDPs",
      "authors": "Haotian Fu, Jiayu Yao, Omer Gottesman, Finale Doshi-Velez, George Konidaris",
      "paper_url": "https://openreview.net/pdf/60d3574f06987c12eb924a57883c12320d9eec12.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_otYAwaTDk1",
      "paper_id": "otYAwaTDk1",
      "title": "Perlin Noise for Exploration in Reinforcement Learning",
      "authors": "Dominik Roth, Onur Celik, Fabian Otto, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf?id=otYAwaTDk1",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_wGvzQWFyUB",
      "paper_id": "wGvzQWFyUB",
      "title": "Personalized Reward Learning with Interaction-Grounded Learning (IGL)",
      "authors": "Jessica Maghakian, Paul Mineiro, Kishan Panaganti, Mark Rucker, Akanksha Saran, Cheng Tan",
      "paper_url": "https://openreview.net/pdf/f1866bfb98a0b15a96694c234259fcbf8f91e3b8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_PbkBDQ5_UbV",
      "paper_id": "PbkBDQ5_UbV",
      "title": "Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes",
      "authors": "Miao Lu, Yifei Min, Zhaoran Wang, Zhuoran Yang",
      "paper_url": "https://openreview.net/pdf/50f1a65a8ac6404dd76325fe84b34c5695ba7360.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_Y4cs1Z3HnqL",
      "paper_id": "Y4cs1Z3HnqL",
      "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning",
      "authors": "Chenjia Bai, Lingxiao Wang, Zhuoran Yang, Zhi-Hong Deng, Animesh Garg, Peng Liu, Zhaoran Wang",
      "paper_url": "https://openreview.net/pdf/cbca2d6ef1966129d7e95e65cae5bec0dc19f0ea.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_tyrJsbKAe6",
      "paper_id": "tyrJsbKAe6",
      "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage",
      "authors": "Masatoshi Uehara, Wen Sun",
      "paper_url": "https://openreview.net/pdf/d15bd4853bbe7787fe5fd4a9ffa5c164ac6e2d90.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_4kLVvIh8cp",
      "paper_id": "4kLVvIh8cp",
      "title": "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning",
      "authors": "Qiwei Di, Heyang Zhao, Jiafan He, Quanquan Gu",
      "paper_url": "https://openreview.net/pdf?id=4kLVvIh8cp",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_hOMVq57Ce0",
      "paper_id": "hOMVq57Ce0",
      "title": "Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning",
      "authors": "Maxime Wabartha, Joelle Pineau",
      "paper_url": "https://openreview.net/pdf?id=hOMVq57Ce0",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_OkHHJcMroY",
      "paper_id": "OkHHJcMroY",
      "title": "PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation",
      "authors": "Zhuqing Liu, Xin Zhang, Jia Liu, Zhengyuan Zhu, Songtao Lu",
      "paper_url": "https://openreview.net/pdf?id=OkHHJcMroY",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_hQ9V5QN27eS",
      "paper_id": "hQ9V5QN27eS",
      "title": "Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning",
      "authors": "Onno Eberhard, Jakob Hollenstein, Cristina Pinneri, Georg Martius",
      "paper_url": "https://openreview.net/pdf/9eb6698653898299e855964e9b4950f0e56ab28c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_w2Z2OwVNeK",
      "paper_id": "w2Z2OwVNeK",
      "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks",
      "authors": "Ingmar Schubert, Ozgur S Oguz, Marc Toussaint",
      "paper_url": "https://openreview.net/pdf/6ab6b9e3a9fe5a364f986aaff177de866990899b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_V6BjBgku7Ro",
      "paper_id": "V6BjBgku7Ro",
      "title": "Planning from Pixels using Inverse Dynamics Models",
      "authors": "Keiran Paster, Sheila A. McIlraith, Jimmy Ba",
      "paper_url": "https://openreview.net/pdf/e1667f4513f3892a3eac139e23ee5198363e6741.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_6qeBuZSo7Pr",
      "paper_id": "6qeBuZSo7Pr",
      "title": "Planning Goals for Exploration",
      "authors": "Edward S. Hu, Richard Chang, Oleh Rybkin, Dinesh Jayaraman",
      "paper_url": "https://openreview.net/pdf/b28237bb9e4d96d5f02a9d0639565db68727d08c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_X6D9bAHhBQ1",
      "paper_id": "X6D9bAHhBQ1",
      "title": "Planning in Stochastic Environments with a Learned Model",
      "authors": "Ioannis Antonoglou, Julian Schrittwieser, Sherjil Ozair, Thomas K Hubert, David Silver",
      "paper_url": "https://openreview.net/pdf/f49fc80947707469997960f573102cea38cafb0f.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_0e2pcSxQJS",
      "paper_id": "0e2pcSxQJS",
      "title": "PN-GAIL: Leveraging Non-optimal Information from Imperfect Demonstrations",
      "authors": "Qiang Liu, Huiqiao Fu, Kaiqiang Tang, Chunlin Chen, Daoyi Dong",
      "paper_url": "https://openreview.net/pdf?id=0e2pcSxQJS",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_AJsI-ymaKn_",
      "paper_id": "AJsI-ymaKn_",
      "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
      "authors": "Alizée Pace, Alex Chan, Mihaela van der Schaar",
      "paper_url": "https://openreview.net/pdf/18b6779789f76ccc8b7ff5e0a77ec0fa2a5d4057.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_e5jGTEiJMT",
      "paper_id": "e5jGTEiJMT",
      "title": "Policy Decorator: Model-Agnostic Online Refinement for Large Policy Model",
      "authors": "Xiu Yuan, Tongzhou Mu, Stone Tao, Yunhao Fang, Mengke Zhang, Hao Su",
      "paper_url": "https://openreview.net/pdf?id=e5jGTEiJMT",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_-Y34L45JR6z",
      "paper_id": "-Y34L45JR6z",
      "title": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning",
      "authors": "Haichao Zhang, Wei Xu, Haonan Yu",
      "paper_url": "https://openreview.net/pdf/bc171436c99bb31ea2d883553ed3204db027ced8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_EHaUTlm2eHg",
      "paper_id": "EHaUTlm2eHg",
      "title": "Policy Gradients Incorporating the Future",
      "authors": "David Venuto, Elaine Lau, Doina Precup, Ofir Nachum",
      "paper_url": "https://openreview.net/pdf/1bc7c8d13a1713bf5e86827cb71b07a2d36496ad.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_bERaNdoegnO",
      "paper_id": "bERaNdoegnO",
      "title": "Policy improvement by planning with Gumbel",
      "authors": "Ivo Danihelka, Arthur Guez, Julian Schrittwieser, David Silver",
      "paper_url": "https://openreview.net/pdf/4f2c0c813d0fbe127329c69b1ba216fbcd95d52c.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_LfekK1E0QE",
      "paper_id": "LfekK1E0QE",
      "title": "Policy Optimization under Imperfect Human Interactions with Agent-Gated Shared Autonomy",
      "authors": "Zhenghai Xue, Bo An, Shuicheng YAN",
      "paper_url": "https://openreview.net/pdf?id=LfekK1E0QE",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_m3xVPaZp6Z",
      "paper_id": "m3xVPaZp6Z",
      "title": "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning",
      "authors": "Chengxing Jia, Chenxiao Gao, Hao Yin, Fuxiang Zhang, Xiong-Hui Chen, Tian Xu, Lei Yuan, Zongzhang Zhang, Zhi-Hua Zhou, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=m3xVPaZp6Z",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_mwdfai8NBrJ",
      "paper_id": "mwdfai8NBrJ",
      "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
      "authors": "Aounon Kumar, Alexander Levine, Soheil Feizi",
      "paper_url": "https://openreview.net/pdf/b1ed375c6d8559126ca3c590cf47feff1ae81aeb.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_SmufNDN90G",
      "paper_id": "SmufNDN90G",
      "title": "Policy-Based Self-Competition for Planning Problems",
      "authors": "Jonathan Pirnay, Quirin Göttl, Jakob Burger, Dominik Gerhard Grimm",
      "paper_url": "https://openreview.net/pdf/e3b41709a4697b503c61af4852343e17df76da28.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_chDrutUTs0K",
      "paper_id": "chDrutUTs0K",
      "title": "POPGym: Benchmarking Partially Observable Reinforcement Learning",
      "authors": "Steven Morad, Ryan Kortvelesy, Matteo Bettini, Stephan Liwicki, Amanda Prorok",
      "paper_url": "https://openreview.net/pdf/9dfc2ae9e672bdd44ff589054c88b18924af8483.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_o2IEmeLL9r",
      "paper_id": "o2IEmeLL9r",
      "title": "Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning",
      "authors": "Haoqi Yuan, Zhancun Mu, Feiyang Xie, Zongqing Lu",
      "paper_url": "https://openreview.net/pdf?id=o2IEmeLL9r",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_PcxQgtHGj2",
      "paper_id": "PcxQgtHGj2",
      "title": "Pre-training with Synthetic Data Helps Offline Reinforcement Learning",
      "authors": "Zecheng Wang, Che Wang, Zixuan Dong, Keith W. Ross",
      "paper_url": "https://openreview.net/pdf?id=PcxQgtHGj2",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_Ptaz_zIFbX",
      "paper_id": "Ptaz_zIFbX",
      "title": "Prediction and generalisation over directed actions by grid cells",
      "authors": "Changmin Yu, Timothy Behrens, Neil Burgess",
      "paper_url": "https://openreview.net/pdf/708e623b918bb762d8cc7249aa89623b0dad19d6.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_agPpmEgf8C",
      "paper_id": "agPpmEgf8C",
      "title": "Predictive auxiliary objectives in deep RL mimic learning in the brain",
      "authors": "Ching Fang, Kim Stachenfeld",
      "paper_url": "https://openreview.net/pdf?id=agPpmEgf8C",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_2pJpFtdVNe",
      "paper_id": "2pJpFtdVNe",
      "title": "Preference Elicitation for Offline Reinforcement Learning",
      "authors": "Alizée Pace, Bernhard Schölkopf, Gunnar Ratsch, Giorgia Ramponi",
      "paper_url": "https://openreview.net/pdf?id=2pJpFtdVNe",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_Peot1SFDX0",
      "paper_id": "Peot1SFDX0",
      "title": "Preference Transformer: Modeling Human Preferences using Transformers for RL",
      "authors": "Changyeon Kim, Jongjin Park, Jinwoo Shin, Honglak Lee, Pieter Abbeel, Kimin Lee",
      "paper_url": "https://openreview.net/pdf/8a47190a33890c3b90463d493dc6f9bb78af91ee.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_KAIqwkB3dT",
      "paper_id": "KAIqwkB3dT",
      "title": "Prevalence of Negative Transfer in Continual Reinforcement Learning: Analyses and a Simple Baseline",
      "authors": "Hongjoon Ahn, Jinu Hyeon, Youngmin Oh, Bosun Hwang, Taesup Moon",
      "paper_url": "https://openreview.net/pdf?id=KAIqwkB3dT",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_TtYSU29zgR",
      "paper_id": "TtYSU29zgR",
      "title": "Primal Wasserstein Imitation Learning",
      "authors": "Robert Dadashi, Leonard Hussenot, Matthieu Geist, Olivier Pietquin",
      "paper_url": "https://openreview.net/pdf/a0cf4ec3c4a75e202ba613caaea4f173d8e53101.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_5IkDAfabuo",
      "paper_id": "5IkDAfabuo",
      "title": "Prioritized Generative Replay",
      "authors": "Renhao Wang, Kevin Frans, Pieter Abbeel, Sergey Levine, Alexei A Efros",
      "paper_url": "https://openreview.net/pdf?id=5IkDAfabuo",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_c0MyyXyGfn",
      "paper_id": "c0MyyXyGfn",
      "title": "Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning",
      "authors": "Finn Rietz, Erik Schaffernicht, Stefan Heinrich, Johannes A. Stork",
      "paper_url": "https://openreview.net/pdf?id=c0MyyXyGfn",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_0v4VkCSkHNm",
      "paper_id": "0v4VkCSkHNm",
      "title": "Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning",
      "authors": "Sasha Salter, Kristian Hartikainen, Walter Goodwin, Ingmar Posner",
      "paper_url": "https://openreview.net/pdf/c363ed9425c2f59718edea214b3ce8625578da08.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_EpVe8jAjdx",
      "paper_id": "EpVe8jAjdx",
      "title": "Privileged Sensing Scaffolds Reinforcement Learning",
      "authors": "Edward S. Hu, James Springer, Oleh Rybkin, Dinesh Jayaraman",
      "paper_url": "https://openreview.net/pdf?id=EpVe8jAjdx",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_FmBegXJToY",
      "paper_id": "FmBegXJToY",
      "title": "Procedural generalization by planning with self-supervised world models",
      "authors": "Ankesh Anand, Jacob C Walker, Yazhe Li, Eszter Vértes, Julian Schrittwieser, Sherjil Ozair, Theophane Weber, Jessica B Hamrick",
      "paper_url": "https://openreview.net/pdf/aff2220dd1aea0f7b326e525fa1ed3f25efe2eb8.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_6Tk2noBdvxt",
      "paper_id": "6Tk2noBdvxt",
      "title": "Programmatic Reinforcement Learning without Oracles",
      "authors": "Wenjie Qiu, He Zhu",
      "paper_url": "https://openreview.net/pdf/92dbdb48fe9a64f9e46e509762a9443b84450f68.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_nfIAEJFiBZ",
      "paper_id": "nfIAEJFiBZ",
      "title": "Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo",
      "authors": "Haque Ishfaq, Qingfeng Lan, Pan Xu, A. Rupam Mahmood, Doina Precup, Anima Anandkumar, Kamyar Azizzadenesheli",
      "paper_url": "https://openreview.net/pdf?id=nfIAEJFiBZ",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_U6Qulbv2qT",
      "paper_id": "U6Qulbv2qT",
      "title": "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes",
      "authors": "Ruiquan Huang, Yuan Cheng, Jing Yang, Vincent Tan, Yingbin Liang",
      "paper_url": "https://openreview.net/pdf?id=U6Qulbv2qT",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_vNiI3aGcE6",
      "paper_id": "vNiI3aGcE6",
      "title": "Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning",
      "authors": "Na Li, Yuchen Jiao, Hangguan Shan, Shefeng Yan",
      "paper_url": "https://openreview.net/pdf?id=vNiI3aGcE6",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_tVMPfEGT2w",
      "paper_id": "tVMPfEGT2w",
      "title": "Provable Offline Preference-Based Reinforcement Learning",
      "authors": "Wenhao Zhan, Masatoshi Uehara, Nathan Kallus, Jason D. Lee, Wen Sun",
      "paper_url": "https://openreview.net/pdf?id=tVMPfEGT2w",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_yTBXeXdbMf",
      "paper_id": "yTBXeXdbMf",
      "title": "Provable Reward-Agnostic Preference-Based Reinforcement Learning",
      "authors": "Wenhao Zhan, Masatoshi Uehara, Wen Sun, Jason D. Lee",
      "paper_url": "https://openreview.net/pdf?id=yTBXeXdbMf",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_hx1IXFHAw7R",
      "paper_id": "hx1IXFHAw7R",
      "title": "Provable Rich Observation Reinforcement Learning with Combinatorial Latent States",
      "authors": "Dipendra Misra, Qinghua Liu, Chi Jin, John Langford",
      "paper_url": "https://openreview.net/pdf/6a01a542edf09482d75550c673ddcb462727111a.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_S31oTB72m0G",
      "paper_id": "S31oTB72m0G",
      "title": "Provable Sim-to-real Transfer in Continuous Domain with Partial Observations",
      "authors": "Jiachen Hu, Han Zhong, Chi Jin, Liwei Wang",
      "paper_url": "https://openreview.net/pdf/515b0ec07db7d7e603d68eda09eb8978669607f4.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_9x6yrFAPnx",
      "paper_id": "9x6yrFAPnx",
      "title": "Provably Efficient CVaR RL in Low-rank MDPs",
      "authors": "Yulai Zhao, Wenhao Zhan, Xiaoyan Hu, Ho-fung Leung, Farzan Farnia, Wen Sun, Jason D. Lee",
      "paper_url": "https://openreview.net/pdf?id=9x6yrFAPnx",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_vW1SkPl4kp",
      "paper_id": "vW1SkPl4kp",
      "title": "Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback",
      "authors": "Yu Chen, Yihan Du, Pihe Hu, Siwei Wang, Desheng Wu, Longbo Huang",
      "paper_url": "https://openreview.net/pdf?id=vW1SkPl4kp",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_Qd0p0bl-A9t",
      "paper_id": "Qd0p0bl-A9t",
      "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Representation",
      "authors": "Sanae Amani, Lin Yang, Ching-An Cheng",
      "paper_url": "https://openreview.net/pdf/2e81dc2a2f2529b307345174708e2ffa49eb464e.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_Yn0xg-kHNW-",
      "paper_id": "Yn0xg-kHNW-",
      "title": "Provably Efficient Risk-Sensitive Reinforcement Learning: Iterated CVaR and Worst Path",
      "authors": "Yihan Du, Siwei Wang, Longbo Huang",
      "paper_url": "https://openreview.net/pdf/522515c753abedbb1309e0ee55893ed3b4e91f6c.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_jId5PXbBbX",
      "paper_id": "jId5PXbBbX",
      "title": "Provably Efficient UCB-type Algorithms For Learning Predictive State Representations",
      "authors": "Ruiquan Huang, Yingbin Liang, Jing Yang",
      "paper_url": "https://openreview.net/pdf?id=jId5PXbBbX",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_TFKIfhvdmZ",
      "paper_id": "TFKIfhvdmZ",
      "title": "Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning",
      "authors": "Sumeet Batra, Bryon Tjanaka, Matthew Christopher Fontaine, Aleksei Petrenko, Stefanos Nikolaidis, Gaurav S. Sukhatme",
      "paper_url": "https://openreview.net/pdf?id=TFKIfhvdmZ",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_G32oY4Vnm8",
      "paper_id": "G32oY4Vnm8",
      "title": "PTaRL: Prototype-based Tabular Representation Learning via Space Calibration",
      "authors": "Hangting Ye, Wei Fan, Xiaozhuang Song, Shun Zheng, He Zhao, Dan dan Guo, Yi Chang",
      "paper_url": "https://openreview.net/pdf?id=G32oY4Vnm8",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_hOELrZfg0J",
      "paper_id": "hOELrZfg0J",
      "title": "PWM: Policy Learning with Multi-Task World Models",
      "authors": "Ignat Georgiev, Varun Giridhar, Nicklas Hansen, Animesh Garg",
      "paper_url": "https://openreview.net/pdf?id=hOELrZfg0J",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_aUZEeb2yvK",
      "paper_id": "aUZEeb2yvK",
      "title": "QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing",
      "authors": "Grace Zhang, Ayush Jain, Injune Hwang, Shao-Hua Sun, Joseph J Lim",
      "paper_url": "https://openreview.net/pdf?id=aUZEeb2yvK",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_Rcmk0xxIQV",
      "paper_id": "Rcmk0xxIQV",
      "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning",
      "authors": "Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/b346f46b6a8ed100f25b8d16fde7d2500965fd70.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_bLmSMXbqXr",
      "paper_id": "bLmSMXbqXr",
      "title": "Quality-Similar Diversity via Population Based Reinforcement Learning",
      "authors": "Shuang Wu, Jian Yao, Haobo Fu, Ye Tian, Chao Qian, Yaodong Yang, QIANG FU, Yang Wei",
      "paper_url": "https://openreview.net/pdf/d8f5cd723fc580efed10ef08df13eda8c3ad877f.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_LwEQnp6CYev",
      "paper_id": "LwEQnp6CYev",
      "title": "Quantifying Differences in Reward Functions",
      "authors": "Adam Gleave, Michael D Dennis, Shane Legg, Stuart Russell, Jan Leike",
      "paper_url": "https://openreview.net/pdf/c9babbffccc1b8e389a2e8de1c7aac4cee00f966.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_pz2E1Q9Wni",
      "paper_id": "pz2E1Q9Wni",
      "title": "Quantifying the Sensitivity of Inverse Reinforcement Learning to Misspecification",
      "authors": "Joar Max Viktor Skalse, Alessandro Abate",
      "paper_url": "https://openreview.net/pdf?id=pz2E1Q9Wni",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_O8Vc52xFSUR",
      "paper_id": "O8Vc52xFSUR",
      "title": "Quasi-optimal Reinforcement Learning with Continuous Actions",
      "authors": "Yuhan Li, Wenzhuo Zhou, Ruoqing Zhu",
      "paper_url": "https://openreview.net/pdf/100ce9435fb820f433bb2a423491a43ed4f64862.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_UoBymIwPJR",
      "paper_id": "UoBymIwPJR",
      "title": "Query-Policy Misalignment in Preference-Based Reinforcement Learning",
      "authors": "Xiao Hu, Jianxiong Li, Xianyuan Zhan, Qing-Shan Jia, Ya-Qin Zhang",
      "paper_url": "https://openreview.net/pdf?id=UoBymIwPJR",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_AY8zfZm0tDd",
      "paper_id": "AY8zfZm0tDd",
      "title": "Randomized Ensembled Double Q-Learning: Learning Fast Without a Model",
      "authors": "Xinyue Chen, Che Wang, Zijian Zhou, Keith W. Ross",
      "paper_url": "https://openreview.net/pdf/c4e6642e1eb45768ab5d7a3291c2a0088665e5c4.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_MtEE0CktZht",
      "paper_id": "MtEE0CktZht",
      "title": "Rank the Episodes: A Simple Approach for Exploration in Procedurally-Generated Environments",
      "authors": "Daochen Zha, Wenye Ma, Lei Yuan, Xia Hu, Ji Liu",
      "paper_url": "https://openreview.net/pdf/1a3486946250b679d39b93e6b12ff912023a3955.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_F-mvpFpn_0q",
      "paper_id": "F-mvpFpn_0q",
      "title": "Rapid Task-Solving in Novel Environments",
      "authors": "Samuel Ritter, Ryan Faulkner, Laurent Sartran, Adam Santoro, Matthew Botvinick, David Raposo",
      "paper_url": "https://openreview.net/pdf/2a2a34541a2b4e34e92e1050f5935a08cca0163b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_XwUrzurG94",
      "paper_id": "XwUrzurG94",
      "title": "Rapidly Adapting Policies to the Real-World via Simulation-Guided Fine-Tuning",
      "authors": "Patrick Yin, Tyler Westenbroek, Ching-An Cheng, Andrey Kolobov, Abhishek Gupta",
      "paper_url": "https://openreview.net/pdf?id=XwUrzurG94",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_tGQirjzddO",
      "paper_id": "tGQirjzddO",
      "title": "Reasoning with Latent Diffusion in Offline Reinforcement Learning",
      "authors": "Siddarth Venkatraman, Shivesh Khaitan, Ravi Tej Akella, John Dolan, Jeff Schneider, Glen Berseth",
      "paper_url": "https://openreview.net/pdf?id=tGQirjzddO",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_Y8L5RB4GWb",
      "paper_id": "Y8L5RB4GWb",
      "title": "Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency",
      "authors": "Liang Qifan, Yixiang Shan, Haipeng Liu, Zhengbang Zhu, Ting Long, Weinan Zhang, Yuan Tian",
      "paper_url": "https://openreview.net/pdf?id=Y8L5RB4GWb",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_mLcmdlEUxy-",
      "paper_id": "mLcmdlEUxy-",
      "title": "Recurrent Independent Mechanisms",
      "authors": "Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine, Yoshua Bengio, Bernhard Schölkopf",
      "paper_url": "https://openreview.net/pdf/a58297a8b9fc47b94fee061cf119f991c6bb2a87.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_NxyfSW6mLK",
      "paper_id": "NxyfSW6mLK",
      "title": "REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments",
      "authors": "Kaustubh Sridhar, Souradeep Dutta, Dinesh Jayaraman, Insup Lee",
      "paper_url": "https://openreview.net/pdf?id=NxyfSW6mLK",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_VD4PFpecG2",
      "paper_id": "VD4PFpecG2",
      "title": "Regret Bounds for Episodic Risk-Sensitive Linear Quadratic Regulator",
      "authors": "Wenhao XU, Xuefeng Gao, Xuedong He",
      "paper_url": "https://openreview.net/pdf?id=VD4PFpecG2",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_yr1mzrH3IC",
      "paper_id": "yr1mzrH3IC",
      "title": "Regularization Matters in Policy Optimization - An Empirical Study on Continuous Control",
      "authors": "Zhuang Liu, Xuanlin Li, Bingyi Kang, Trevor Darrell",
      "paper_url": "https://openreview.net/pdf/4ea87f9a661822f24e9371710f2f815e90d8bd23.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_HgLO8yalfwc",
      "paper_id": "HgLO8yalfwc",
      "title": "Regularized Inverse Reinforcement Learning",
      "authors": "Wonseok Jeon, Chen-Yang Su, Paul Barde, Thang Doan, Derek Nowrouzezahrai, Joelle Pineau",
      "paper_url": "https://openreview.net/pdf/fdd6861c0f1a3c729dc7a2d59344633293d0df3e.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_dsHpulHpOK",
      "paper_id": "dsHpulHpOK",
      "title": "Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics",
      "authors": "Josiah C Kratz, Jacob Adamczyk",
      "paper_url": "https://openreview.net/pdf?id=dsHpulHpOK",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_JTji0Jfh5a",
      "paper_id": "JTji0Jfh5a",
      "title": "Reinforcement Learning from Imperfect Corrective Actions and Proxy Rewards",
      "authors": "Zhaohui JIANG, Xuening Feng, Paul Weng, Yifei Zhu, Yan Song, Tianze Zhou, Yujing Hu, Tangjie Lv, Changjie Fan",
      "paper_url": "https://openreview.net/pdf?id=JTji0Jfh5a",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_CmsfC7u054S",
      "paper_id": "CmsfC7u054S",
      "title": "Reinforcement Learning in Presence of Discrete Markovian Context Evolution",
      "authors": "Hang Ren, Aivar Sootla, Taher Jafferjee, Junxiao Shen, Jun Wang, Haitham Bou Ammar",
      "paper_url": "https://openreview.net/pdf/53bda3136fe85f6fe3bed9a024f40991920a62fc.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_PLDOnFoVm4",
      "paper_id": "PLDOnFoVm4",
      "title": "Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory",
      "authors": "Zhi Zhang, Zhuoran Yang, Han Liu, Pratap Tokekar, Furong Huang",
      "paper_url": "https://openreview.net/pdf/abd7a0683441b4eb75fb4381e8ac583f2bff2b90.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_QFYnKlBJYR",
      "paper_id": "QFYnKlBJYR",
      "title": "Reinforcement Learning with Random Delays",
      "authors": "Yann Bouteiller, Simon Ramstedt, Giovanni Beltrame, Christopher Pal, Jonathan Binas",
      "paper_url": "https://openreview.net/pdf/744fcf663d9a7335f90ed1ec81d97b3661166e56.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_YJ1WzgMVsMt",
      "paper_id": "YJ1WzgMVsMt",
      "title": "Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration",
      "authors": "Desik Rengarajan, Gargi Vaidya, Akshay Sarvesh, Dileep Kalathil, Srinivas Shakkottai",
      "paper_url": "https://openreview.net/pdf/3b163b1af845a3cb05504bfe3d2f3a4a205fe856.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_lGz9u1ubUXE",
      "paper_id": "lGz9u1ubUXE",
      "title": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences",
      "authors": "Lin Guan, Karthik Valmeekam, Subbarao Kambhampati",
      "paper_url": "https://openreview.net/pdf/8ddd06f0bef80e495ca1650eb74874f576793c38.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_Nf4Lm6fXN8",
      "paper_id": "Nf4Lm6fXN8",
      "title": "Replay across Experiments: A Natural Extension of Off-Policy RL",
      "authors": "Dhruva Tirumala, Thomas Lampe, Jose Enrique Chen, Tuomas Haarnoja, Sandy Huang, Guy Lever, Ben Moran, Tim Hertweck, Leonard Hasenclever, Martin Riedmiller, Nicolas Heess, Markus Wulfmeier",
      "paper_url": "https://openreview.net/pdf?id=Nf4Lm6fXN8",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_SjzFVSJUt8S",
      "paper_id": "SjzFVSJUt8S",
      "title": "Replay Memory as An Empirical MDP: Combining Conservative Estimation with Experience Replay",
      "authors": "Hongming Zhang, Chenjun Xiao, Han Wang, Jun Jin, bo xu, Martin Müller",
      "paper_url": "https://openreview.net/pdf/6565f5cf8822651bf590d8be99db1fe12f5c1da5.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_8oJHwb3Sgp",
      "paper_id": "8oJHwb3Sgp",
      "title": "Represent to Control Partially Observed Systems: Representation Learning with Provable Sample Efficiency",
      "authors": "Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang",
      "paper_url": "https://openreview.net/pdf/eaf0d6ae5cbcc76e626aef7d8b1df2b919b74633.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_QpNz8r_Ri2Y",
      "paper_id": "QpNz8r_Ri2Y",
      "title": "Representation Balancing Offline Model-based Reinforcement Learning",
      "authors": "Byung-Jun Lee, Jongmin Lee, Kee-Eung Kim",
      "paper_url": "https://openreview.net/pdf/bb8bd2e330b957759e7d56f7715bdb54a256caab.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22_J4iSIR9fhY0",
      "paper_id": "J4iSIR9fhY0",
      "title": "Representation Learning for Online and Offline RL in Low-rank MDPs",
      "authors": "Masatoshi Uehara, Xuezhou Zhang, Wen Sun",
      "paper_url": "https://openreview.net/pdf/5efca5979678883d593d4e2a7fd7c48f0add1015.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_HIGSa_3kOx3",
      "paper_id": "HIGSa_3kOx3",
      "title": "Reset-Free Lifelong Learning with Skill-Space Planning",
      "authors": "Kevin Lu, Aditya Grover, Pieter Abbeel, Igor Mordatch",
      "paper_url": "https://openreview.net/pdf/c2294e8113d0b33d3849f2a97396d946826c3de3.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_2vgcDW2blS",
      "paper_id": "2vgcDW2blS",
      "title": "Residual Kernel Policy Network: Enhancing Stability and Robustness in RKHS-Based Reinforcement Learning",
      "authors": "Yixian Zhang, Huaze Tang, Huijing Lin, Wenbo Ding",
      "paper_url": "https://openreview.net/pdf?id=2vgcDW2blS",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_gVnJFY8nCM",
      "paper_id": "gVnJFY8nCM",
      "title": "Residual-MPPI: Online Policy Customization for Continuous Control",
      "authors": "Pengcheng Wang, Chenran Li, Catherine Weaver, Kenta Kawamoto, Masayoshi Tomizuka, Chen Tang, Wei Zhan",
      "paper_url": "https://openreview.net/pdf?id=gVnJFY8nCM",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_pDCublKPmG",
      "paper_id": "pDCublKPmG",
      "title": "Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL",
      "authors": "Xiangyu Liu, Souradip Chakraborty, Yanchao Sun, Furong Huang",
      "paper_url": "https://openreview.net/pdf?id=pDCublKPmG",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_KJztlfGPdwW",
      "paper_id": "KJztlfGPdwW",
      "title": "Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL",
      "authors": "Rui Yang, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/4480bd8b649d86ec422acd68ae606cd7f8fa1d6d.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21__TM6rT7tXke",
      "paper_id": "_TM6rT7tXke",
      "title": "Return-Based Contrastive Representation Learning for Reinforcement  Learning",
      "authors": "Guoqing Liu, Chuheng Zhang, Li Zhao, Tao Qin, Jinhua Zhu, Li Jian, Nenghai Yu, Tie-Yan Liu",
      "paper_url": "https://openreview.net/pdf/da82358af2f47721465fefc3dffd1bd3f3f2c16e.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_Gf15GsnfTy",
      "paper_id": "Gf15GsnfTy",
      "title": "REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes",
      "authors": "David Ireland, Giovanni Montana",
      "paper_url": "https://openreview.net/pdf?id=Gf15GsnfTy",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_w4rODxXsmM",
      "paper_id": "w4rODxXsmM",
      "title": "Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency",
      "authors": "Stone Tao, Arth Shukla, Tse-kai Chan, Hao Su",
      "paper_url": "https://openreview.net/pdf?id=w4rODxXsmM",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_38BBWrXUhP",
      "paper_id": "38BBWrXUhP",
      "title": "Revisiting a Design Choice in Gradient Temporal Difference Learning",
      "authors": "Xiaochi Qian, Shangtong Zhang",
      "paper_url": "https://openreview.net/pdf?id=38BBWrXUhP",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_EGQBpkIEuu",
      "paper_id": "EGQBpkIEuu",
      "title": "Revisiting Data Augmentation in Deep Reinforcement Learning",
      "authors": "Jianshu Hu, Yunpeng Jiang, Paul Weng",
      "paper_url": "https://openreview.net/pdf?id=EGQBpkIEuu",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_zz9hXVhf40",
      "paper_id": "zz9hXVhf40",
      "title": "Revisiting Design Choices in Offline Model Based Reinforcement Learning",
      "authors": "Cong Lu, Philip Ball, Jack Parker-Holder, Michael Osborne, Stephen J. Roberts",
      "paper_url": "https://openreview.net/pdf/1fd710c82e5202735a840dcabdf897afa2030b34.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_j3GK3_xZydY",
      "paper_id": "j3GK3_xZydY",
      "title": "Revisiting Intrinsic Reward for Exploration in Procedurally Generated Environments",
      "authors": "Kaixin Wang, Kuangqi Zhou, Bingyi Kang, Jiashi Feng, Shuicheng YAN",
      "paper_url": "https://openreview.net/pdf/5b63f069d20506723467e420a5a7a64916ab8335.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_0aR1s9YxoL",
      "paper_id": "0aR1s9YxoL",
      "title": "Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules and Training Stages",
      "authors": "Guozheng Ma, Lu Li, Sen Zhang, Zixuan Liu, Zhen Wang, Yixin Chen, Li Shen, Xueqian Wang, Dacheng Tao",
      "paper_url": "https://openreview.net/pdf?id=0aR1s9YxoL",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_OWZVD-l-ZrC",
      "paper_id": "OWZVD-l-ZrC",
      "title": "Reward Uncertainty for Exploration in Preference-based Reinforcement Learning",
      "authors": "Xinran Liang, Katherine Shu, Kimin Lee, Pieter Abbeel",
      "paper_url": "https://openreview.net/pdf/96609cdcc6871a3da572808bab08da66cc38cb2c.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_GSBHKiw19c",
      "paper_id": "GSBHKiw19c",
      "title": "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning",
      "authors": "Fan-Ming Luo, Tian Xu, Xingchen Cao, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=GSBHKiw19c",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_eCGpNGDeNu",
      "paper_id": "eCGpNGDeNu",
      "title": "Reward-Free Curricula for Training Robust World Models",
      "authors": "Marc Rigter, Minqi Jiang, Ingmar Posner",
      "paper_url": "https://openreview.net/pdf?id=eCGpNGDeNu",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_TBIzh9b5eaz",
      "paper_id": "TBIzh9b5eaz",
      "title": "Risk-Averse Offline Reinforcement Learning",
      "authors": "Núria Armengol Urpí, Sebastian Curi, Andreas Krause",
      "paper_url": "https://openreview.net/pdf/be66503efdccf10359c7112b8c3732b28564db16.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_-RwZOVybbj",
      "paper_id": "-RwZOVybbj",
      "title": "Risk-Aware Reinforcement Learning with Coherent Risk Measures and Non-linear Function Approximation",
      "authors": "Thanh Lam, Arun Verma, Bryan Kian Hsiang Low, Patrick Jaillet",
      "paper_url": "https://openreview.net/pdf/12ed9c605b0fa8dc9237a38935722f9687e15641.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_irrtPRFksw",
      "paper_id": "irrtPRFksw",
      "title": "Risk-Sensitive Variational Actor-Critic: A Model-Based Approach",
      "authors": "Alonso Granados, Reza Ebrahimi, Jason Pacheco",
      "paper_url": "https://openreview.net/pdf?id=irrtPRFksw",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_oLLZhbBSOU",
      "paper_id": "oLLZhbBSOU",
      "title": "RLIF: Interactive Imitation Learning as Reinforcement Learning",
      "authors": "Jianlan Luo, Perry Dong, Yuexiang Zhai, Yi Ma, Sergey Levine",
      "paper_url": "https://openreview.net/pdf?id=oLLZhbBSOU",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_DJEEqoAq7to",
      "paper_id": "DJEEqoAq7to",
      "title": "RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch",
      "authors": "Yiqin Tan, Pihe Hu, Ling Pan, Jiatai Huang, Longbo Huang",
      "paper_url": "https://openreview.net/pdf/095bd7aea3382d53f48388a8b9051db4f9ed8f31.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_IL71c1z7et",
      "paper_id": "IL71c1z7et",
      "title": "Robot Fleet Learning via Policy Merging",
      "authors": "Lirui Wang, Kaiqing Zhang, Allan Zhou, Max Simchowitz, Russ Tedrake",
      "paper_url": "https://openreview.net/pdf?id=IL71c1z7et",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_pFOoOdaiue",
      "paper_id": "pFOoOdaiue",
      "title": "Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula",
      "authors": "Aryaman Reddi, Maximilian Tölle, Jan Peters, Georgia Chalvatzaki, Carlo D'Eramo",
      "paper_url": "https://openreview.net/pdf?id=pFOoOdaiue",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_pOoKI3ouv1",
      "paper_id": "pOoKI3ouv1",
      "title": "Robust agents learn causal world models",
      "authors": "Jonathan Richens, Tom Everitt",
      "paper_url": "https://openreview.net/pdf?id=pOoKI3ouv1",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_2uQBSa2X4R",
      "paper_id": "2uQBSa2X4R",
      "title": "Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning",
      "authors": "Shangding Gu, Laixi Shi, Muning Wen, Ming Jin, Eric Mazumdar, Yuejie Chi, Adam Wierman, Costas Spanos",
      "paper_url": "https://openreview.net/pdf?id=2uQBSa2X4R",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_GaLCLvJaoF",
      "paper_id": "GaLCLvJaoF",
      "title": "Robust Model Based Reinforcement Learning Using $\\mathcal{L}_1$ Adaptive Control",
      "authors": "Minjun Sung, Sambhu Harimanas Karumanchi, Aditya Gahlawat, Naira Hovakimyan",
      "paper_url": "https://openreview.net/pdf?id=GaLCLvJaoF",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_sCZbhBvqQaU",
      "paper_id": "sCZbhBvqQaU",
      "title": "Robust Reinforcement Learning on State Observations with Learned Optimal Adversary",
      "authors": "Huan Zhang, Hongge Chen, Duane S Boning, Cho-Jui Hsieh",
      "paper_url": "https://openreview.net/pdf/9a0def4f4b70bbb3d4c3157a3ee5e4110bb9363a.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_rvXdGL4pCJ",
      "paper_id": "rvXdGL4pCJ",
      "title": "Robust Transfer of Safety-Constrained Reinforcement Learning Agents",
      "authors": "Markel Zubia, Thiago D. Simão, Nils Jansen",
      "paper_url": "https://openreview.net/pdf?id=rvXdGL4pCJ",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_TTUVg6vkNjK",
      "paper_id": "TTUVg6vkNjK",
      "title": "RODE: Learning Roles to Decompose Multi-Agent Tasks",
      "authors": "Tonghan Wang, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/b3099a13254cda0cd68fedf29a0227d9684bc973.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_HnSceSzlfrY",
      "paper_id": "HnSceSzlfrY",
      "title": "RPM: Generalizable Multi-Agent Policies for Multi-Agent Reinforcement Learning",
      "authors": "Wei Qiu, Xiao Ma, Bo An, Svetlana Obraztsova, Shuicheng YAN, Zhongwen Xu",
      "paper_url": "https://openreview.net/pdf/e0f67e22108de8d6be84c75330ee0de82ed3ae5a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_0FK6tzqV76",
      "paper_id": "0FK6tzqV76",
      "title": "RTDiff: Reverse Trajectory Synthesis via Diffusion for Offline Reinforcement Learning",
      "authors": "Qianlan Yang, Yu-Xiong Wang",
      "paper_url": "https://openreview.net/pdf?id=0FK6tzqV76",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_S874XAIpkR-",
      "paper_id": "S874XAIpkR-",
      "title": "RvS: What is Essential for Offline RL via Supervised Learning?",
      "authors": "Scott Emmons, Benjamin Eysenbach, Ilya Kostrikov, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/e72a195a733bc43adb5968aa6500c934806fa486.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_rAHcTCMaLc",
      "paper_id": "rAHcTCMaLc",
      "title": "S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic",
      "authors": "Safa Messaoud, Billel Mokeddem, Zhenghai Xue, Linsey Pang, Bo An, Haipeng Chen, Sanjay Chawla",
      "paper_url": "https://openreview.net/pdf?id=rAHcTCMaLc",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_wNUgn1n6esQ",
      "paper_id": "wNUgn1n6esQ",
      "title": "Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-Free RL",
      "authors": "Ruiquan Huang, Jing Yang, Yingbin Liang",
      "paper_url": "https://openreview.net/pdf/4d89566649ca26b4992a3fab78d893feb9ca8dc1.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_j5JvZCaDM0",
      "paper_id": "j5JvZCaDM0",
      "title": "Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model",
      "authors": "Yinan Zheng, Jianxiong Li, Dongjie Yu, Yujie Yang, Shengbo Eben Li, Xianyuan Zhan, Jingjing Liu",
      "paper_url": "https://openreview.net/pdf?id=j5JvZCaDM0",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_b39dQt_uffW",
      "paper_id": "b39dQt_uffW",
      "title": "Safe Reinforcement Learning From Pixels Using a Stochastic Latent Representation",
      "authors": "Yannick Hogewind, Thiago D. Simão, Tal Kachman, Nils Jansen",
      "paper_url": "https://openreview.net/pdf/9c4b07fd4a61d7c3cbe4abfa26f9ce1b7f127301.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_ig2wk7kK9J",
      "paper_id": "ig2wk7kK9J",
      "title": "SafeDiffuser: Safe Planning with Diffusion Probabilistic Models",
      "authors": "Wei Xiao, Tsun-Hsuan Wang, Chuang Gan, Ramin Hasani, Mathias Lechner, Daniela Rus",
      "paper_url": "https://openreview.net/pdf?id=ig2wk7kK9J",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_tsE5HLYtYg",
      "paper_id": "tsE5HLYtYg",
      "title": "SafeDreamer: Safe Reinforcement Learning with World Models",
      "authors": "Weidong Huang, Jiaming Ji, Chunhe Xia, Borong Zhang, Yaodong Yang",
      "paper_url": "https://openreview.net/pdf?id=tsE5HLYtYg",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_6Mxhg9PtDE",
      "paper_id": "6Mxhg9PtDE",
      "title": "Safety Alignment Should be Made More Than Just a Few Tokens Deep",
      "authors": "Xiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao Ma, Subhrajit Roy, Ahmad Beirami, Prateek Mittal, Peter Henderson",
      "paper_url": "https://openreview.net/pdf?id=6Mxhg9PtDE",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_gJG4IPwg6l",
      "paper_id": "gJG4IPwg6l",
      "title": "Safety Representations for Safer Policy Learning",
      "authors": "Kaustubh Mani, Vincent Mai, Charlie Gauthier, Annie S Chen, Samer B. Nashed, Liam Paull",
      "paper_url": "https://openreview.net/pdf?id=gJG4IPwg6l",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_f3QR9TEERH",
      "paper_id": "f3QR9TEERH",
      "title": "Safety-Prioritizing Curricula for Constrained Reinforcement Learning",
      "authors": "Cevahir Koprulu, Thiago D. Simão, Nils Jansen, ufuk topcu",
      "paper_url": "https://openreview.net/pdf?id=f3QR9TEERH",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_9x3CO0ZU9LR",
      "paper_id": "9x3CO0ZU9LR",
      "title": "Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks",
      "authors": "Xiang Ji, Minshuo Chen, Mengdi Wang, Tuo Zhao",
      "paper_url": "https://openreview.net/pdf/6ce075be5b8a6bc4f5f89e4d67cb652b91081627.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_vrW3tvDfOJQ",
      "paper_id": "vrW3tvDfOJQ",
      "title": "Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation",
      "authors": "Vincent Mai, Kaustubh Mani, Liam Paull",
      "paper_url": "https://openreview.net/pdf/2957fd1597c9d0c85f628e1d53b0aba1a7aa45b1.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_YZrg56G0JV",
      "paper_id": "YZrg56G0JV",
      "title": "Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks",
      "authors": "Ziping Xu, Zifan Xu, Runxuan Jiang, Peter Stone, Ambuj Tewari",
      "paper_url": "https://openreview.net/pdf?id=YZrg56G0JV",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_ey3GhWXQ97",
      "paper_id": "ey3GhWXQ97",
      "title": "Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity",
      "authors": "Emmeran Johnson, Ciara Pike-Burke, Patrick Rebeschini",
      "paper_url": "https://openreview.net/pdf?id=ey3GhWXQ97",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_hSjxQ3B7GWq",
      "paper_id": "hSjxQ3B7GWq",
      "title": "Sample-Efficient Automated Deep Reinforcement Learning",
      "authors": "Jörg K.H. Franke, Gregor Koehler, André Biedenkapp, Frank Hutter",
      "paper_url": "https://openreview.net/pdf/50e735ee784190b4976fe22036a75b2ac2feee2b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_fq1wNrC2ai",
      "paper_id": "fq1wNrC2ai",
      "title": "Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation",
      "authors": "Jianliang He, Han Zhong, Zhuoran Yang",
      "paper_url": "https://openreview.net/pdf?id=fq1wNrC2ai",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_1hsVvgW0rU",
      "paper_id": "1hsVvgW0rU",
      "title": "Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight",
      "authors": "Jiacheng Guo, Minshuo Chen, Huan Wang, Caiming Xiong, Mengdi Wang, Yu Bai",
      "paper_url": "https://openreview.net/pdf?id=1hsVvgW0rU",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_o7qhUMylLU",
      "paper_id": "o7qhUMylLU",
      "title": "Sample-Efficient Multi-Agent RL: An Optimization Perspective",
      "authors": "Nuoya Xiong, Zhihan Liu, Zhaoran Wang, Zhuoran Yang",
      "paper_url": "https://openreview.net/pdf?id=o7qhUMylLU",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_JDud6zbpFv",
      "paper_id": "JDud6zbpFv",
      "title": "Sample-Efficient Quality-Diversity by Cooperative Coevolution",
      "authors": "Ke Xue, Ren-Jian Wang, Pengyi Li, Dong Li, Jianye HAO, Chao Qian",
      "paper_url": "https://openreview.net/pdf?id=JDud6zbpFv",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_OpC-9aBBVJe",
      "paper_id": "OpC-9aBBVJe",
      "title": "Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier",
      "authors": "Pierluca D'Oro, Max Schwarzer, Evgenii Nikishin, Pierre-Luc Bacon, Marc G Bellemare, Aaron Courville",
      "paper_url": "https://openreview.net/pdf/c891095f8e46b891138ef064f19d6b0e2d84dcb2.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_4qR3coiNaIv",
      "paper_id": "4qR3coiNaIv",
      "title": "Scalable Bayesian Inverse Reinforcement Learning",
      "authors": "Alex James Chan, Mihaela van der Schaar",
      "paper_url": "https://openreview.net/pdf/a94f190029f9ebd5affafc141a770843d501a8a2.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_pQsllTesiE",
      "paper_id": "pQsllTesiE",
      "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
      "authors": "Baiting Luo, Ava Pettet, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay",
      "paper_url": "https://openreview.net/pdf?id=pQsllTesiE",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_womU9cEwcO",
      "paper_id": "womU9cEwcO",
      "title": "Scaling Autonomous Agents via Automatic Reward Modeling And Planning",
      "authors": "Zhenfang Chen, Delin Chen, Rui Sun, Wenjun Liu, Chuang Gan",
      "paper_url": "https://openreview.net/pdf?id=womU9cEwcO",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_ZrEbzL9eQ3W",
      "paper_id": "ZrEbzL9eQ3W",
      "title": "Scaling Laws for a Multi-Agent Reinforcement Learning Model",
      "authors": "Oren Neumann, Claudius Gros",
      "paper_url": "https://openreview.net/pdf/f98ab0085243b503d56efc920c90c19b95dc7ec8.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_T1OvCSFaum",
      "paper_id": "T1OvCSFaum",
      "title": "Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining",
      "authors": "Jie Cheng, Ruixi Qiao, YINGWEI MA, Binhua Li, Gang Xiong, Qinghai Miao, Yongbin Li, Yisheng Lv",
      "paper_url": "https://openreview.net/pdf?id=T1OvCSFaum",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_PYbe4MoHf32",
      "paper_id": "PYbe4MoHf32",
      "title": "Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation",
      "authors": "Linfeng Zhao, Huazhe Xu, Lawson L.S. Wong",
      "paper_url": "https://openreview.net/pdf/c9ba511ff253534e8b5c8b381259eb8b04b6406a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_oXjnwQLcTA",
      "paper_id": "oXjnwQLcTA",
      "title": "Score Models for Offline Goal-Conditioned Reinforcement Learning",
      "authors": "Harshit Sikchi, Rohan Chitnis, Ahmed Touati, Alborz Geramifard, Amy Zhang, Scott Niekum",
      "paper_url": "https://openreview.net/pdf?id=oXjnwQLcTA",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_xCRr9DrolJ",
      "paper_id": "xCRr9DrolJ",
      "title": "Score Regularized Policy Optimization through Diffusion Behavior",
      "authors": "Huayu Chen, Cheng Lu, Zhengyi Wang, Hang Su, Jun Zhu",
      "paper_url": "https://openreview.net/pdf?id=xCRr9DrolJ",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_Cr1XlGBGVm",
      "paper_id": "Cr1XlGBGVm",
      "title": "Scrutinize What We Ignore: Reining In Task Representation Shift Of Context-Based Offline Meta Reinforcement Learning",
      "authors": "Hai Zhang, Boyuan Zheng, Tianying Ji, JinHang Liu, Anqi Guo, Junqiao Zhao, Lanqing Li",
      "paper_url": "https://openreview.net/pdf?id=Cr1XlGBGVm",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_MNyOI3C7YB",
      "paper_id": "MNyOI3C7YB",
      "title": "SEABO: A Simple Search-Based Method for Offline Imitation Learning",
      "authors": "Jiafei Lyu, Xiaoteng Ma, Le Wan, Runze Liu, Xiu Li, Zongqing Lu",
      "paper_url": "https://openreview.net/pdf?id=MNyOI3C7YB",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_3ULaIHxn9u7",
      "paper_id": "3ULaIHxn9u7",
      "title": "Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning",
      "authors": "Xin-Qiang Cai, Yao-Xiang Ding, Zixuan Chen, Yuan Jiang, Masashi Sugiyama, Zhi-Hua Zhou",
      "paper_url": "https://openreview.net/pdf/38e823cd3fba73660cf9a28932a2ba5cad391a39.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_PDgZ3rvqHn",
      "paper_id": "PDgZ3rvqHn",
      "title": "Select before Act: Spatially Decoupled Action Repetition for Continuous Control",
      "authors": "Buqing Nie, Yangqing Fu, Yue Gao",
      "paper_url": "https://openreview.net/pdf?id=PDgZ3rvqHn",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_L6crLU7MIE",
      "paper_id": "L6crLU7MIE",
      "title": "Select to Perfect: Imitating desired behavior from large multi-agent data",
      "authors": "Tim Franzmeyer, Edith Elkind, Philip Torr, Jakob Nicolaus Foerster, Joao F. Henriques",
      "paper_url": "https://openreview.net/pdf?id=L6crLU7MIE",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_o_V-MjyyGV_",
      "paper_id": "o_V-MjyyGV_",
      "title": "Self-Supervised Policy Adaptation during Deployment",
      "authors": "Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Alenyà, Pieter Abbeel, Alexei A Efros, Lerrel Pinto, Xiaolong Wang",
      "paper_url": "https://openreview.net/pdf/6949f5e82ffd2bd635a6de802a733540b19b9cc3.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr21_xppLmXCbOw1",
      "paper_id": "xppLmXCbOw1",
      "title": "Self-supervised Visual Reinforcement Learning with Object-centric Representations",
      "authors": "Andrii Zadaianchuk, Maximilian Seitzer, Georg Martius",
      "paper_url": "https://openreview.net/pdf/17a02894cb2794484690465818a08e4b35ea6982.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_zY37C8d6bS",
      "paper_id": "zY37C8d6bS",
      "title": "Semantic Temporal Abstraction via Vision-Language Model Guidance for Efficient Reinforcement Learning",
      "authors": "Tian-Shuo Liu, Xu-Hui Liu, Ruifeng Chen, Lixuan Jin, Pengyuan Wang, Zhilong Zhang, Yang Yu",
      "paper_url": "https://openreview.net/pdf?id=zY37C8d6bS",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_rJ5g8ueQaI",
      "paper_id": "rJ5g8ueQaI",
      "title": "SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation",
      "authors": "Jongmin Lee, Meiqi Sun, Pieter Abbeel",
      "paper_url": "https://openreview.net/pdf?id=rJ5g8ueQaI",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_dnqPvUjyRI",
      "paper_id": "dnqPvUjyRI",
      "title": "SemiReward: A General Reward Model for Semi-supervised Learning",
      "authors": "Siyuan Li, Weiyang Jin, Zedong Wang, Fang Wu, Zicheng Liu, Cheng Tan, Stan Z. Li",
      "paper_url": "https://openreview.net/pdf?id=dnqPvUjyRI",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_AP1MKT37rJ",
      "paper_id": "AP1MKT37rJ",
      "title": "Should I Run Offline Reinforcement Learning or Behavioral Cloning?",
      "authors": "Aviral Kumar, Joey Hong, Anikait Singh, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/ab91050974b19858a9a241236b4d69019903de0e.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_jXLiDKsuDo",
      "paper_id": "jXLiDKsuDo",
      "title": "SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning",
      "authors": "Hojoon Lee, Dongyoon Hwang, Donghu Kim, Hyunseung Kim, Jun Jet Tai, Kaushik Subramanian, Peter R. Wurman, Jaegul Choo, Peter Stone, Takuma Seno",
      "paper_url": "https://openreview.net/pdf?id=jXLiDKsuDo",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_NUl0ylt7SM",
      "paper_id": "NUl0ylt7SM",
      "title": "Simple Emergent Action Representations from Multi-Task Policy Training",
      "authors": "Pu Hua, Yubei Chen, Huazhe Xu",
      "paper_url": "https://openreview.net/pdf/af859d60f1af73991c631bf27224a456c44ce94a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_kXHEBK9uAY",
      "paper_id": "kXHEBK9uAY",
      "title": "Simple Hierarchical Planning with Diffusion",
      "authors": "Chang Chen, Fei Deng, Kenji Kawaguchi, Caglar Gulcehre, Sungjin Ahn",
      "paper_url": "https://openreview.net/pdf?id=kXHEBK9uAY",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_yFGR36PLDJ",
      "paper_id": "yFGR36PLDJ",
      "title": "Simple, Good, Fast: Self-Supervised World Models Free of Baggage",
      "authors": "Jan Robine, Marc Höftmann, Stefan Harmeling",
      "paper_url": "https://openreview.net/pdf?id=yFGR36PLDJ",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_7IzeL0kflu",
      "paper_id": "7IzeL0kflu",
      "title": "Simplifying Deep Temporal Difference Learning",
      "authors": "Matteo Gallici, Mattie Fellows, Benjamin Ellis, Bartomeu Pou, Ivan Masmitja, Jakob Nicolaus Foerster, Mario Martin",
      "paper_url": "https://openreview.net/pdf?id=7IzeL0kflu",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_MQcmfgRxf7a",
      "paper_id": "MQcmfgRxf7a",
      "title": "Simplifying Model-based RL: Learning Representations, Latent-space Models, and Policies with One Objective",
      "authors": "Raj Ghugare, Homanga Bharadhwaj, Benjamin Eysenbach, Sergey Levine, Russ Salakhutdinov",
      "paper_url": "https://openreview.net/pdf/f4207005e1b30d58cc78f473150de8c1777a8904.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_46xYl55hdc",
      "paper_id": "46xYl55hdc",
      "title": "Single-agent Poisoning Attacks Suffice to Ruin Multi-Agent Learning",
      "authors": "Fan Yao, Yuwei Cheng, Ermin Wei, Haifeng Xu",
      "paper_url": "https://openreview.net/pdf?id=46xYl55hdc",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_pqZV_srUVmK",
      "paper_id": "pqZV_srUVmK",
      "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy",
      "authors": "Zuyue Fu, Zhuoran Yang, Zhaoran Wang",
      "paper_url": "https://openreview.net/pdf/23d733db99e61b484d06180f5dfbb470789b7ff0.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_qiduMcw3CU",
      "paper_id": "qiduMcw3CU",
      "title": "Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning",
      "authors": "Geraud Nangue Tasse, Devon Jarvis, Steven James, Benjamin Rosman",
      "paper_url": "https://openreview.net/pdf?id=qiduMcw3CU",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_ZFMiHfZwIf",
      "paper_id": "ZFMiHfZwIf",
      "title": "Skill or Luck? Return Decomposition via Advantage Functions",
      "authors": "Hsiao-Ru Pan, Bernhard Schölkopf",
      "paper_url": "https://openreview.net/pdf?id=ZFMiHfZwIf",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_cPZOyoDloxl",
      "paper_id": "cPZOyoDloxl",
      "title": "SMiRL: Surprise Minimizing Reinforcement Learning in Unstable Environments",
      "authors": "Glen Berseth, Daniel Geng, Coline Manon Devin, Nicholas Rhinehart, Chelsea Finn, Dinesh Jayaraman, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/f9be390d21352320ef34c706df775ded52b79ebd.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_dEz3ge8QSo",
      "paper_id": "dEz3ge8QSo",
      "title": "Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity",
      "authors": "Runyu Zhang, Yang Hu, Na Li",
      "paper_url": "https://openreview.net/pdf?id=dEz3ge8QSo",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_9SS69KwomAM",
      "paper_id": "9SS69KwomAM",
      "title": "Solving Compositional Reinforcement Learning Problems via Task Reduction",
      "authors": "Yunfei Li, Yilin Wu, Huazhe Xu, Xiaolong Wang, Yi Wu",
      "paper_url": "https://openreview.net/pdf/77f78b692f36356e5e5bbddd012a3367bd821b29.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_U5XOGxAgccS",
      "paper_id": "U5XOGxAgccS",
      "title": "Solving Continuous Control via Q-learning",
      "authors": "Tim Seyde, Peter Werner, Wilko Schwarting, Igor Gilitschenski, Martin Riedmiller, Daniela Rus, Markus Wulfmeier",
      "paper_url": "https://openreview.net/pdf/8785841c3d3960cea3b9230ca8db34e70e54e679.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_hB2hXtxIPH",
      "paper_id": "hB2hXtxIPH",
      "title": "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution",
      "authors": "Shanqi Liu, Dong Xing, Pengjie Gu, Xinrun Wang, Bo An, Yong Liu",
      "paper_url": "https://openreview.net/pdf?id=hB2hXtxIPH",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_5l9zj5G7vDY",
      "paper_id": "5l9zj5G7vDY",
      "title": "Spatially Structured Recurrent Modules",
      "authors": "Nasim Rahaman, Anirudh Goyal, Muhammad Waleed Gondal, Manuel Wuthrich, Stefan Bauer, Yash Sharma, Yoshua Bengio, Bernhard Schölkopf",
      "paper_url": "https://openreview.net/pdf/3590e3dd48376daa86d4fee6c6cb3c8b051d03b9.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_FBMLeaXpZN",
      "paper_id": "FBMLeaXpZN",
      "title": "Spectral Decomposition Representation for Reinforcement Learning",
      "authors": "Tongzheng Ren, Tianjun Zhang, Lisa Lee, Joseph E. Gonzalez, Dale Schuurmans, Bo Dai",
      "paper_url": "https://openreview.net/pdf/bad3599bfddaf9f576a9c84fc0e1ddb678a2c5dc.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_Mg5CLXZgvLJ",
      "paper_id": "Mg5CLXZgvLJ",
      "title": "SpeedyZero: Mastering Atari with Limited Data and Time",
      "authors": "Yixuan Mei, Jiaxuan Gao, Weirui Ye, Shaohuai Liu, Yang Gao, Yi Wu",
      "paper_url": "https://openreview.net/pdf/93caec5d1353b3d4a35a3efed19a2a836a1c6238.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_lajn1iROCu",
      "paper_id": "lajn1iROCu",
      "title": "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores",
      "authors": "Zhiyu Mei, Wei Fu, Jiaxuan Gao, Guangju Wang, Huanchen Zhang, Yi Wu",
      "paper_url": "https://openreview.net/pdf?id=lajn1iROCu",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_Xkf2EBj4w3",
      "paper_id": "Xkf2EBj4w3",
      "title": "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data",
      "authors": "Chongyi Zheng, Benjamin Eysenbach, Homer Rich Walke, Patrick Yin, Kuan Fang, Ruslan Salakhutdinov, Sergey Levine",
      "paper_url": "https://openreview.net/pdf?id=Xkf2EBj4w3",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_We5z3UEnUY",
      "paper_id": "We5z3UEnUY",
      "title": "Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning",
      "authors": "Hung Le, Dung Nguyen, Kien Do, Sunil Gupta, Svetha Venkatesh",
      "paper_url": "https://openreview.net/pdf?id=We5z3UEnUY",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_wPhbtwlCDa",
      "paper_id": "wPhbtwlCDa",
      "title": "STARC: A General Framework For Quantifying Differences Between Reward Functions",
      "authors": "Joar Max Viktor Skalse, Lucy Farnik, Sumeet Ramesh Motwani, Erik Jenner, Adam Gleave, Alessandro Abate",
      "paper_url": "https://openreview.net/pdf?id=wPhbtwlCDa",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_B4maZQLLW0_",
      "paper_id": "B4maZQLLW0_",
      "title": "Stateful Active Facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning",
      "authors": "Dianbo Liu, Vedant Shah, Oussama Boussif, Cristian Meo, Anirudh Goyal, Tianmin Shu, Michael Curtis Mozer, Nicolas Heess, Yoshua Bengio",
      "paper_url": "https://openreview.net/pdf/e91b82d1a670376c4dd37b3ff6ed712eff719b12.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_Qja5s0K3VX",
      "paper_id": "Qja5s0K3VX",
      "title": "Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs",
      "authors": "Yuheng Zhang, Nan Jiang",
      "paper_url": "https://openreview.net/pdf?id=Qja5s0K3VX",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_xaYlO03tIk",
      "paper_id": "xaYlO03tIk",
      "title": "Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion",
      "authors": "Kaizhe Hu, Zihang Rui, Yao He, Yuyao Liu, Pu Hua, Huazhe Xu",
      "paper_url": "https://openreview.net/pdf?id=xaYlO03tIk",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_fy_XRVHqly",
      "paper_id": "fy_XRVHqly",
      "title": "Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning",
      "authors": "Sunghoon Hong, Deunsol Yoon, Kee-Eung Kim",
      "paper_url": "https://openreview.net/pdf/111d5058b0200075159b27c0969addf7f1a2a871.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_tErHYBGlWc",
      "paper_id": "tErHYBGlWc",
      "title": "Studying the Interplay Between the Actor and Critic Representations in Reinforcement Learning",
      "authors": "Samuel Garcin, Trevor McInroe, Pablo Samuel Castro, Christopher G. Lucas, David Abel, Prakash Panangaden, Stefano V Albrecht",
      "paper_url": "https://openreview.net/pdf?id=tErHYBGlWc",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_rnHNDihrIT",
      "paper_id": "rnHNDihrIT",
      "title": "Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets",
      "authors": "Yihuan Mao, Chengjie Wu, Xi Chen, Hao Hu, Ji Jiang, Tianze Zhou, Tangjie Lv, Changjie Fan, Zhipeng Hu, Yi Wu, Yujing Hu, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf?id=rnHNDihrIT",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_mqKVe6F3Up",
      "paper_id": "mqKVe6F3Up",
      "title": "Subtask-Aware Visual Reward Learning from Segmented Demonstrations",
      "authors": "Changyeon Kim, Minho Heo, Doohyun Lee, Honglak Lee, Jinwoo Shin, Joseph J Lim, Kimin Lee",
      "paper_url": "https://openreview.net/pdf?id=mqKVe6F3Up",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_TfhfZLQ2EJO",
      "paper_id": "TfhfZLQ2EJO",
      "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning",
      "authors": "Jongjin Park, Younggyo Seo, Jinwoo Shin, Honglak Lee, Pieter Abbeel, Kimin Lee",
      "paper_url": "https://openreview.net/pdf/2fe39fd19cc40472a98221890fb4cfd5f924e6c7.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_phAlw3JPms",
      "paper_id": "phAlw3JPms",
      "title": "Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling",
      "authors": "Jiawei Xu, Rui Yang, Shuang Qiu, Feng Luo, Meng Fang, Baoxiang Wang, Lei Han",
      "paper_url": "https://openreview.net/pdf?id=phAlw3JPms",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_RRayv1ZPN3",
      "paper_id": "RRayv1ZPN3",
      "title": "TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models",
      "authors": "Zuxin Liu, Jesse Zhang, Kavosh Asadi, Yao Liu, Ding Zhao, Shoham Sabach, Rasool Fakoor",
      "paper_url": "https://openreview.net/pdf?id=RRayv1ZPN3",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_t8eO0CiZJV",
      "paper_id": "t8eO0CiZJV",
      "title": "Tailoring Self-Rationalizers with Multi-Reward Distillation",
      "authors": "Sahana Ramnath, Brihi Joshi, Skyler Hallinan, Ximing Lu, Liunian Harold Li, Aaron Chan, Jack Hessel, Yejin Choi, Xiang Ren",
      "paper_url": "https://openreview.net/pdf?id=t8eO0CiZJV",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_zSxpnKh1yS",
      "paper_id": "zSxpnKh1yS",
      "title": "Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning",
      "authors": "Yucheng Yang, Tianyi Zhou, Qiang He, Lei Han, Mykola Pechenizkiy, Meng Fang",
      "paper_url": "https://openreview.net/pdf?id=zSxpnKh1yS",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_CGQ6ENUMX6",
      "paper_id": "CGQ6ENUMX6",
      "title": "Task-Agnostic Morphology Evolution",
      "authors": "Donald Joseph Hejna III, Pieter Abbeel, Lerrel Pinto",
      "paper_url": "https://openreview.net/pdf/8548ea3c5369fd4bf3a020ff1c71f973bf77a3b3.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_Oxh5CstDJU",
      "paper_id": "Oxh5CstDJU",
      "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
      "authors": "Nicklas Hansen, Hao Su, Xiaolong Wang",
      "paper_url": "https://openreview.net/pdf?id=Oxh5CstDJU",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_j3bKnEidtT",
      "paper_id": "j3bKnEidtT",
      "title": "Temporal Difference Learning: Why It Can Be Fast and How It Will Be Faster",
      "authors": "Patrick Schnell, Luca Guastoni, Nils Thuerey",
      "paper_url": "https://openreview.net/pdf?id=j3bKnEidtT",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_sPgP6aISLTD",
      "paper_id": "sPgP6aISLTD",
      "title": "Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning",
      "authors": "Mhairi Dunion, Trevor McInroe, Kevin Sebastian Luck, Josiah P. Hanna, Stefano V Albrecht",
      "paper_url": "https://openreview.net/pdf/01ae4a17b982a43d3a961ee90d4d05b788c87c3b.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_ONBPHFZ7zG4",
      "paper_id": "ONBPHFZ7zG4",
      "title": "Temporally-Extended ε-Greedy Exploration",
      "authors": "Will Dabney, Georg Ostrovski, Andre Barreto",
      "paper_url": "https://openreview.net/pdf/be288b1cdd527108548adea1d4d8319ce8a8eae8.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr22__l_QjPGN5ye",
      "paper_id": "_l_QjPGN5ye",
      "title": "The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models",
      "authors": "Cassidy Laidlaw, Anca Dragan",
      "paper_url": "https://openreview.net/pdf/441fdfcfbe0339bb96b0292455eb5acb04f4676e.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_M3QXCOTTk4",
      "paper_id": "M3QXCOTTk4",
      "title": "The Curse of Diversity in Ensemble-Based Exploration",
      "authors": "Zhixuan Lin, Pierluca D'Oro, Evgenii Nikishin, Aaron Courville",
      "paper_url": "https://openreview.net/pdf?id=M3QXCOTTk4",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_5ES5Hdlbxw",
      "paper_id": "5ES5Hdlbxw",
      "title": "The Effective Horizon Explains Deep RL Performance in Stochastic Environments",
      "authors": "Cassidy Laidlaw, Banghua Zhu, Stuart Russell, Anca Dragan",
      "paper_url": "https://openreview.net/pdf?id=5ES5Hdlbxw",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_3w6xuXDOdY",
      "paper_id": "3w6xuXDOdY",
      "title": "The Generalization Gap in Offline Reinforcement Learning",
      "authors": "Ishita Mediratta, Qingfei You, Minqi Jiang, Roberta Raileanu",
      "paper_url": "https://openreview.net/pdf?id=3w6xuXDOdY",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_A05I5IvrdL-",
      "paper_id": "A05I5IvrdL-",
      "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs",
      "authors": "Johannes Müller, Guido Montufar",
      "paper_url": "https://openreview.net/pdf/d9402e7eae55cb2e0a33dfaedb88a525a88beb52.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_E3Ys6a1NTGT",
      "paper_id": "E3Ys6a1NTGT",
      "title": "The Importance of Pessimism in Fixed-Dataset Policy Optimization",
      "authors": "Jacob Buckman, Carles Gelada, Marc G Bellemare",
      "paper_url": "https://openreview.net/pdf/e3dfbddf4c9078c3d334b54122b25fd90aba6c9b.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_u-RuvyDYqCM",
      "paper_id": "u-RuvyDYqCM",
      "title": "The In-Sample Softmax for Offline Reinforcement Learning",
      "authors": "Chenjun Xiao, Han Wang, Yangchen Pan, Adam White, Martha White",
      "paper_url": "https://openreview.net/pdf/69f475d9352b20ebc3fc03da590f54192f7856ec.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_3wU2UX0voE",
      "paper_id": "3wU2UX0voE",
      "title": "The Information Geometry of Unsupervised Reinforcement Learning",
      "authors": "Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine",
      "paper_url": "https://openreview.net/pdf/4709236cdf10497a057511e94fe99f87770c5bf6.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_MTTPLcwvqTt",
      "paper_id": "MTTPLcwvqTt",
      "title": "The Provable Benefit of Unsupervised Data Sharing for Offline Reinforcement Learning",
      "authors": "Hao Hu, Yiqin Yang, Qianchuan Zhao, Chongjie Zhang",
      "paper_url": "https://openreview.net/pdf/806e8342078d660ef637a7cf57bbd0d47d229211.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_LQIjzPdDt3q",
      "paper_id": "LQIjzPdDt3q",
      "title": "The Role of Coverage in Online Reinforcement Learning",
      "authors": "Tengyang Xie, Dylan J Foster, Yu Bai, Nan Jiang, Sham M. Kakade",
      "paper_url": "https://openreview.net/pdf/a2c365918c8b9f3e5b7cd871606f05d90118525a.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_8eb12UQYxrG",
      "paper_id": "8eb12UQYxrG",
      "title": "The Role of Pretrained Representations for the OOD Generalization of RL Agents",
      "authors": "Frederik Träuble, Andrea Dittadi, Manuel Wuthrich, Felix Widmaier, Peter Vincent Gehler, Ole Winther, Francesco Locatello, Olivier Bachem, Bernhard Schölkopf, Stefan Bauer",
      "paper_url": "https://openreview.net/pdf/21a137cbbf57e242ed59de220b1d44db251017d9.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_qYda4oLEc1",
      "paper_id": "qYda4oLEc1",
      "title": "The Traveling Observer Model: Multi-task Learning Through Spatial Variable Embeddings",
      "authors": "Elliot Meyerson, Risto Miikkulainen",
      "paper_url": "https://openreview.net/pdf/467ef145eb7edf951ce11daf694cfa5593a44e89.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr24_JXGph215fL",
      "paper_id": "JXGph215fL",
      "title": "The Update-Equivalence Framework for Decision-Time Planning",
      "authors": "Samuel Sokota, Gabriele Farina, David J Wu, Hengyuan Hu, Kevin A. Wang, J Zico Kolter, Noam Brown",
      "paper_url": "https://openreview.net/pdf?id=JXGph215fL",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_KrtGfTGaGe",
      "paper_id": "KrtGfTGaGe",
      "title": "The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models",
      "authors": "Raphaël Avalos, Florent Delgrange, Ann Nowe, Guillermo Perez, Diederik M Roijers",
      "paper_url": "https://openreview.net/pdf?id=KrtGfTGaGe",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_QDdJhACYrlX",
      "paper_id": "QDdJhACYrlX",
      "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
      "authors": "Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan Stanciulescu, Fabien Moutarde",
      "paper_url": "https://openreview.net/pdf/a8ce9facf1e0dfc642c02f9849f5b7910589efad.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_5yDS32hKJc",
      "paper_id": "5yDS32hKJc",
      "title": "Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do",
      "authors": "Yoav Wald, Mark Goldstein, Yonathan Efroni, Wouter A.C. van Amsterdam, Rajesh Ranganath",
      "paper_url": "https://openreview.net/pdf?id=5yDS32hKJc",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_5liV2xUdJL",
      "paper_id": "5liV2xUdJL",
      "title": "Time-Efficient Reinforcement Learning with Stochastic Stateful Policies",
      "authors": "Firas Al-Hafez, Guoping Zhao, Jan Peters, Davide Tateo",
      "paper_url": "https://openreview.net/pdf?id=5liV2xUdJL",
      "venue": "iclr24"
    },
    {
      "id": "iclr23__BoPed4tYww",
      "paper_id": "_BoPed4tYww",
      "title": "Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints",
      "authors": "David Henry Mguni, Aivar Sootla, Juliusz Krzysztof Ziomek, Oliver Slumbers, Zipeng Dai, Kun Shao, Jun Wang",
      "paper_url": "https://openreview.net/pdf/bc9be9e8ebfee6333ee4f81c2a12d4f382d07442.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_N4NhVN30ph",
      "paper_id": "N4NhVN30ph",
      "title": "TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning",
      "authors": "Ge Li, Dong Tian, Hongyi Zhou, Xinkai Jiang, Rudolf Lioutikov, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf?id=N4NhVN30ph",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_OXRZeMmOI7a",
      "paper_id": "OXRZeMmOI7a",
      "title": "Topological Experience Replay",
      "authors": "Zhang-Wei Hong, Tao Chen, Yen-Chen Lin, Joni Pajarinen, Pulkit Agrawal",
      "paper_url": "https://openreview.net/pdf/67478db1775a09947be98e8721cebb8b1e453692.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_QxItoEAVMb",
      "paper_id": "QxItoEAVMb",
      "title": "TorchRL: A data-driven decision-making library for PyTorch",
      "authors": "Albert Bou, Matteo Bettini, Sebastian Dittert, Vikash Kumar, Shagun Sodhani, Xiaomeng Yang, Gianni De Fabritiis, Vincent Moens",
      "paper_url": "https://openreview.net/pdf?id=QxItoEAVMb",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_YvKJGYL4j7",
      "paper_id": "YvKJGYL4j7",
      "title": "Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization",
      "authors": "Tianxu Li, Kun Zhu",
      "paper_url": "https://openreview.net/pdf?id=YvKJGYL4j7",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_ycF7mKfVGO",
      "paper_id": "ycF7mKfVGO",
      "title": "Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation",
      "authors": "Haruka Kiyohara, Ren Kishimoto, Kosuke Kawakami, Ken Kobayashi, Kazuhide Nakata, Yuta Saito",
      "paper_url": "https://openreview.net/pdf?id=ycF7mKfVGO",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_ccWaPGl9Hq",
      "paper_id": "ccWaPGl9Hq",
      "title": "Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality",
      "authors": "Jiawei Huang, Jinglin Chen, Li Zhao, Tao Qin, Nan Jiang, Tie-Yan Liu",
      "paper_url": "https://openreview.net/pdf/a0405b77400aed6d75d6c20a20d9a5335d22d314.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_6pPYRXKPpw",
      "paper_id": "6pPYRXKPpw",
      "title": "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations",
      "authors": "Xiaogang Jia, Denis Blessing, Xinkai Jiang, Moritz Reuss, Atalay Donat, Rudolf Lioutikov, Gerhard Neumann",
      "paper_url": "https://openreview.net/pdf?id=6pPYRXKPpw",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_vgXI1Ws0ma",
      "paper_id": "vgXI1Ws0ma",
      "title": "Towards Empowerment Gain through Causal Structure Learning in Model-Based Reinforcement Learning",
      "authors": "Hongye Cao, Fan Feng, Meng Fang, Shaokang Dong, Tianpei Yang, Jing Huo, Yang Gao",
      "paper_url": "https://openreview.net/pdf?id=vgXI1Ws0ma",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_R1hIXdST22",
      "paper_id": "R1hIXdST22",
      "title": "Towards General-Purpose Model-Free Reinforcement Learning",
      "authors": "Scott Fujimoto, Pierluca D'Oro, Amy Zhang, Yuandong Tian, Michael Rabbat",
      "paper_url": "https://openreview.net/pdf?id=R1hIXdST22",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_bMvqccRmKD",
      "paper_id": "bMvqccRmKD",
      "title": "Towards Generalizable Reinforcement Learning via Causality-Guided Self-Adaptive Representations",
      "authors": "Yupei Yang, Biwei Huang, Fan Feng, Xinyue Wang, Shikui Tu, Lei Xu",
      "paper_url": "https://openreview.net/pdf?id=bMvqccRmKD",
      "venue": "iclr25"
    },
    {
      "id": "iclr25_HH4KWP8RP5",
      "paper_id": "HH4KWP8RP5",
      "title": "Towards Improving Exploration through Sibling Augmented GFlowNets",
      "authors": "Kanika Madan, Alex Lamb, Emmanuel Bengio, Glen Berseth, Yoshua Bengio",
      "paper_url": "https://openreview.net/pdf?id=HH4KWP8RP5",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_hWwY_Jq0xsN",
      "paper_id": "hWwY_Jq0xsN",
      "title": "Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes",
      "authors": "Eoin M. Kenny, Mycal Tucker, Julie Shah",
      "paper_url": "https://openreview.net/pdf/89dc907add1447b8730b63f4562410d7d9346676.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_U9HW6vyNClg",
      "paper_id": "U9HW6vyNClg",
      "title": "Towards Minimax Optimal Reward-free Reinforcement Learning in Linear MDPs",
      "authors": "Pihe Hu, Yu Chen, Longbo Huang",
      "paper_url": "https://openreview.net/pdf/98b0ed97b22ff4771f3198ce6446f6efc032fadc.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_3mnWvUZIXt",
      "paper_id": "3mnWvUZIXt",
      "title": "Towards Principled Representation Learning from Videos for Reinforcement Learning",
      "authors": "Dipendra Misra, Akanksha Saran, Tengyang Xie, Alex Lamb, John Langford",
      "paper_url": "https://openreview.net/pdf?id=3mnWvUZIXt",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_5hAMmCU0bK",
      "paper_id": "5hAMmCU0bK",
      "title": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption",
      "authors": "Rui Yang, Han Zhong, Jiawei Xu, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang",
      "paper_url": "https://openreview.net/pdf?id=5hAMmCU0bK",
      "venue": "iclr24"
    },
    {
      "id": "iclr25_stUKwWBuBm",
      "paper_id": "stUKwWBuBm",
      "title": "Tractable Multi-Agent Reinforcement Learning through Behavioral Economics",
      "authors": "Eric Mazumdar, Kishan Panaganti, Laixi Shi",
      "paper_url": "https://openreview.net/pdf?id=stUKwWBuBm",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_6q_2b6u0BnJ",
      "paper_id": "6q_2b6u0BnJ",
      "title": "TRAIL: Near-Optimal Imitation Learning with Suboptimal Data",
      "authors": "Mengjiao Yang, Sergey Levine, Ofir Nachum",
      "paper_url": "https://openreview.net/pdf/958e9e602eeb7bacbb7b7ef495ca1126f80bed1f.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_6vkzF28Hur8",
      "paper_id": "6vkzF28Hur8",
      "title": "Training Transition Policies via Distribution Matching for Complex Tasks",
      "authors": "JU-SEUNG BYUN, Andrew Perrault",
      "paper_url": "https://openreview.net/pdf/b0fad4cf84b44e02b873a928fb82cf77473641fa.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_uqe5HkjbT9",
      "paper_id": "uqe5HkjbT9",
      "title": "Trajectory-Class-Aware Multi-Agent Reinforcement Learning",
      "authors": "Hyungho Na, Kwanghyeon Lee, Sumin Lee, Il-chul Moon",
      "paper_url": "https://openreview.net/pdf?id=uqe5HkjbT9",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_7KdAoOsI81C",
      "paper_id": "7KdAoOsI81C",
      "title": "Transfer RL across Observation Feature Spaces via Model-Based Regularization",
      "authors": "Yanchao Sun, Ruijie Zheng, Xiyao Wang, Andrew E Cohen, Furong Huang",
      "paper_url": "https://openreview.net/pdf/8b952d72e26efd12a72d49901beab7dc48d28ce9.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_UcDUxjPYWSr",
      "paper_id": "UcDUxjPYWSr",
      "title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design",
      "authors": "Ye Yuan, Yuda Song, Zhengyi Luo, Wen Sun, Kris M. Kitani",
      "paper_url": "https://openreview.net/pdf/511a5c95afacad18125605721a8d1e530c07018b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_yN4Wv17ss3",
      "paper_id": "yN4Wv17ss3",
      "title": "Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining",
      "authors": "Licong Lin, Yu Bai, Song Mei",
      "paper_url": "https://openreview.net/pdf?id=yN4Wv17ss3",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_Qun8fv4qSby",
      "paper_id": "Qun8fv4qSby",
      "title": "Transient Non-stationarity and Generalisation in Deep Reinforcement Learning",
      "authors": "Maximilian Igl, Gregory Farquhar, Jelena Luketina, Wendelin Boehmer, Shimon Whiteson",
      "paper_url": "https://openreview.net/pdf/ea444807010b334cd2b90645f1cfa31bd38f3ef7.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_WQV9kB1qSU",
      "paper_id": "WQV9kB1qSU",
      "title": "Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers",
      "authors": "Kiyoung Seong, Seonghyun Park, Seonghwan Kim, Woo Youn Kim, Sungsoo Ahn",
      "paper_url": "https://openreview.net/pdf?id=WQV9kB1qSU",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_RaqZX9LSGA",
      "paper_id": "RaqZX9LSGA",
      "title": "Tree Search-Based Policy Optimization under Stochastic Execution Delay",
      "authors": "David Valensi, Esther Derman, Shie Mannor, Gal Dalal",
      "paper_url": "https://openreview.net/pdf?id=RaqZX9LSGA",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_EcGGFkNTxdJ",
      "paper_id": "EcGGFkNTxdJ",
      "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
      "authors": "Jakub Grudzien Kuba, Ruiqing Chen, Muning Wen, Ying Wen, Fanglei Sun, Jun Wang, Yaodong Yang",
      "paper_url": "https://openreview.net/pdf/3909fb38c37d6d25dca74d884b891baf99754ff3.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_iamWnRpMuQ",
      "paper_id": "iamWnRpMuQ",
      "title": "Uncertainty and Influence aware Reward Model Refinement for Reinforcement Learning from Human Feedback",
      "authors": "Zexu Sun, Yiju Guo, Yankai Lin, Xu Chen, Qi Qi, Xing Tang, xiuqiang He, Ji-Rong Wen",
      "paper_url": "https://openreview.net/pdf?id=iamWnRpMuQ",
      "venue": "iclr25"
    },
    {
      "id": "iclr24_ILYjDvUM6U",
      "paper_id": "ILYjDvUM6U",
      "title": "Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning",
      "authors": "Sheng Xu, Guiliang Liu",
      "paper_url": "https://openreview.net/pdf?id=ILYjDvUM6U",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_shbAgEsk3qM",
      "paper_id": "shbAgEsk3qM",
      "title": "Understanding and Leveraging Overparameterization in Recursive Value Estimation",
      "authors": "Chenjun Xiao, Bo Dai, Jincheng Mei, Oscar A Ramirez, Ramki Gummadi, Chris Harris, Dale Schuurmans",
      "paper_url": "https://openreview.net/pdf/c5131ad5930c1a9f32ede673f284175158a75792.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_ZkC8wKoLbQ7",
      "paper_id": "ZkC8wKoLbQ7",
      "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning",
      "authors": "Clare Lyle, Mark Rowland, Will Dabney",
      "paper_url": "https://openreview.net/pdf/4d5e54a26ae7558a8d6efeb0bcc7d5f6844aba2a.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr25_B2RXwASSpy",
      "paper_id": "B2RXwASSpy",
      "title": "Understanding Constraint Inference in Safety-Critical Inverse Reinforcement Learning",
      "authors": "Bo Yue, Shufan Wang, Ashish Gaurav, Jian Li, Pascal Poupart, Guiliang Liu",
      "paper_url": "https://openreview.net/pdf?id=B2RXwASSpy",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_T8vZHIRTrY",
      "paper_id": "T8vZHIRTrY",
      "title": "Understanding Domain Randomization for Sim-to-real Transfer",
      "authors": "Xiaoyu Chen, Jiachen Hu, Chi Jin, Lihong Li, Liwei Wang",
      "paper_url": "https://openreview.net/pdf/4e09871da1715277fa6f29c516b944b9e97b0c16.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_sVEu295o70",
      "paper_id": "sVEu295o70",
      "title": "Understanding when Dynamics-Invariant Data Augmentations Benefit Model-free Reinforcement Learning Updates",
      "authors": "Nicholas Corrado, Josiah P. Hanna",
      "paper_url": "https://openreview.net/pdf?id=sVEu295o70",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_tbFBh3LMKi",
      "paper_id": "tbFBh3LMKi",
      "title": "Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization",
      "authors": "Kun LEI, Zhengmao He, Chenhao Lu, Kaizhe Hu, Yang Gao, Huazhe Xu",
      "paper_url": "https://openreview.net/pdf?id=tbFBh3LMKi",
      "venue": "iclr24"
    },
    {
      "id": "iclr24_OwtMhMSybu",
      "paper_id": "OwtMhMSybu",
      "title": "Unlocking the Power of Representations in Long-term Novelty-based Exploration",
      "authors": "Alaa Saade, Steven Kapturowski, Daniele Calandriello, Charles Blundell, Pablo Sprechmann, Leopoldo Sarra, Oliver Groth, Michal Valko, Bilal Piot",
      "paper_url": "https://openreview.net/pdf?id=OwtMhMSybu",
      "venue": "iclr24"
    },
    {
      "id": "iclr21_GJwMHetHc73",
      "paper_id": "GJwMHetHc73",
      "title": "Unsupervised Object Keypoint Learning using Local Spatial Predictability",
      "authors": "Anand Gopalakrishnan, Sjoerd van Steenkiste, Jürgen Schmidhuber",
      "paper_url": "https://openreview.net/pdf/9c46c3c76f9646f35cf6acdbca761d23e88bde59.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_0QnKnt411O",
      "paper_id": "0QnKnt411O",
      "title": "Unsupervised Zero-Shot Reinforcement Learning via Dual-Value Forward-Backward Representation",
      "authors": "Jingbo Sun, Songjun Tu, qichao Zhang, Haoran Li, Xin Liu, Yaran Chen, Ke Chen, Dongbin Zhao",
      "paper_url": "https://openreview.net/pdf?id=0QnKnt411O",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_v9c7hr9ADKx",
      "paper_id": "v9c7hr9ADKx",
      "title": "UPDeT: Universal Multi-agent RL via Policy Decoupling with Transformers",
      "authors": "Siyi Hu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang",
      "paper_url": "https://openreview.net/pdf/1f24b0b3a09ad8484d3887053d6c4c6a87d96ba1.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_a4COps0uokg",
      "paper_id": "a4COps0uokg",
      "title": "User-Interactive Offline Reinforcement Learning",
      "authors": "Phillip Swazinna, Steffen Udluft, Thomas Runkler",
      "paper_url": "https://openreview.net/pdf/81fc7c68487b51f4cf252f7eaa1571f38b45e4cb.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_Tk1VQDadfL",
      "paper_id": "Tk1VQDadfL",
      "title": "UTILITY: Utilizing Explainable Reinforcement Learning to Improve Reinforcement Learning",
      "authors": "Shicheng Liu, Minghui Zhu",
      "paper_url": "https://openreview.net/pdf?id=Tk1VQDadfL",
      "venue": "iclr25"
    },
    {
      "id": "iclr22_vgqS1vkkCbE",
      "paper_id": "vgqS1vkkCbE",
      "title": "Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning",
      "authors": "Dhruv Shah, Peng Xu, Yao Lu, Ted Xiao, Alexander T Toshev, Sergey Levine, brian ichter",
      "paper_url": "https://openreview.net/pdf/c49d03d6fc757e37898cc5399159de2e30589146.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr22_4-D6CZkRXxI",
      "paper_id": "4-D6CZkRXxI",
      "title": "Value Gradient weighted Model-Based Reinforcement Learning",
      "authors": "Claas A Voelcker, Victor Liao, Animesh Garg, Amir-massoud Farahmand",
      "paper_url": "https://openreview.net/pdf/d924f4fd00b558974bf7f10d5b94c179c583225b.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_UYcIheNY9Pf",
      "paper_id": "UYcIheNY9Pf",
      "title": "Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning",
      "authors": "Deyao Zhu, Li Erran Li, Mohamed Elhoseiny",
      "paper_url": "https://openreview.net/pdf/150a84ae3915a51fe2f20095f5f1bdb3d24fa581.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr25_elTJBP7Fbv",
      "paper_id": "elTJBP7Fbv",
      "title": "Value-aligned Behavior Cloning for Offline Reinforcement Learning via Bi-level Optimization",
      "authors": "Xingyu Jiang, Ning Gao, Xiuhui Zhang, Hongkun Dou, Yue Deng",
      "paper_url": "https://openreview.net/pdf?id=elTJBP7Fbv",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_P0p33rgyoE",
      "paper_id": "P0p33rgyoE",
      "title": "Variational Intrinsic Control Revisited",
      "authors": "Taehwan Kwon",
      "paper_url": "https://openreview.net/pdf/8841dcedad713be63398c9001418c334c7479b4e.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr23_3VFQfAG3vwi",
      "paper_id": "3VFQfAG3vwi",
      "title": "Variational Latent Branching Model for Off-Policy Evaluation",
      "authors": "Qitong Gao, Ge Gao, Min Chi, Miroslav Pajic",
      "paper_url": "https://openreview.net/pdf/59d490c9944a87d96bea36cd12136115535559d0.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_pjqqxepwoMy",
      "paper_id": "pjqqxepwoMy",
      "title": "Variational oracle guiding for reinforcement learning",
      "authors": "Dongqi Han, Tadashi Kozuno, Xufang Luo, Zhao-Yun Chen, Kenji Doya, Yuqing Yang, Dongsheng Li",
      "paper_url": "https://openreview.net/pdf/88d5d80331a1704592f9a66d052c33f976661945.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr23_YJ7o2wetJ2",
      "paper_id": "YJ7o2wetJ2",
      "title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training",
      "authors": "Yecheng Jason Ma, Shagun Sodhani, Dinesh Jayaraman, Osbert Bastani, Vikash Kumar, Amy Zhang",
      "paper_url": "https://openreview.net/pdf/56f5b528ba9ae4f7c40ca328636fffe7c8c0c7da.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr23_WOquZTLCBO1",
      "paper_id": "WOquZTLCBO1",
      "title": "VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation",
      "authors": "Thanh Nguyen-Tang, Raman Arora",
      "paper_url": "https://openreview.net/pdf/9a8eb48070ffcd0332fa35d7aaa9229cea1438c4.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr24_N0I2RtD8je",
      "paper_id": "N0I2RtD8je",
      "title": "Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning",
      "authors": "Juan Rocamonde, Victoriano Montesinos, Elvis Nava, Ethan Perez, David Lindner",
      "paper_url": "https://openreview.net/pdf?id=N0I2RtD8je",
      "venue": "iclr24"
    },
    {
      "id": "iclr23_OnM3R47KIiU",
      "paper_id": "OnM3R47KIiU",
      "title": "Visual Imitation Learning with Patch Rewards",
      "authors": "Minghuan Liu, Tairan He, Weinan Zhang, Shuicheng YAN, Zhongwen Xu",
      "paper_url": "https://openreview.net/pdf/c288073bd4cad20bf8058f578c66b24863f2944d.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_9r30XCjf5Dt",
      "paper_id": "9r30XCjf5Dt",
      "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics",
      "authors": "Yanchao Sun, Da Huo, Furong Huang",
      "paper_url": "https://openreview.net/pdf/fb9e902c18157059497d56cdc36770d12b05acf4.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_5xSRg3eYZz",
      "paper_id": "5xSRg3eYZz",
      "title": "VVC-Gym: A Fixed-Wing UAV Reinforcement Learning Environment for Multi-Goal Long-Horizon Problems",
      "authors": "Xudong Gong, Feng Dawei, Kele Xu, weijia wang, Zhangjun Sun, Xing Zhou, Si Zheng, Bo Ding, Huaimin Wang",
      "paper_url": "https://openreview.net/pdf?id=5xSRg3eYZz",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_JLLTtEdh1ZY",
      "paper_id": "JLLTtEdh1ZY",
      "title": "Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees",
      "authors": "Florent Delgrange, Ann Nowe, Guillermo Perez",
      "paper_url": "https://openreview.net/pdf/0f568427fb05b2660614b52c5f8dab551fc4d702.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr21_30EvkP2aQLD",
      "paper_id": "30EvkP2aQLD",
      "title": "What are the Statistical Limits of Offline RL with Linear Function Approximation?",
      "authors": "Ruosong Wang, Dean Foster, Sham M. Kakade",
      "paper_url": "https://openreview.net/pdf/abc8c212aff033c6042f681a3e27a3c9af250066.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_7BQkXXM8Fy",
      "paper_id": "7BQkXXM8Fy",
      "title": "What Makes a Good Diffusion Planner for Decision Making?",
      "authors": "Haofei Lu, Dongqi Han, Yifei Shen, Dongsheng Li",
      "paper_url": "https://openreview.net/pdf?id=7BQkXXM8Fy",
      "venue": "iclr25"
    },
    {
      "id": "iclr21_nIAxjsniDzg",
      "paper_id": "nIAxjsniDzg",
      "title": "What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study",
      "authors": "Marcin Andrychowicz, Anton Raichuk, Piotr Stańczyk, Manu Orsini, Sertan Girgin, Raphaël Marinier, Leonard Hussenot, Matthieu Geist, Olivier Pietquin, Marcin Michalski, Sylvain Gelly, Olivier Bachem",
      "paper_url": "https://openreview.net/pdf/6e07c0b9828c97445a9667bf90fe254fa7de8e3a.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_r0pLGGcuY6",
      "paper_id": "r0pLGGcuY6",
      "title": "What's the Move? Hybrid Imitation Learning via Salient Points",
      "authors": "Priya Sundaresan, Hengyuan Hu, Quan Vuong, Jeannette Bohg, Dorsa Sadigh",
      "paper_url": "https://openreview.net/pdf?id=r0pLGGcuY6",
      "venue": "iclr25"
    },
    {
      "id": "iclr23_lMO7TC7cuuh",
      "paper_id": "lMO7TC7cuuh",
      "title": "When Data Geometry Meets Deep Function: Generalizing Offline Reinforcement Learning",
      "authors": "Jianxiong Li, Xianyuan Zhan, Haoran Xu, Xiangyu Zhu, Jingjing Liu, Ya-Qin Zhang",
      "paper_url": "https://openreview.net/pdf/94dbfca2646bd9ee54214755138d35cafa230611.pdf",
      "venue": "iclr23"
    },
    {
      "id": "iclr22_dEwfxt14bca",
      "paper_id": "dEwfxt14bca",
      "title": "When should agents explore?",
      "authors": "Miruna Pislar, David Szepesvari, Georg Ostrovski, Diana L Borsa, Tom Schaul",
      "paper_url": "https://openreview.net/pdf/5628a68890630dcf1b41b8c21140287bb6d2e9eb.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr24_vpV7fOFQy4",
      "paper_id": "vpV7fOFQy4",
      "title": "When should we prefer Decision Transformers for Offline Reinforcement Learning?",
      "authors": "Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani, Amy Zhang",
      "paper_url": "https://openreview.net/pdf?id=vpV7fOFQy4",
      "venue": "iclr24"
    },
    {
      "id": "iclr22_JM2kFbJvvI",
      "paper_id": "JM2kFbJvvI",
      "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL",
      "authors": "Yanchao Sun, Ruijie Zheng, Yongyuan Liang, Furong Huang",
      "paper_url": "https://openreview.net/pdf/b11335ea1d1d4ca95531723261e11735e0550bc4.pdf",
      "venue": "iclr22"
    },
    {
      "id": "iclr21_LmUJqB1Cz8",
      "paper_id": "LmUJqB1Cz8",
      "title": "Winning the L2RPN Challenge: Power Grid Management via Semi-Markov Afterstate Actor-Critic",
      "authors": "Deunsol Yoon, Sunghoon Hong, Byung-Jun Lee, Kee-Eung Kim",
      "paper_url": "https://openreview.net/pdf/19ea8e1953e4da5a00beede7da663e04f6717020.pdf",
      "venue": "iclr21"
    },
    {
      "id": "iclr25_cmYScmfu4Q",
      "paper_id": "cmYScmfu4Q",
      "title": "Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inference",
      "authors": "Qining Zhang, Lei Ying",
      "paper_url": "https://openreview.net/pdf?id=cmYScmfu4Q",
      "venue": "iclr25"
    }
  ]
}